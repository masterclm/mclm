---
title: "Keyword Analysis"
output: learnr::tutorial
runtime: shiny_prerendered
description: >
  Learn how to run keyword analysis with `mclm`.
---

```{r setup, include=FALSE}
library(learnr)
library(tidyverse)
library(mclm)
knitr::opts_chunk$set(echo = FALSE)

stop_list <- read_types("data/stop_list.txt")

freqlists <- readRDS("data/freqlists.rds")
attach(freqlists)
top_20 <- flist_20 %>% 
  drop_types(stop_list) %>% 
  drop_types("applause") %>% 
  keep_pos(1:50) %>% 
  as_types()

```

## Setting up

To show how to run some keyword analysis, we'll use three frequency lists of subcorpora of US presidential speeches:

- `flist_18` for the period of 1789-1809 (Washington, Adams and Jefferson)
- `flist_19` for the period of 1889-1909 (Harrison, Cleveland, McKinley and Roosevelt)
- `flist_20` for the period of 1989-2009 (Bush Sr., Clinton and Bush Jr.)

Inspect the frequency lists to answer the questions below. If you don't know how to get the information you need, go through `learnr::run_tutorial("freq_and_conc", "mclm")` and then come back!

```{r flist-18, exercise = TRUE, exercise.eval = TRUE}
flist_18
```

```{r flist-quiz}
quiz(
  mclm_question_num("How many types are in the 18th Century subcorpus?",
              n_types(flist_18)),
  mclm_question_num("How many types are in the 19th Century subcorpus?",
              n_types(flist_19)),
  mclm_question_num("How many tokens are in the 18th Century subcorpus?",
              tot_n_tokens(flist_18)),
  mclm_question_num("How many tokens are in the 20th Century subcorpus?",
              tot_n_tokens(flist_20)),
  question_text("Which word is in the tenth position in the 20th Century corpus?", answer(names(flist_20[10]), correct = TRUE)),
  mclm_question_num("How many occurrences of *i* are there in the 20th Century corpus?", flist_20[["i"]]),
  caption = "Exploring frequency lists..."
)
```

## List of types

In order to select the key words, we will extract the types of a frequency list with `as_types()`, after following two important steps:

1. Excluding the terms from the stop words list (and, in the case of the `flist_19` and `flist_20`, "000" and "applause" respectively) with `drop_types()`

2. Extracting the top 10 most frequent types with `keep_pos()`

```{r top-freq1, exercise = TRUE, exercise.eval = TRUE}
stop_list <- read_types("data/stop_list.txt")
top_18 <- flist_18 %>% 
  drop_types(stop_list) %>% 
  keep_pos(1:50) %>% 
  as_types()
print(top_18, n = 50)
```

Run the appropriate code to generate `top_19` and `top_20`:

```{r top-freq2, exercise = TRUE}

```

```{r top-freq2-hint}
flist_19 %>% drop_types("000")
```


```{r drop-quiz}
quiz(
  mclm_question_text("Which is the twentieth type in `top_19`?",
              answer("great", correct = TRUE),
              answer("government",
                     message = 'Did you exclude "000"?'),
              answer("is",
                     message = "Did you remove the stop words?")
              ),
  mclm_question_text("Which is the fifteenth type in `top_20`?",
              answer("help", correct = TRUE),
              answer("health",
                     message = 'Did you exclude "applause"?'),
              answer("from",
                     message = "Did you remove the stop words?")
              ),
  caption = "Let's check if the results are right!"
)
```

## Unique words

```{r topsetup}
top_18 <- flist_18 %>% 
  drop_types(stop_list) %>% 
  keep_pos(1:50) %>% 
  as_types()
top_19 <- flist_19 %>% 
  drop_types(stop_list) %>% 
  drop_types("000") %>% 
  keep_pos(1:50) %>% 
  as_types()
```

Now that we have created type lists with `as_types()`, we can filter lists based on the other lists. For example, we can use `keep_types()` to find the types that two subcorpora have in common:

```{r top-keep, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "topsetup"}
top_18 %>% 
  keep_types(top_19) %>% 
  keep_types(top_20)
```

Alternatively, we could use `drop_types()` to find the types that are unique to a specific subcorpus. In the following exercise, change the code to find the types that are unique to the different subcorpora and answer the questions below.

```{r top-drop, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "topsetup"}
top_18 %>% 
  drop_types(top_19) %>% 
  drop_types(top_20)
```

```{r unique-quiz}
unique_18 <- top_18 %>% drop_types(top_19) %>% drop_types(top_20)
unique_19 <- top_19 %>% drop_types(top_18) %>% drop_types(top_20)
unique_20 <- top_20 %>% drop_types(top_19) %>% drop_types(top_18)
uniqueness_question <- function(word) {
  mclm_question(sprintf('Which of the lists includes the word "%s"?', word),
              answer("top_18", correct = word %in% top_18),
              answer("top_19", correct = word %in% top_19),
              answer("top_20", correct = word %in% top_20)
              )
}
quiz(
  mclm_question_num("How many types are unique to the list of most frequent words in subcorpus of the 18th Century presidential speeches?",
              n_types(unique_18)),
  mclm_question_num("How many types are unique to the list of most frequent words in the subcorpus of the 19th Century presidential speeches?",
              n_types(unique_19)
              ),
  uniqueness_question("constitution"),
  uniqueness_question("america"),
  uniqueness_question("justice"),
  caption = "Exploring the uniqueness of the subcorpora..."
)
```

## Keyword analysis

Keyword analysis is more sophisticated than just identifying the words that are unique to one subcorpus or another. Instead, we select words that are "attracted" to a specific corpus in comparison to a reference corpus. For that purpose we can use the `assoc_scores()` function.

Let's say we want to find the words that are more characteristic of the 20th Century subcorpus as opposed to the combined 18th and 19th Century subcorpora. First, we can merge the frequency lists `flist_18` and `flist_19`, which is the equivalent of creating a frequency list based no the combined corpora. The total number of _tokens_ is the same as the sum of the tokens in both subcorpora, but the total number of types is different, because some types occur in both corpora.

```{r reflist, exercise = TRUE, exercise.eval = TRUE}
flist_ref <- freqlist_merge(flist_18, flist_19)
flist_ref
```

Once we have a reference corpus, we can compute the association scores:

```{r scores, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "reflist"}
scores <- assoc_scores(flist_20, flist_ref)
scores
```

The output of `assoc_scores()` is extremely comprehensive and can seem intimidating at the beginning. If you run `print(scores)` instead you will see a more compact version. You can always run `?assoc_scores` to check the documentation, where the output is thoroughly described (see "Values" section).

For now, let's see how we can manipulate the output to get some information on demand. You can choose between using {mclm} tools and using {tidyverse} tools on the `tibble` version.

If you'd like to use {mlm} tools, you can filter your rows using `filter()` an include `sort_order` as an argument of `print()`. To access the types column, you can use `type_names()`:

```{r mclm-filter, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "scores"}
scores %>% 
  filter(PMI > 0.3 & !(type_names(.) %in% stop_list)) %>% 
  print(sort_order = "G_signed", n = 50)
```

```{r tidyverse-filter, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "scores"}
scores %>% 
  as_tibble() %>% # to manipulate as tibble
  filter(PMI > 0.3 & !(type %in% stop_list)) %>% 
  arrange(desc(G_signed)) %>% 
  select(type, a, PMI, G_signed)
```

> Some frequencies are 0.5: they are original `0`s that were transformed to avoid
breaking computations that cannot be performed with zeros (e.g. $\log$, division by 0).

From such a selection we can create a `types` object of words that are significantly more attracted to the 20th Century speeches than to the 18th and 19th Century speeches.

```{r scores-types, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "scores"}
keyw_20 <- scores %>%
  as_tibble() %>%
  filter(PMI > 0.3 & !(type %in% stop_list)) %>%
  arrange(desc(G_signed)) %>%
  slice_head(n = 50) %>% # get top 50 elements
  pull(type) %>% # extract types
  as_types()# convert to types object
print(keyw_20, n = 50)
```

Then `keyw_20` can be compared to the list of types we selected before. The code below shows the intersection between the top 50 words in the subcorpus and the keywords. Use `drop_types()` to find the difference between the sets and answer the questions below.

```{r keyw, exercise = TRUE, exercise.eval = TRUE, exercise.setup = "scores-types"}
top_20 %>% 
  keep_types(keyw_20) %>% 
  print(n = 50)
```

In the questions below, *for the sake of simplicity*, "frequent" means that a word is among the 50 most frequent types of the 20th Century speeches (in `top_20`) and "characteristic" that it is among the top 50 types in terms of keyness (in `keyw_20`).

```{r keyw-quiz}
intersection_20 <- keep_types(top_20, keyw_20)
only_top_20 <- drop_types(top_20, keyw_20)
only_kw_20 <- drop_types(keyw_20, top_20)
keyness_question <- function(word) {
  mclm_question(sprintf('Which of the following statements is true for the word "%s"?', word),
              answer(
                "It is frequent in AND characteristic of the 20th Century speeches.",
                correct = word %in% intersection_20),
              answer(
                "It is frequent in BUT NOT characteristic of the 20th Century speeches.",
                correct = word %in% only_top_20),
              answer(
                "It is NOT frequent in BUT it is characteristic of the 20th Century speeches.",
                correct = word %in% only_kw_20),
              answer(
                "It is NEITHER frequent in NOR characteristic of the 20th Century speeches.",
                correct = !(word %in% top_20 | word %in% keyw_20))
              )
}
quiz(
  mclm_question("How many types are among the 50 most frequent types in the 20th Century subcorpus *and* among the top 50 keywords?",
              answer(as.character(n_types(top_20))),
              answer(as.character(n_types(drop_types(keyw_20, top_20)))),
              answer(
                as.character(n_types(keep_types(top_20, keyw_20))),
                correct = TRUE)
              ),
  keyness_question("america"),
  keyness_question("president"),
  keyness_question("nation"),
  keyness_question("iraq"),
  keyness_question("democracy"),
  keyness_question("legislation"),
  caption = "Let's compare frequency and keyness."
)
```
