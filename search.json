[{"path":"https://masterclm.github.io/mclm/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Dirk Speelman. Author. Mariana Montes. Author, maintainer.","code":""},{"path":"https://masterclm.github.io/mclm/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Speelman D, Montes M (2022). mclm: Mastering Corpus Linguistics Methods. https://github.com/masterclm/mclm, https://masterclm.github.io/mclm/.","code":"@Manual{,   title = {mclm: Mastering Corpus Linguistics Methods},   author = {Dirk Speelman and Mariana Montes},   year = {2022},   note = {https://github.com/masterclm/mclm, https://masterclm.github.io/mclm/}, }"},{"path":"https://masterclm.github.io/mclm/index.html","id":"mclm-","dir":"","previous_headings":"","what":"Mastering Corpus Linguistics Methods","title":"Mastering Corpus Linguistics Methods","text":"goal mclm gather various functions support quantitative corpus linguistics. contains classes corpus files, frequency lists, association scores dataframes concordances functions create , manipulate read write files. package companion Methods Corpus Linguistics course Advanced Master Linguistics (KU Leuven), can used basic corpus linguistic analyses. particular, offers number learnr tutorials perform basic tasks mclm filter objects PERL-flavor regular expressions.","code":""},{"path":"https://masterclm.github.io/mclm/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Mastering Corpus Linguistics Methods","text":"can install development version mclm GitHub :","code":"# install.packages(\"devtools\") devtools::install_github(\"montesmariana/mclm\")"},{"path":"https://masterclm.github.io/mclm/index.html","id":"examples","dir":"","previous_headings":"","what":"Examples","title":"Mastering Corpus Linguistics Methods","text":"basic usages mclm. freqlist() function can generate frequency list either text corpus corpus files. get_fnames() function creates list filenames based contents directory can given different functions process corpora. surf_cooc(), example, computes surface co-occurrences item, type “government”, given corpus. co-occurrences can provided assoc_scores() compute association strength different collocates node (“government”) corpus. function conc() finds occurrences regular expression corpus generates concordance.","code":"library(mclm) #> Loading required package: ca #> Loading required package: tibble #>  #> Attaching package: 'mclm' #> The following object is masked from 'package:tibble': #>  #>     as_data_frame toy_corpus <- \"Once upon a time there was a tiny toy corpus. It consisted of three sentences. And it lived happily ever after.\"  flist <- freqlist(toy_corpus, as_text = TRUE) print(flist, n = 5) #> Frequency list (types in list: 19, tokens in list: 21) #> rank      type abs_freq nrm_freq #> ---- --------- -------- -------- #>    1         a        2  952.381 #>    2        it        2  952.381 #>    3     after        1  476.190 #>    4       and        1  476.190 #>    5 consisted        1  476.190 #> ... corpus_files <- get_fnames(system.file(\"extdata\", \"cleveland\", package = \"mclm\")) length(corpus_files) #> [1] 4  surf <- surf_cooc(corpus_files, \"government\", w_left = 5, w_right = 5) assoc_scores(surf) #> Association scores (types in list: 77) #>      type   a    PMI G_signed|   b    c     d dir   exp_a DP_rows #>  1    the 230  0.578   39.554|1321 2152 20276   1 154.072   0.052 #>  2     of 136  0.403   11.259|1415 1454 20974   1 102.844   0.023 #>  3     to  57  0.286    2.323|1494  666 21762   1  46.765   0.007 #>  4     by  39  1.017   17.223|1512  259 22169   1  19.275   0.014 #>  5     in  37  0.038    0.028|1514  520 21908   1  36.028   0.001 #>  6   this  37  1.811   45.360|1514  126 22302   1  10.543   0.018 #>  7    and  36 -0.634   -8.873|1515  828 21600  -1  55.885  -0.014 #>  8      a  28  0.207    0.600|1523  347 22081   1  24.256   0.003 #>  9    has  18  1.238   11.232|1533  100 22328   1   7.632   0.007 #> 10     be  15 -0.332   -0.927|1536  277 22151  -1  18.887  -0.003 #> 11   that  15 -0.067   -0.036|1536  228 22200  -1  15.718   0.000 #> 12    for  14 -0.185   -0.258|1537  232 22196  -1  15.912  -0.001 #> 13   with  14  0.136    0.130|1537  183 22245   1  12.742   0.001 #> 14  their  13  0.112    0.082|1538  173 22255   1  12.031   0.001 #> 15  which  10 -0.120   -0.076|1541  158 22270  -1  10.867  -0.001 #> 16     as   9 -0.128   -0.078|1542  143 22285  -1   9.832  -0.001 #> 17   made   9  1.393    6.903|1542   44 22384   1   3.428   0.004 #> 18    our   9 -0.297   -0.440|1542  162 22266  -1  11.061  -0.001 #> 19 states   9  0.491    1.012|1542   90 22338   1   6.403   0.002 #> 20   been   8  0.169    0.114|1543  102 22326   1   7.115   0.001 #> ... #> <number of extra columns to the right: 7> conc(corpus_files, \"govern\") #> Concordance-based data frame (number of observations: 29) #> idx                             left|match |right                            #>   1 ...heir power and right of self-|govern|ment they have committed to o... #>   2 ... the strength and safety of a|govern|ment by the people. In each s... #>   3 ...d the surest guaranty of good|govern|ment. But the best results in... #>   4 ...results in the operation of a|govern|ment wherein every citizen ha... #>   5 ...efits which our happy form of|govern|ment can bestow. On this ausp... #>   6 ...ation of a republican form of|govern|ment and most compatible with... #>   7 ...f. In the administration of a|govern|ment pledged to do equal and ... #>   8 ... benefits of the best form of|govern|ment ever vouchsafed to man. ... #>   9 ...hina. The admitted right of a|govern|ment to prevent the influx of... #>  10 ...asure of that sovereign self-|govern|ment pertaining to the States... #>  11 ...his land of freedom, of self-|govern|ment, and of laws, here peace... #>  12 ... of successful constitutional|govern|ment, maintenance of good fai... #>  13 ...ulty pending with any foreign|govern|ment. The Argentine Governmen... #>  14 ...itation in favor of a foreign|govern|ment upon the right of select... #>  15 ... several States into a single|govern|ment. In these contests betwe... #>  16 ... and complications of distant|govern|ments. Therefore I am unable ... #>  17 ...hina. The admitted right of a|govern|ment to prevent the influx of... #>  18 ...Kongo has been organized as a|govern|ment under the sovereignty of... #>  19 ...he plenipotentiaries of other|govern|ments, thus making the United... #>  20 ...purpose toward their original|govern|ments. These evils have had m... #>  21 ...the safety and welfare of any|govern|ment. Emergency calling for a... #>  22 ...es at legations. Some foreign|govern|ments do not recognize the un... #>  23 ...he President shall invite the|govern|ments of the countries compos... #>  24 ... attitude and intent of those|govern|ments in respect of the estab... #>  25 ...ioned that the views of these|govern|ments are in each instance su... #>  26 ...to the fixed rules which must|govern|the Army, I am inclined to ag... #>  27 ...ected by a republican form of|govern|ment, to which they owe alleg... #>  28 ...nd the people who desire good|govern|ment, having secured this sta... #>  29 ...g for the use of the District|govern|ment which shall better secur... #>  #> This data frame has 6 columns: #>    column #> 1 glob_id #> 2      id #> 3  source #> 4    left #> 5   match #> 6   right"},{"path":"https://masterclm.github.io/mclm/reference/as_character.html","id":null,"dir":"Reference","previous_headings":"","what":"Coerce object to character — as_character","title":"Coerce object to character — as_character","text":"method turns argument x, least part information , character vector.","code":""},{"path":"https://masterclm.github.io/mclm/reference/as_character.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coerce object to character — as_character","text":"","code":"as_character(x, ...)  # S3 method for default as_character(x, ...)  # S3 method for re as_character(x, ...)  # S3 method for tokens as_character(x, ...)"},{"path":"https://masterclm.github.io/mclm/reference/as_character.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coerce object to character — as_character","text":"x Object coerce character ... Additional arguments","code":""},{"path":"https://masterclm.github.io/mclm/reference/as_character.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coerce object to character — as_character","text":"Object class character","code":""},{"path":"https://masterclm.github.io/mclm/reference/as_character.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coerce object to character — as_character","text":"","code":"(tks <- tokenize(\"The old man and the sea.\")) #> Token sequence of length 6 #> idx token #> --- ----- #>   1   the #>   2   old #>   3   man #>   4   and #>   5   the #>   6   sea as_character(tks) # turn 'tokens' object into character vector #> [1] \"the\" \"old\" \"man\" \"and\" \"the\" \"sea\" as.character(tks) # alternative approach #> [1] \"the\" \"old\" \"man\" \"and\" \"the\" \"sea\"  as_character(1:10) #>  [1] \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\" as.character(1:10) #>  [1] \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\"  regex <- re(\"(?xi) ^ .*\") as_character(regex) # turn 're' object into character vector #> [1] \"(?xi) ^ .*\" as.character(regex) # alternative approach #> [1] \"(?xi) ^ .*\""},{"path":"https://masterclm.github.io/mclm/reference/as_conc.html","id":null,"dir":"Reference","previous_headings":"","what":"Coerce data frame to a concordance object — as_conc","title":"Coerce data frame to a concordance object — as_conc","text":"function coerces data frame object class conc.","code":""},{"path":"https://masterclm.github.io/mclm/reference/as_conc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coerce data frame to a concordance object — as_conc","text":"","code":"as_conc(x, left = NA, match = NA, right = NA, keep_original = FALSE, ...)"},{"path":"https://masterclm.github.io/mclm/reference/as_conc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coerce data frame to a concordance object — as_conc","text":"x data frame. left name column x contains left co-text concordance. .na(left), column assumed name \"left\". match name column x contains match concordance. .na(match), column assumed name \"match\". right name column x contains right co-text concordance. .na(right), column assumed name \"right\". keep_original Logical. values left, match right NA, original names columns kept conc object. ... Additional arguments.","code":""},{"path":"https://masterclm.github.io/mclm/reference/as_conc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coerce data frame to a concordance object — as_conc","text":"Object class conc, kind data frame rows matches following columns: glob_id: Number indicating position match overall list matches. id: Number indicating position match list matches one specific query. source: Either filename file match found (case setting as_text = FALSE), string '-' (case setting as_text = TRUE). left: left-hand side co-text match. match: actual match. right: right-hand side co-text match. also additional attributes methods : base as_data_frame() print() methods, well print_kwic() function, explore() method. object class conc can merged another means merge_conc(). can written file write_conc() read read_conc(). also possible import concordances created means write_conc() import_conc().","code":""},{"path":"https://masterclm.github.io/mclm/reference/as_conc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coerce data frame to a concordance object — as_conc","text":"","code":"(conc_data <- conc('A very small corpus.', '\\\\w+', as_text = TRUE)) #> Concordance-based data frame (number of observations: 4) #> idx                                           left|match |right              #>   1                                               |  A   |very small corpus. #>   2                                              A| very |small corpus.      #>   3                                         A very|small |corpus.            #>   4                                   A very small|corpus|.                  #>  #> This data frame has 6 columns: #>    column #> 1 glob_id #> 2      id #> 3  source #> 4    left #> 5   match #> 6   right df <- as.data.frame(conc_data) as_conc(df) #> Concordance-based data frame (number of observations: 4) #> idx                                           left|match |right              #>   1                                               |  A   |very small corpus. #>   2                                              A| very |small corpus.      #>   3                                         A very|small |corpus.            #>   4                                   A very small|corpus|.                  #>  #> This data frame has 6 columns: #>    column #> 1 glob_id #> 2      id #> 3  source #> 4    left #> 5   match #> 6   right"},{"path":"https://masterclm.github.io/mclm/reference/as_data_frame.html","id":null,"dir":"Reference","previous_headings":"","what":"Coerce object to a data frame — as_data_frame","title":"Coerce object to a data frame — as_data_frame","text":"as_data_frame() alternative .data.frame(). number objects mclm can turned dataframes one functions.","code":""},{"path":"https://masterclm.github.io/mclm/reference/as_data_frame.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coerce object to a data frame — as_data_frame","text":"","code":"as_data_frame(x, row.names = NULL, optional = FALSE, ...)  # S3 method for default as_data_frame(x, row.names = NULL, optional = FALSE, ...)  # S3 method for assoc_scores as.data.frame(x, ...)  # S3 method for conc as.data.frame(x, ...)  # S3 method for fnames as.data.frame(x, ...)  # S3 method for freqlist as.data.frame(x, row.names = NULL, optional = FALSE, ...)  # S3 method for details.slma as.data.frame(x, ...)  # S3 method for slma as.data.frame(x, ...)  # S3 method for tokens as.data.frame(x, ...)  # S3 method for types as.data.frame(x, ...)"},{"path":"https://masterclm.github.io/mclm/reference/as_data_frame.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coerce object to a data frame — as_data_frame","text":"x Object coerce data.frame. row.names NULL character vector giving rownames dataframe. optional Logical. TRUE, setting rownames converting column names optional (see .data.frame()). ... Additional arguments","code":""},{"path":"https://masterclm.github.io/mclm/reference/as_data_frame.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coerce object to a data frame — as_data_frame","text":"Object class data.frame","code":""},{"path":"https://masterclm.github.io/mclm/reference/as_data_frame.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coerce object to a data frame — as_data_frame","text":"","code":"# for an assoc_scores object --------------------- a <- c(10,    30,    15,    1) b <- c(200, 1000,  5000,  300) c <- c(100,   14,    16,    4) d <- c(300, 5000, 10000, 6000) types <- c(\"four\", \"fictitious\", \"toy\", \"examples\") (scores <- assoc_abcd(a, b, c, d, types = types)) #> Association scores (types in list: 4) #>         type  a    PMI G_signed|   b   c     d dir  exp_a DP_rows #> 1       four 10 -1.921  -45.432| 200 100   300  -1 37.869  -0.202 #> 2 fictitious 30  2.000   56.959|1000  14  5000   1  7.498   0.026 #> 3        toy 15  0.536    2.984|5000  16 10000   1 10.343   0.001 #> 4   examples  1  2.067    1.473| 300   4  6000   1  0.239   0.003 #> <number of extra columns to the right: 7> #>   as.data.frame(scores) #>         type  a    b   c     d dir      exp_a      DP_rows    RR_rows       OR #> 1       four 10  200 100   300  -1 37.8688525 -0.202380952  0.1904762  0.15000 #> 2 fictitious 30 1000  14  5000   1  7.4983455  0.026334032 10.4313454 10.71429 #> 3        toy 15 5000  16 10000   1 10.3429579  0.001393583  1.8723829  1.87500 #> 4   examples  1  300   4  6000   1  0.2386994  0.002656037  4.9867110  5.00000 #>            MS        Dice        PMI chi2_signed   G_signed          t #> 1 0.047619048 0.062500000 -1.9210117  -38.158009 -45.431519 -8.8860423 #> 2 0.029126214 0.055865922  2.0003183   81.993003  56.958917  4.1184552 #> 3 0.002991027 0.005945303  0.5363137    3.153303   2.983872  1.2030435 #> 4 0.003322259 0.006535948  2.0667329    2.551819   1.473313  0.7613609 #>     p_fisher_1 #> 1 1.000000e+00 #> 2 6.106227e-14 #> 3 5.916695e-02 #> 4 2.170331e-01 as_data_frame(scores) #>         type  a    b   c     d dir      exp_a      DP_rows    RR_rows       OR #> 1       four 10  200 100   300  -1 37.8688525 -0.202380952  0.1904762  0.15000 #> 2 fictitious 30 1000  14  5000   1  7.4983455  0.026334032 10.4313454 10.71429 #> 3        toy 15 5000  16 10000   1 10.3429579  0.001393583  1.8723829  1.87500 #> 4   examples  1  300   4  6000   1  0.2386994  0.002656037  4.9867110  5.00000 #>            MS        Dice        PMI chi2_signed   G_signed          t #> 1 0.047619048 0.062500000 -1.9210117  -38.158009 -45.431519 -8.8860423 #> 2 0.029126214 0.055865922  2.0003183   81.993003  56.958917  4.1184552 #> 3 0.002991027 0.005945303  0.5363137    3.153303   2.983872  1.2030435 #> 4 0.003322259 0.006535948  2.0667329    2.551819   1.473313  0.7613609 #>     p_fisher_1 #> 1 1.000000e+00 #> 2 6.106227e-14 #> 3 5.916695e-02 #> 4 2.170331e-01  # for a conc object ------------------------------ (conc_data <- conc('A very small corpus.', '\\\\w+', as_text = TRUE)) #> Concordance-based data frame (number of observations: 4) #> idx                                           left|match |right              #>   1                                               |  A   |very small corpus. #>   2                                              A| very |small corpus.      #>   3                                         A very|small |corpus.            #>   4                                   A very small|corpus|.                  #>  #> This data frame has 6 columns: #>    column #> 1 glob_id #> 2      id #> 3  source #> 4    left #> 5   match #> 6   right as.data.frame(conc_data) #>   glob_id id source          left  match               right #> 1       1  1      -                    A  very small corpus. #> 2       2  2      -            A    very       small corpus. #> 3       3  3      -       A very   small             corpus. #> 4       4  4      - A very small  corpus                   .  # for an fnames object --------------------------- cwd_fnames <- as_fnames(c('file1', 'file2')) as.data.frame(cwd_fnames) #>   filename #> 1    file1 #> 2    file2  # for a freqlist, types or tokens object --------- toy_corpus <- \"Once upon a time there was a tiny toy corpus.   It consisted of three sentences. And it lived happily ever after.\" (flist <- freqlist(toy_corpus, as_text = TRUE)) #> Frequency list (types in list: 19, tokens in list: 21) #> rank      type abs_freq nrm_freq #> ---- --------- -------- -------- #>    1         a        2  952.381 #>    2        it        2  952.381 #>    3     after        1  476.190 #>    4       and        1  476.190 #>    5 consisted        1  476.190 #>    6    corpus        1  476.190 #>    7      ever        1  476.190 #>    8   happily        1  476.190 #>    9     lived        1  476.190 #>   10        of        1  476.190 #>   11      once        1  476.190 #>   12 sentences        1  476.190 #>   13     there        1  476.190 #>   14     three        1  476.190 #>   15      time        1  476.190 #>   16      tiny        1  476.190 #>   17       toy        1  476.190 #>   18      upon        1  476.190 #>   19       was        1  476.190 as.data.frame(flist) #>    rank      type abs_freq nrm_freq #> 1     1         a        2 952.3810 #> 2     2        it        2 952.3810 #> 3     3     after        1 476.1905 #> 4     4       and        1 476.1905 #> 5     5 consisted        1 476.1905 #> 6     6    corpus        1 476.1905 #> 7     7      ever        1 476.1905 #> 8     8   happily        1 476.1905 #> 9     9     lived        1 476.1905 #> 10   10        of        1 476.1905 #> 11   11      once        1 476.1905 #> 12   12 sentences        1 476.1905 #> 13   13     there        1 476.1905 #> 14   14     three        1 476.1905 #> 15   15      time        1 476.1905 #> 16   16      tiny        1 476.1905 #> 17   17       toy        1 476.1905 #> 18   18      upon        1 476.1905 #> 19   19       was        1 476.1905  (flist2 <- keep_re(flist, \"^..?$\")) #> Frequency list (types in list: 3, tokens in list: 5) #> <total number of tokens: 21> #> rank orig_rank type abs_freq nrm_freq #> ---- --------- ---- -------- -------- #>    1         1    a        2  952.381 #>    2         2   it        2  952.381 #>    3        10   of        1  476.190 as.data.frame #> function (x, row.names = NULL, optional = FALSE, ...)  #> { #>     if (is.null(x))  #>         return(as.data.frame(list())) #>     UseMethod(\"as.data.frame\") #> } #> <bytecode: 0x5651e264c410> #> <environment: namespace:base>  (toks <- tokenize(toy_corpus)) #> Token sequence of length 21 #> idx     token #> --- --------- #>   1      once #>   2      upon #>   3         a #>   4      time #>   5     there #>   6       was #>   7         a #>   8      tiny #>   9       toy #>  10    corpus #>  11        it #>  12 consisted #>  13        of #>  14     three #>  15 sentences #>  16       and #>  17        it #>  18     lived #>  19   happily #>  20      ever #> ... #>  as.data.frame(toks) #>        token #> 1       once #> 2       upon #> 3          a #> 4       time #> 5      there #> 6        was #> 7          a #> 8       tiny #> 9        toy #> 10    corpus #> 11        it #> 12 consisted #> 13        of #> 14     three #> 15 sentences #> 16       and #> 17        it #> 18     lived #> 19   happily #> 20      ever #> 21     after  (toks <- tokenize(toy_corpus)) #> Token sequence of length 21 #> idx     token #> --- --------- #>   1      once #>   2      upon #>   3         a #>   4      time #>   5     there #>   6       was #>   7         a #>   8      tiny #>   9       toy #>  10    corpus #>  11        it #>  12 consisted #>  13        of #>  14     three #>  15 sentences #>  16       and #>  17        it #>  18     lived #>  19   happily #>  20      ever #> ... #>  as.data.frame(toks) #>        token #> 1       once #> 2       upon #> 3          a #> 4       time #> 5      there #> 6        was #> 7          a #> 8       tiny #> 9        toy #> 10    corpus #> 11        it #> 12 consisted #> 13        of #> 14     three #> 15 sentences #> 16       and #> 17        it #> 18     lived #> 19   happily #> 20      ever #> 21     after"},{"path":"https://masterclm.github.io/mclm/reference/as_fnames.html","id":null,"dir":"Reference","previous_headings":"","what":"Coerce object to 'fnames' — as_fnames","title":"Coerce object to 'fnames' — as_fnames","text":"function coerces character vector object class fnames.","code":""},{"path":"https://masterclm.github.io/mclm/reference/as_fnames.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coerce object to 'fnames' — as_fnames","text":"","code":"as_fnames(x, remove_duplicates = TRUE, sort = TRUE, ...)"},{"path":"https://masterclm.github.io/mclm/reference/as_fnames.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coerce object to 'fnames' — as_fnames","text":"x character vector (freqlist object!) remove_duplicates Boolean. Whether duplicates removed. sort Boolean. Whether output sorted. ... Additional arguments.","code":""},{"path":"https://masterclm.github.io/mclm/reference/as_fnames.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coerce object to 'fnames' — as_fnames","text":"object class fnames.","code":""},{"path":"https://masterclm.github.io/mclm/reference/as_fnames.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coerce object to 'fnames' — as_fnames","text":"","code":"as_fnames(\"path/to/my/corpus_file\") #> Filename collection of length 1 #>                 filename #>   ---------------------- #> 1 path/to/my/corpus_file"},{"path":"https://masterclm.github.io/mclm/reference/as_freqlist.html","id":null,"dir":"Reference","previous_headings":"","what":"Coerce table to a frequency list — as_freqlist","title":"Coerce table to a frequency list — as_freqlist","text":"function coerces object class table object class freqlist.","code":""},{"path":"https://masterclm.github.io/mclm/reference/as_freqlist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coerce table to a frequency list — as_freqlist","text":"","code":"as_freqlist(x, tot_n_tokens = NULL, sort_by_ranks = TRUE)"},{"path":"https://masterclm.github.io/mclm/reference/as_freqlist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coerce table to a frequency list — as_freqlist","text":"x Object class table named numeric vector interpreted . tot_n_tokens Number representing total number tokens corpus frequency list derived. tot_n_tokens NULL, total number tokens taken sum frequencies x. sort_by_ranks Logical. TRUE, items frequency list sorted frequency rank. FALSE, items frequency list, depending input type, either sorted alphabetically sorted .","code":""},{"path":"https://masterclm.github.io/mclm/reference/as_freqlist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coerce table to a frequency list — as_freqlist","text":"object class freqlist, based class table. additional attributes methods : base print(), as_data_frame(), summary() sort, tibble::as_tibble(), interactive explore() method, various getters, including tot_n_tokens(), n_types(), n_tokens(), values also returned summary(), , subsetting methods keep_types(), keep_pos(), etc. including [] subsetting (see brackets). Additional manipulation functions include type_freqs() extract frequencies different items, freqlist_merge() combine frequency lists, freqlist_diff() subtract frequency list another. Objects class freqlist can saved file write_freqlist(); files can read read_freqlist().","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/as_freqlist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coerce table to a frequency list — as_freqlist","text":"","code":"toy_corpus <- \"Once upon a time there was a tiny toy corpus. It consisted of three sentences. And it lived happily ever after.\"  ## make frequency list in a roundabout way tokens <- tokenize(toy_corpus) flist <- as_freqlist(table(tokens)) flist #> Frequency list (types in list: 19, tokens in list: 21) #> rank      type abs_freq nrm_freq #> ---- --------- -------- -------- #>    1         a        2  952.381 #>    2        it        2  952.381 #>    3     after        1  476.190 #>    4       and        1  476.190 #>    5 consisted        1  476.190 #>    6    corpus        1  476.190 #>    7      ever        1  476.190 #>    8   happily        1  476.190 #>    9     lived        1  476.190 #>   10        of        1  476.190 #>   11      once        1  476.190 #>   12 sentences        1  476.190 #>   13     there        1  476.190 #>   14     three        1  476.190 #>   15      time        1  476.190 #>   16      tiny        1  476.190 #>   17       toy        1  476.190 #>   18      upon        1  476.190 #>   19       was        1  476.190  ## more direct procedure freqlist(toy_corpus, as_text = TRUE) #> Frequency list (types in list: 19, tokens in list: 21) #> rank      type abs_freq nrm_freq #> ---- --------- -------- -------- #>    1         a        2  952.381 #>    2        it        2  952.381 #>    3     after        1  476.190 #>    4       and        1  476.190 #>    5 consisted        1  476.190 #>    6    corpus        1  476.190 #>    7      ever        1  476.190 #>    8   happily        1  476.190 #>    9     lived        1  476.190 #>   10        of        1  476.190 #>   11      once        1  476.190 #>   12 sentences        1  476.190 #>   13     there        1  476.190 #>   14     three        1  476.190 #>   15      time        1  476.190 #>   16      tiny        1  476.190 #>   17       toy        1  476.190 #>   18      upon        1  476.190 #>   19       was        1  476.190  ## build frequency list from scratch: example 1 flist <- as_freqlist(c(\"a\" = 12, \"toy\" = 53, \"example\" = 20)) flist #> Frequency list (types in list: 3, tokens in list: 85) #> rank    type abs_freq nrm_freq #> ---- ------- -------- -------- #>    1     toy       53 6235.294 #>    2 example       20 2352.941 #>    3       a       12 1411.765  ## build frequency list from scratch: example 2 flist <- as_freqlist(c(\"a\" = 12, \"toy\" = 53, \"example\" = 20),                      tot_n_tokens = 1300) flist #> Frequency list (types in list: 3, tokens in list: 85) #> <total number of tokens: 1300> #> rank    type abs_freq nrm_freq #> ---- ------- -------- -------- #>    1     toy       53  407.692 #>    2 example       20  153.846 #>    3       a       12   92.308"},{"path":"https://masterclm.github.io/mclm/reference/as_numeric.html","id":null,"dir":"Reference","previous_headings":"","what":"Coerce object to a numeric vector — as_numeric","title":"Coerce object to a numeric vector — as_numeric","text":"generic method turns first argument x least part information numeric object. alternative notation base::.numeric().","code":""},{"path":"https://masterclm.github.io/mclm/reference/as_numeric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coerce object to a numeric vector — as_numeric","text":"","code":"as_numeric(x, ...)  # S3 method for default as_numeric(x, ...)"},{"path":"https://masterclm.github.io/mclm/reference/as_numeric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coerce object to a numeric vector — as_numeric","text":"x object coerce. ... Additional arguments.","code":""},{"path":"https://masterclm.github.io/mclm/reference/as_numeric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coerce object to a numeric vector — as_numeric","text":"numeric vector.","code":""},{"path":"https://masterclm.github.io/mclm/reference/as_numeric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coerce object to a numeric vector — as_numeric","text":"","code":"(flist <- freqlist(tokenize(\"The old story of the old man and the sea.\"))) #> Frequency list (types in list: 7, tokens in list: 10) #> rank  type abs_freq nrm_freq #> ---- ----- -------- -------- #>    1   the        3     3000 #>    2   old        2     2000 #>    3   and        1     1000 #>    4   man        1     1000 #>    5    of        1     1000 #>    6   sea        1     1000 #>    7 story        1     1000  # extract frequency counts from a frequency list as_numeric(flist) #> [1] 3 2 1 1 1 1 1 as.numeric(flist) #> [1] 3 2 1 1 1 1 1  # preferable alternative type_freqs(flist) #> [1] 3 2 1 1 1 1 1"},{"path":"https://masterclm.github.io/mclm/reference/as_tokens.html","id":null,"dir":"Reference","previous_headings":"","what":"Coerce object to class tokens — as_tokens","title":"Coerce object to class tokens — as_tokens","text":"function coerces character object another object can coerced character object class tokens.","code":""},{"path":"https://masterclm.github.io/mclm/reference/as_tokens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coerce object to class tokens — as_tokens","text":"","code":"as_tokens(x, ...)"},{"path":"https://masterclm.github.io/mclm/reference/as_tokens.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coerce object to class tokens — as_tokens","text":"x Object coerce. ... Additional arguments (implemented).","code":""},{"path":"https://masterclm.github.io/mclm/reference/as_tokens.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coerce object to class tokens — as_tokens","text":"object class tokens.","code":""},{"path":"https://masterclm.github.io/mclm/reference/as_tokens.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coerce object to class tokens — as_tokens","text":"","code":"toy_corpus <- \"Once upon a time there was a tiny toy corpus. It consisted of three sentences. And it lived happily ever after.\"  tks <- tokenize(toy_corpus) print(tks, n = 1000) #> Token sequence of length 21 #> idx     token #> --- --------- #>   1      once #>   2      upon #>   3         a #>   4      time #>   5     there #>   6       was #>   7         a #>   8      tiny #>   9       toy #>  10    corpus #>  11        it #>  12 consisted #>  13        of #>  14     three #>  15 sentences #>  16       and #>  17        it #>  18     lived #>  19   happily #>  20      ever #>  21     after  tks[3:12] #> Token sequence of length 10 #> idx     token #> --- --------- #>   1         a #>   2      time #>   3     there #>   4       was #>   5         a #>   6      tiny #>   7       toy #>   8    corpus #>   9        it #>  10 consisted print(as_tokens(tks[3:12]), n = 1000) #> Token sequence of length 10 #> idx     token #> --- --------- #>   1         a #>   2      time #>   3     there #>   4       was #>   5         a #>   6      tiny #>   7       toy #>   8    corpus #>   9        it #>  10 consisted as_tokens(tail(tks)) #> Token sequence of length 6 #> idx   token #> --- ------- #>   1     and #>   2      it #>   3   lived #>   4 happily #>   5    ever #>   6   after"},{"path":"https://masterclm.github.io/mclm/reference/as_types.html","id":null,"dir":"Reference","previous_headings":"","what":"Coerce object to a vector of types — as_types","title":"Coerce object to a vector of types — as_types","text":"function coerces object, character vector, object class types.","code":""},{"path":"https://masterclm.github.io/mclm/reference/as_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coerce object to a vector of types — as_types","text":"","code":"as_types(x, remove_duplicates = TRUE, sort = TRUE, ...)"},{"path":"https://masterclm.github.io/mclm/reference/as_types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coerce object to a vector of types — as_types","text":"x Object coerce remove_duplicates Logical. duplicates removed x prior coercing vector types. sort Logical. x alphabetically sorted prior coercing vector types; argument ignored remove_duplicates TRUE, result removing duplicates always sorted. ... Additional arguments (implemented)","code":""},{"path":"https://masterclm.github.io/mclm/reference/as_types.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coerce object to a vector of types — as_types","text":"object class types, based character vector. additional attributes methods : base print(), as_data_frame(), sort() base::summary() (returns number items unique items), tibble::as_tibble(), n_types() getter explore() method, subsetting methods keep_types(), keep_pos(), etc. including [] subsetting (see brackets). object class types can merged another means types_merge(), written file write_types() read file write_types().","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/as_types.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coerce object to a vector of types — as_types","text":"","code":"toy_corpus <- \"Once upon a time there was a tiny toy corpus. It consisted of three sentences. And it lived happily ever after.\"  flist <- freqlist(toy_corpus, re_token_splitter = \"\\\\W+\", as_text = TRUE) print(flist, n = 1000) #> Frequency list (types in list: 19, tokens in list: 21) #> rank      type abs_freq nrm_freq #> ---- --------- -------- -------- #>    1         a        2  952.381 #>    2        it        2  952.381 #>    3     after        1  476.190 #>    4       and        1  476.190 #>    5 consisted        1  476.190 #>    6    corpus        1  476.190 #>    7      ever        1  476.190 #>    8   happily        1  476.190 #>    9     lived        1  476.190 #>   10        of        1  476.190 #>   11      once        1  476.190 #>   12 sentences        1  476.190 #>   13     there        1  476.190 #>   14     three        1  476.190 #>   15      time        1  476.190 #>   16      tiny        1  476.190 #>   17       toy        1  476.190 #>   18      upon        1  476.190 #>   19       was        1  476.190 (sel_types <- as_types(c(\"happily\", \"lived\", \"once\"))) #> Type collection of length 3 #>      type #>   ------- #> 1 happily #> 2   lived #> 3    once keep_types(flist, sel_types) #> Frequency list (types in list: 3, tokens in list: 3) #> <total number of tokens: 21> #> rank orig_rank    type abs_freq nrm_freq #> ---- --------- ------- -------- -------- #>    1         8 happily        1   476.19 #>    2         9   lived        1   476.19 #>    3        11    once        1   476.19 tks <- tokenize(toy_corpus, re_token_splitter = \"\\\\W+\") print(tks, n = 1000) #> Token sequence of length 21 #> idx     token #> --- --------- #>   1      once #>   2      upon #>   3         a #>   4      time #>   5     there #>   6       was #>   7         a #>   8      tiny #>   9       toy #>  10    corpus #>  11        it #>  12 consisted #>  13        of #>  14     three #>  15 sentences #>  16       and #>  17        it #>  18     lived #>  19   happily #>  20      ever #>  21     after tks[3:12] # idx is relative to selection #> Token sequence of length 10 #> idx     token #> --- --------- #>   1         a #>   2      time #>   3     there #>   4       was #>   5         a #>   6      tiny #>   7       toy #>   8    corpus #>   9        it #>  10 consisted head(tks) # idx is relative to selection #> Token sequence of length 6 #> idx token #> --- ----- #>   1  once #>   2  upon #>   3     a #>   4  time #>   5 there #>   6   was tail(tks) # idx is relative to selection #> Token sequence of length 6 #> idx   token #> --- ------- #>   1     and #>   2      it #>   3   lived #>   4 happily #>   5    ever #>   6   after"},{"path":"https://masterclm.github.io/mclm/reference/assoc_scores.html","id":null,"dir":"Reference","previous_headings":"","what":"Association scores used in collocation analysis and keyword analysis — assoc_scores","title":"Association scores used in collocation analysis and keyword analysis — assoc_scores","text":"assoc_scores assoc_abcd take arguments co-occurrence frequencies number items return range association scores used collocation analysis, collostruction analysis keyword analysis.","code":""},{"path":"https://masterclm.github.io/mclm/reference/assoc_scores.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Association scores used in collocation analysis and keyword analysis — assoc_scores","text":"","code":"assoc_scores(   x,   y = NULL,   min_freq = 3,   measures = NULL,   with_variants = FALSE,   show_dots = FALSE,   p_fisher_2 = FALSE,   haldane = TRUE,   small_pos = 1e-05 )  assoc_abcd(   a,   b,   c,   d,   types = NULL,   measures = NULL,   with_variants = FALSE,   show_dots = FALSE,   p_fisher_2 = FALSE,   haldane = TRUE,   small_pos = 1e-05 )"},{"path":"https://masterclm.github.io/mclm/reference/assoc_scores.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Association scores used in collocation analysis and keyword analysis — assoc_scores","text":"x Either object class freqlist object class cooc_info. x freqlist, interpreted target frequency list (.e. list frequency items target context) y must freqlist frequency items reference context. x object class cooc_info instead, interpreted containing target frequency information, reference frequency information corpus size information. y object class freqlist frequencies reference context x also freqlist. x object class cooc_info, argument ignored. min_freq Minimum value [[]] (frequency item target frequency list) needed corresponding item included output. measures Character vector containing association measures (related quantities) scores requested. Supported measure names (related quantities) described Value . measures NULL, interpreted short default selection, .e. c(\"exp_a\", \"DP_rows\", \"RR_rows\", \"\", \"MS\", \"Dice\", \"PMI\", \"chi2_signed\", \"G_signed\", \"t\", \"fisher\"). measures \"\", supported measures calculated (necessarily variants; see with_variants). with_variants Logical. Whether, requested measures, variants included output (TRUE) main version (FALSE). See also p_fisher_2. show_dots Logical. Whether dot shown console time calculations measure finished. p_fisher_2 Logical. relevant \"fisher\" included measures. TRUE, p-value two-sided test (testing either attraction repulsion) also calculated. default, (computationally less demanding) p-value one-sided test calculated. See Value details. haldane Logical. Haldane-Anscombe correction used? (See Details section.) haldane TRUE, least one zero frequency contingency table, correction used measures calculated table, just measures need done. small_pos Alternative (sometimes inferior) approach dealing zero frequencies, compared haldane. argument small_pos applies haldane set FALSE. (See Details section.) haldane FALSE, least one zero frequency contingency table, adding small positive values zero frequency cells done systematically measures calculated table, just measures need done. Numeric vector expressing many times tested item occurs target context. specifically, [[]], integer, expresses many times -th tested item occurs target context. b Numeric vector expressing many times items tested item occur target context. specifically, b[[]], integer, expresses many times items -th tested item occur target context. c Numeric vector expressing many times tested item occurs reference context. specifically, c[[]], integer, expresses many times -th tested item occurs reference context. d Numeric vector expressing many times items tested item occur reference context. specifically, d[[]], integer, expresses many times items -th tested item occur reference context. types character vector containing names linguistic items association scores calculated, NULL. NULL, assoc_abcd() creates dummy types \"t001\", \"t002\", etc.","code":""},{"path":"https://masterclm.github.io/mclm/reference/assoc_scores.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Association scores used in collocation analysis and keyword analysis — assoc_scores","text":"object class assoc_scores. kind data frame rows items either target frequency list reference frequency list frequency larger min_freq target list, columns range measures express extent items attracted target context (compared reference context). columns contain actual measures rather additional information useful interpreting measures.","code":""},{"path":"https://masterclm.github.io/mclm/reference/assoc_scores.html","id":"possible-columns","dir":"Reference","previous_headings":"","what":"Possible columns","title":"Association scores used in collocation analysis and keyword analysis — assoc_scores","text":"following sections describe (possible) columns output. measures reported measures set \"\". Alternatively, measure can requested specifying name character vector given measures argument. Exceptions described sections .","code":""},{"path":"https://masterclm.github.io/mclm/reference/assoc_scores.html","id":"observed-and-expected-frequencies","dir":"Reference","previous_headings":"","what":"Observed and expected frequencies","title":"Association scores used in collocation analysis and keyword analysis — assoc_scores","text":", b, c, d: frequencies cells , b, c d, respectively. one 0, augmented 0.5 small_pos (see Details). output columns always present. dir: direction association: 1 case relative attraction tested item target context (\\(\\frac{}{m} \\ge \\frac{c}{n}\\)) -1 case relative repulsion target item target context (\\(\\frac{}{m} < {c}{n}\\)). exp_a, exp_b, exp_c, exp_d: expected values cells , b, c d, respectively. columns included \"expected\" measures. exp_a also one default measures therefore included measures NULL. values columns computed follows: exp_a = \\(\\frac{m \\times k}{N}\\) exp_b = \\(\\frac{m \\times l}{N}\\) exp_c = \\(\\frac{n \\times k}{N}\\) exp_d = \\(\\frac{n \\times l}{N}\\)","code":""},{"path":"https://masterclm.github.io/mclm/reference/assoc_scores.html","id":"effect-size-measures","dir":"Reference","previous_headings":"","what":"Effect size measures","title":"Association scores used in collocation analysis and keyword analysis — assoc_scores","text":"measures based proportions can therefore computed either rows columns contingency table. measure can requested , pairs measures can also requested first part name, indicated corresponding descriptions. DP_rows DP_cols: difference proportions, sometimes also called Delta-p (\\(\\Delta p\\)), rows columns respectively. columns present \"DP\" included measures. DP_rows also included measures NULL. calculated follows: DP_rows = \\(\\frac{}{m} - \\frac{c}{n}\\) DP_cols = \\(\\frac{}{k} - \\frac{b}{l}\\) perc_DIFF_rows perc_DIFF_cols: measures can seen normalized versions Delta-p, .e. essentially measures divided denominator multiplied 100. therefore express large difference proportions , relative reference proportion. multiplication 100 turns resulting 'relative difference proportion' percentage. columns present \"perc_DIFF\" included measures. calculated follows: perc_DIFF_rows = \\(100 * \\frac{(/ m) - (c / n)}{c / n}\\) perc_DIFF_cols = \\(100 * \\frac{(/ k) - (b / l)}{c / n}\\) DC_rows DC_cols: difference coefficient can seen normalized version Delta-p, .e. essentially dividing difference proportions sum proportions. columns present \"DC\" included measures. calculated follows: DC_rows = \\(\\frac{(/ m) - (c / n)}{(/ m) + (c / n)}\\) DC_cols = \\(\\frac{(/ k) - (b / l)}{(/ k) + (b / l)}\\) RR_rows RR_cols: Relative risk rows columns respectively. RR_rows represents large proportion target context , relative proportion reference context. columns present \"RR\" included measures. RR_rows also included measures NULL. calculated follows: RR_rows = \\(\\frac{/ m}{c / n}\\) RR_cols = \\(\\frac{/ k}{b / l}\\) LR_rows LR_cols: -called 'log ratio' rows columns, respectively. can seen transformed version relative risk, viz. binary log. columns present \"LR\" included measures. calculated follows: LR_rows = \\(\\log_2\\left(\\frac{/ m}{c / n}\\right)\\) LR_cols = \\(\\log_2\\left(\\frac{/ k}{b / l}\\right)\\) measures use contingency table different way therefore complementary row/column pair. order retrieve columns, measures \"\", name must measures vector. included default, .e. measures NULL. : odds ratio, can calculated either \\(\\frac{/b}{c/d}\\) \\(\\frac{/c}{b/d}\\). column present measures NULL. log_OR: log odds ratio, can calculated either \\(\\log\\left(\\frac{/b}{c/d}\\right)\\) \\(\\log\\left(\\frac{/c}{b/d}\\right)\\). words, natural log odds ratio. MS: minimum sensitivity, calculated \\(\\min(\\frac{}{m}, \\frac{}{k})\\). words, either \\(\\frac{}{m}\\) \\(\\frac{}{k}\\), whichever lowest. column present measures NULL. Jaccard: Jaccard index, calculated \\(\\frac{}{+ b + c}\\). expresses , frequency test item target context, relative b + c + d, .e. frequency contexts. Dice: Dice coefficient, calculated \\(\\frac{2a}{m + k}\\). expresses harmonic mean \\(\\frac{}{m}\\) \\(\\frac{}{k}\\) column present measures NULL. logDice: adapted version Dice coefficient. calculated \\(14 + \\log_2\\left(\\frac{2a}{m + k}\\right)\\). words, 14 plus binary log Dice coefficient. phi: phi coefficient (\\(\\phi\\)), calculated \\(\\frac{(\\times d) - (b \\times c)}{ \\sqrt{m \\times n \\times k \\times l}}\\). Q: Yule's Q, calculated \\(\\frac{(\\times d) - (b \\times c)}{(\\times d)(b \\times c)}\\). mu: measure mu (\\(\\mu\\)), calculated \\(\\frac{}{\\mathrm{exp\\_a}}\\) (see exp_a). PMI pos_PMI: (Positive) pointwise mutual information, can seen modification mu measure calculated \\(\\log_2\\left(\\frac{}{\\mathrm{exp\\_a}}\\right)\\). pos_PMI, negative values set 0. PMI column present measures NULL. PMI2 PMI3: Modified versions PMI aim give relatively weight cases relatively higher . However, modification, pure effect size measures . PMI2 = \\(\\log_2\\left(\\frac{^2}{\\mathrm{exp\\_a}}\\right)\\) PMI3 = \\(\\log_2\\left(\\frac{^3}{\\mathrm{exp\\_a}}\\right)\\)","code":""},{"path":"https://masterclm.github.io/mclm/reference/assoc_scores.html","id":"strength-of-evidence-measures","dir":"Reference","previous_headings":"","what":"Strength of evidence measures","title":"Association scores used in collocation analysis and keyword analysis — assoc_scores","text":"first measures section tend come triples: test statistic, p-value (preceded p_) signed version (followed _signed). test statistics indicate evidence either attraction repulsion. Thus, order indicate direction relationship, negative sign added \"signed\" version \\(\\frac{}{k} < \\frac{c}{l}\\). cases, name main measure (e.g. \"chi2\") /signed counterpart (e.g. \"chi2_signed\") must measures argument, measures must \"\", columns included output. main function requested, signed counterpart also included, signed counterpart requested, non-signed version excluded. p-value retrieved, either main measure signed version must requested , additionally, with_variants argument must set TRUE. chi2, p_chi2 chi2_signed: chi-squared test statistic (\\(\\chi^2\\)) used chi-squared test independence chi-squared test homogeneity two--two contingency table. Scores measure high strong evidence attraction, also strong evidence repulsion. chi2_signed column present measures NULL. chi2 calculated follows: $$                         \\frac{(-\\mathrm{exp\\_a})^2}{\\mathrm{exp\\_a}} +                         \\frac{(b-\\mathrm{exp\\_b})^2}{\\mathrm{exp\\_b}} +                         \\frac{(c-\\mathrm{exp\\_c})^2}{\\mathrm{exp\\_c}} +                         \\frac{(d-\\mathrm{exp\\_d})^2}{\\mathrm{exp\\_d}}                        $$. chi2_Y, p_chi2_Y chi2_Y_signed: chi-squared test statistic (\\(\\chi^2\\)) used chi-squared test Yates correction two--two contingency table. chi2_Y calculated follows: $$                         \\frac{(|-\\mathrm{exp\\_a}| - 0.5)^2}{\\mathrm{exp\\_a}} +                         \\frac{(|b-\\mathrm{exp\\_b}| - 0.5)^2}{\\mathrm{exp\\_b}} +                         \\frac{(|c-\\mathrm{exp\\_c}| - 0.5)^2}{\\mathrm{exp\\_c}} +                         \\frac{(|d-\\mathrm{exp\\_d}| - 0.5)^2}{\\mathrm{exp\\_d}}                        $$. chi2_2T, p_chi2_2T chi2_2T_signed: chi-squared test statistic (\\(\\chi^2\\)) used chi-squared goodness--fit test applied first column contingency table. \"2T\" name stands 'two terms' (opposed chi2, sometimes 'four terms' version). chi2_2T calculated follows: $$                         \\frac{(-\\mathrm{exp\\_a})^2}{\\mathrm{exp\\_a}} +                         \\frac{(c-\\mathrm{exp\\_c})^2}{\\mathrm{exp\\_c}}                        $$. chi2_2T_Y, p_chi2_2T_Y chi2_2T_Y_signed: chi-squared test statistic (\\(\\chi^2\\)) used chi-squared goodness--fit test Yates correction, applied first column contingency table. chi2_2T_Y calculated follows: $$                           \\frac{(|-\\mathrm{exp\\_a}| - 0.5)^2}{\\mathrm{exp\\_a}} +                           \\frac{(|c-\\mathrm{exp\\_c}| - 0.5)^2}{\\mathrm{exp\\_c}}                          $$. G, p_G G_signed: G test statistic, also sometimes called log-likelihood ratio (LLR) , somewhat confusingly, G-squared. test statistic used log-likelihood ratio test independence homogeneity two--two contingency table. Scores high case strong evidence attraction, also case strong evidence repulsion. G_signed column present measures NULL. G calculated follows: $$                   2 \\left(                   \\times \\log(\\frac{}{\\mathrm{exp\\_a}}) +                   b \\times \\log(\\frac{b}{\\mathrm{exp\\_b}}) +                   c \\times \\log(\\frac{c}{\\mathrm{exp\\_c}}) +                   d \\times \\log(\\frac{d}{\\mathrm{exp\\_d}})                   \\right)                  $$ G_2T, p_G_2T G_2T_signed: test statistic used log-likelihood ratio test goodness--fit applied first column contingency table. \"2T\" stands 'two terms'. G_2T calculated follows: $$                   2 \\left(                   \\times \\log(\\frac{}{\\mathrm{exp\\_a}}) +                   c \\times \\log(\\frac{c}{\\mathrm{exp\\_c}})                   \\right)                  $$ final two groups measures take different shape. _as_chisq1 columns compute qchisq(1 - p, 1), p p-values transforming, .e. p right quantile \\(\\chi^2\\) distribution one degree freedom (see p_to_chisq1()). t, p_t_1, t_1_as_chisq1, p_t_2 t_2_as_chisq1: t-test statistic, used t-test proportion \\(\\frac{}{N}\\) null hypothesis based \\(\\frac{k}{N}\\times\\frac{m}{N}\\). Column t present \"t\" included measures measures \"\" NULL. four columns present t requested , additionally, with_variants TRUE. t = \\(                    \\frac{                    /N + k/N + m/N                    }{                    \\sqrt{((/N)\\times (1-/N))/N}                    }                     \\) p_t_1 p-value corresponds t assuming one-tailed test looks attraction; t_1_as_chisq1 transformation. p_t_2 p-value corresponds t assuming two-tailed test, viz. looks attraction repulsion; t_2_as_chisq1 transformation. p_fisher_1, fisher_1_as_chisq1, p_fisher_1r, fisher_1r_as_chisq1: p-value one-sided Fisher exact test. column p_fisher_1 present either \"fisher\" \"p_fisher\" measures measures \"\" NULL. columns present p_fisher_1 requested , additionally, with_variants TRUE. p_fisher_1 p_fisher_1r p-values Fisher exact test look attraction repulsion respectively. fisher_1_as_chisq1 fisher_1r_as_chisq1 respective transformations.. p_fisher_2 fisher_2_as_chisq1: p-value two-sided Fisher exact test, viz. looking attraction repulsion. p_fisher_2 returns p-value fisher_2_as_chisq1 transformation. p_fisher_2 column present either \"fisher\" \"p_fisher_1\" measures measures \"\" NULL , additionally, p_fisher_2 TRUE. fisher_2_as_chisq1 present p_fisher_2 requested , additionally, with_variants TRUE.","code":""},{"path":"https://masterclm.github.io/mclm/reference/assoc_scores.html","id":"properties-of-the-class","dir":"Reference","previous_headings":"","what":"Properties of the class","title":"Association scores used in collocation analysis and keyword analysis — assoc_scores","text":"object class assoc_scores : associated .data.frame(), print(), sort() tibble::as_tibble() methods, interactive explore() method useful getters, viz. n_types() type_names(). object class can saved file write_assoc() read read_assoc().","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/assoc_scores.html","id":"input-and-output","dir":"Reference","previous_headings":"","what":"Input and output","title":"Association scores used in collocation analysis and keyword analysis — assoc_scores","text":"assoc_scores() takes arguments target frequency list reference frequency lists (either two freqlist objects cooc_info object) returns number popular measures expressing, (almost) every item either one lists, extent item attracted target context, compared reference context. \"almost\" added parentheses , default settings, items automatically excluded output (see min_freq). assoc_abcd() takes arguments four vectors , b, c, d, equal length. tuple values ([], b[], c[], d[]), integer number 1 length vectors, assumed represent four numbers , b, c, d contingency table type: table m, n, k, l N marginal frequencies. specifically, m = + b, n = c + d, k = + c, l = b + d N = m + n.","code":""},{"path":"https://masterclm.github.io/mclm/reference/assoc_scores.html","id":"dealing-with-zeros","dir":"Reference","previous_headings":"","what":"Dealing with zeros","title":"Association scores used in collocation analysis and keyword analysis — assoc_scores","text":"Several association measures break one values , b, c, d zero (instance, lead division zero taking log zero). can dealt different ways, Haldane-Anscombe correction. Strictly speaking, Haldane-Anscombe correction specifically applies context (log) odds ratios two--two tables boils adding 0.5 four values , b, c, d every two--two contingency table original values , b, c, d allow us calculate (log) odds ratio, happens one (one) four cells zero. Using Haldane-Anscombe correction, (log) odds ratio calculated bases 'corrected' values , b, c, d. However, measures compute (log) odds ratios might also break value zero, measures computed 'corrected' contingency matrix. haldane argument set FALSE, division zero taking log zero avoided systematically adding small positive value zero values , b, c, d. argument small_pos determines small positive value added cases. default value 0.00001.","code":""},{"path":"https://masterclm.github.io/mclm/reference/assoc_scores.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Association scores used in collocation analysis and keyword analysis — assoc_scores","text":"","code":"assoc_abcd(10 , 200, 100,  300, types = \"four\") #> Association scores (types in list: 1) #>   type  a    PMI G_signed|  b   c   d dir  exp_a DP_rows RR_rows   OR #> 1 four 10 -1.921  -45.432|200 100 300  -1 37.869  -0.202    0.19 0.15 #> <number of extra columns to the right: 5> #>  assoc_abcd(30, 1000,  14, 5000, types = \"fictitious\") #> Association scores (types in list: 1) #>         type  a PMI G_signed|   b  c    d dir exp_a DP_rows RR_rows #> 1 fictitious 30   2   56.959|1000 14 5000   1 7.498   0.026  10.431 #> <number of extra columns to the right: 6> #>  assoc_abcd(15, 5000,  16, 1000, types = \"toy\") #> Association scores (types in list: 1) #>   type  a    PMI G_signed|   b  c    d dir  exp_a DP_rows RR_rows    OR #> 1  toy 15 -0.781  -19.723|5000 16 1000  -1 25.778  -0.013    0.19 0.188 #> <number of extra columns to the right: 5> #>  assoc_abcd( 1,  300,   4, 6000, types = \"examples\") #> Association scores (types in list: 1) #>       type a   PMI G_signed|  b c    d dir exp_a DP_rows RR_rows OR #> 1 examples 1 2.067    1.473|300 4 6000   1 0.239   0.003   4.987  5 #> <number of extra columns to the right: 5> #>   a <- c(10,    30,    15,    1) b <- c(200, 1000,  5000,  300) c <- c(100,   14,    16,    4) d <- c(300, 5000, 10000, 6000) types <- c(\"four\", \"fictitious\", \"toy\", \"examples\") (scores <- assoc_abcd(a, b, c, d, types = types)) #> Association scores (types in list: 4) #>         type  a    PMI G_signed|   b   c     d dir  exp_a DP_rows #> 1       four 10 -1.921  -45.432| 200 100   300  -1 37.869  -0.202 #> 2 fictitious 30  2.000   56.959|1000  14  5000   1  7.498   0.026 #> 3        toy 15  0.536    2.984|5000  16 10000   1 10.343   0.001 #> 4   examples  1  2.067    1.473| 300   4  6000   1  0.239   0.003 #> <number of extra columns to the right: 7> #>   as_data_frame(scores) #>         type  a    b   c     d dir      exp_a      DP_rows    RR_rows       OR #> 1       four 10  200 100   300  -1 37.8688525 -0.202380952  0.1904762  0.15000 #> 2 fictitious 30 1000  14  5000   1  7.4983455  0.026334032 10.4313454 10.71429 #> 3        toy 15 5000  16 10000   1 10.3429579  0.001393583  1.8723829  1.87500 #> 4   examples  1  300   4  6000   1  0.2386994  0.002656037  4.9867110  5.00000 #>            MS        Dice        PMI chi2_signed   G_signed          t #> 1 0.047619048 0.062500000 -1.9210117  -38.158009 -45.431519 -8.8860423 #> 2 0.029126214 0.055865922  2.0003183   81.993003  56.958917  4.1184552 #> 3 0.002991027 0.005945303  0.5363137    3.153303   2.983872  1.2030435 #> 4 0.003322259 0.006535948  2.0667329    2.551819   1.473313  0.7613609 #>     p_fisher_1 #> 1 1.000000e+00 #> 2 6.106227e-14 #> 3 5.916695e-02 #> 4 2.170331e-01 as_tibble(scores) #> # A tibble: 4 × 17 #>   type           a     b     c     d   dir  exp_a  DP_rows RR_rows    OR      MS #>   <chr>      <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl>    <dbl>   <dbl> <dbl>   <dbl> #> 1 four          10   200   100   300    -1 37.9   -0.202     0.190  0.15 0.0476  #> 2 fictitious    30  1000    14  5000     1  7.50   0.0263   10.4   10.7  0.0291  #> 3 toy           15  5000    16 10000     1 10.3    0.00139   1.87   1.88 0.00299 #> 4 examples       1   300     4  6000     1  0.239  0.00266   4.99   5    0.00332 #> # … with 6 more variables: Dice <dbl>, PMI <dbl>, chi2_signed <dbl>, #> #   G_signed <dbl>, t <dbl>, p_fisher_1 <dbl>  print(scores, sort_order = \"PMI\") #> Association scores (types in list: 4, sort order criterion: PMI) #>         type  a    PMI G_signed|   b   c     d dir  exp_a DP_rows #> 1   examples  1  2.067    1.473| 300   4  6000   1  0.239   0.003 #> 2 fictitious 30  2.000   56.959|1000  14  5000   1  7.498   0.026 #> 3        toy 15  0.536    2.984|5000  16 10000   1 10.343   0.001 #> 4       four 10 -1.921  -45.432| 200 100   300  -1 37.869  -0.202 #> <number of extra columns to the right: 7> #>  print(scores, sort_order = \"alpha\") #> Association scores (types in list: 4, sort order criterion: alpha) #>         type  a    PMI G_signed|   b   c     d dir  exp_a DP_rows #> 1   examples  1  2.067    1.473| 300   4  6000   1  0.239   0.003 #> 2 fictitious 30  2.000   56.959|1000  14  5000   1  7.498   0.026 #> 3       four 10 -1.921  -45.432| 200 100   300  -1 37.869  -0.202 #> 4        toy 15  0.536    2.984|5000  16 10000   1 10.343   0.001 #> <number of extra columns to the right: 7> #>  print(scores, sort_order = \"none\") #> Association scores (types in list: 4) #>         type  a    PMI G_signed|   b   c     d dir  exp_a DP_rows #> 1       four 10 -1.921  -45.432| 200 100   300  -1 37.869  -0.202 #> 2 fictitious 30  2.000   56.959|1000  14  5000   1  7.498   0.026 #> 3        toy 15  0.536    2.984|5000  16 10000   1 10.343   0.001 #> 4   examples  1  2.067    1.473| 300   4  6000   1  0.239   0.003 #> <number of extra columns to the right: 7> #>  print(scores, sort_order = \"nonsense\") #> Association scores (types in list: 4) #>         type  a    PMI G_signed|   b   c     d dir  exp_a DP_rows #> 1       four 10 -1.921  -45.432| 200 100   300  -1 37.869  -0.202 #> 2 fictitious 30  2.000   56.959|1000  14  5000   1  7.498   0.026 #> 3        toy 15  0.536    2.984|5000  16 10000   1 10.343   0.001 #> 4   examples  1  2.067    1.473| 300   4  6000   1  0.239   0.003 #> <number of extra columns to the right: 7> #>   print(scores, sort_order = \"PMI\",       keep_cols = c(\"a\", \"exp_a\", \"PMI\", \"G_signed\")) #> Association scores (types in list: 4, sort order criterion: PMI) #>         type  a    PMI G_signed|   b   c     d dir  exp_a DP_rows #> 1   examples  1  2.067    1.473| 300   4  6000   1  0.239   0.003 #> 2 fictitious 30  2.000   56.959|1000  14  5000   1  7.498   0.026 #> 3        toy 15  0.536    2.984|5000  16 10000   1 10.343   0.001 #> 4       four 10 -1.921  -45.432| 200 100   300  -1 37.869  -0.202 #> <number of extra columns to the right: 7> #>  print(scores, sort_order = \"PMI\",       keep_cols = c(\"a\", \"b\", \"c\", \"d\", \"exp_a\", \"G_signed\")) #> Association scores (types in list: 4, sort order criterion: PMI) #>         type  a G_signed|   b   c     d dir  exp_a DP_rows RR_rows #> 1   examples  1    1.473| 300   4  6000   1  0.239   0.003   4.987 #> 2 fictitious 30   56.959|1000  14  5000   1  7.498   0.026  10.431 #> 3        toy 15    2.984|5000  16 10000   1 10.343   0.001   1.872 #> 4       four 10  -45.432| 200 100   300  -1 37.869  -0.202   0.190 #> <number of extra columns to the right: 6> #>  print(scores, sort_order = \"PMI\",      drop_cols = c(\"a\", \"b\", \"c\", \"d\", \"exp_a\", \"G_signed\",                     \"RR_rows\", \"chi2_signed\", \"t\")) #> Association scores (types in list: 4, sort order criterion: PMI) #>         type  a    PMI G_signed|   b   c     d dir  exp_a DP_rows #> 1   examples  1  2.067    1.473| 300   4  6000   1  0.239   0.003 #> 2 fictitious 30  2.000   56.959|1000  14  5000   1  7.498   0.026 #> 3        toy 15  0.536    2.984|5000  16 10000   1 10.343   0.001 #> 4       four 10 -1.921  -45.432| 200 100   300  -1 37.869  -0.202 #> <number of extra columns to the right: 7> #>"},{"path":"https://masterclm.github.io/mclm/reference/brackets.html","id":null,"dir":"Reference","previous_headings":"","what":"Subset an object by different criteria — brackets","title":"Subset an object by different criteria — brackets","text":"method can used subset objects based different criteria.","code":""},{"path":"https://masterclm.github.io/mclm/reference/brackets.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subset an object by different criteria — brackets","text":"","code":"# S3 method for fnames [(x, i, invert = FALSE, ...)  # S3 method for fnames [(x, i, invert = FALSE) <- value  # S3 method for freqlist [(x, i, invert = FALSE, ...)  # S3 method for tokens [(x, i, invert = FALSE, ...)  # S3 method for tokens [(x, i, invert = FALSE, ...) <- value  # S3 method for types [(x, i, invert = FALSE, ...)  # S3 method for types [(x, i, invert = FALSE) <- value"},{"path":"https://masterclm.github.io/mclm/reference/brackets.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Subset an object by different criteria — brackets","text":"x object classes method implemented. Selection criterion; depending class, behaves differently. invert Logical. Whether matches selected rather non-matches. ... Additional arguments. value Value assign.","code":""},{"path":"https://masterclm.github.io/mclm/reference/brackets.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Subset an object by different criteria — brackets","text":"Object class x selected elements .","code":""},{"path":"https://masterclm.github.io/mclm/reference/brackets.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Subset an object by different criteria — brackets","text":"subsetting method notation [], applied mclm objects, part family subsetting methods: see keep_pos(), keep_re(), keep_types() keep_bool(). case, argument selection criterion , depending class, method behaves different: providing re object equivalent calling keep_re(), providing numeric vector equivalent calling keep_pos(), providing logical vector equivalent calling keep_bool(), providing types object character vector equivalent calling keep_types(). notation x[, ...] used, also possible set invert argument TRUE (one additional arguments ...). invert argument serves purpose invert argument keep_ methods, turning drop_ method.","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/brackets.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Subset an object by different criteria — brackets","text":"","code":"# For a 'freqlist' object -------------------- (flist <- freqlist(\"The man and the mouse.\", as_text = TRUE)) #> Frequency list (types in list: 4, tokens in list: 5) #> rank  type abs_freq nrm_freq #> ---- ----- -------- -------- #>    1   the        2     4000 #>    2   and        1     2000 #>    3   man        1     2000 #>    4 mouse        1     2000  ## like keep_re() flist[re(\"[ao]\")] #> Frequency list (types in list: 3, tokens in list: 3) #> <total number of tokens: 5> #> rank orig_rank  type abs_freq nrm_freq #> ---- --------- ----- -------- -------- #>    1         2   and        1     2000 #>    2         3   man        1     2000 #>    3         4 mouse        1     2000 flist[re(\"[ao]\"), invert = TRUE] #> Frequency list (types in list: 1, tokens in list: 2) #> <total number of tokens: 5> #> rank orig_rank type abs_freq nrm_freq #> ---- --------- ---- -------- -------- #>    1         1  the        2     4000  ## like keep_pos() flist[type_freqs(flist) < 2] #> Frequency list (types in list: 3, tokens in list: 3) #> <total number of tokens: 5> #> rank orig_rank  type abs_freq nrm_freq #> ---- --------- ----- -------- -------- #>    1         2   and        1     2000 #>    2         3   man        1     2000 #>    3         4 mouse        1     2000 flist[ranks(flist) <= 3] #> Frequency list (types in list: 3, tokens in list: 4) #> <total number of tokens: 5> #> rank orig_rank type abs_freq nrm_freq #> ---- --------- ---- -------- -------- #>    1         1  the        2     4000 #>    2         2  and        1     2000 #>    3         3  man        1     2000 flist[ranks(flist) <= 3, invert = TRUE] #> Frequency list (types in list: 1, tokens in list: 1) #> <total number of tokens: 5> #> rank orig_rank  type abs_freq nrm_freq #> ---- --------- ----- -------- -------- #>    1         4 mouse        1     2000 flist[2:3] #> Frequency list (types in list: 2, tokens in list: 2) #> <total number of tokens: 5> #> rank orig_rank type abs_freq nrm_freq #> ---- --------- ---- -------- -------- #>    1         2  and        1     2000 #>    2         3  man        1     2000  ## like keep_bool() (flist2 <- keep_bool(flist, type_freqs(flist) < 2)) #> Frequency list (types in list: 3, tokens in list: 3) #> <total number of tokens: 5> #> rank orig_rank  type abs_freq nrm_freq #> ---- --------- ----- -------- -------- #>    1         2   and        1     2000 #>    2         3   man        1     2000 #>    3         4 mouse        1     2000 flist2[orig_ranks(flist2) > 2] #> Frequency list (types in list: 2, tokens in list: 2) #> <total number of tokens: 5> #> rank orig_rank  type abs_freq nrm_freq #> ---- --------- ----- -------- -------- #>    1         3   man        1     2000 #>    2         4 mouse        1     2000  ## like keep_types() flist[c(\"man\", \"and\")] #> Frequency list (types in list: 2, tokens in list: 2) #> <total number of tokens: 5> #> rank orig_rank type abs_freq nrm_freq #> ---- --------- ---- -------- -------- #>    2         3  man        1     2000 #>    1         2  and        1     2000 flist[as_types(c(\"man\", \"and\"))] #> Frequency list (types in list: 2, tokens in list: 2) #> <total number of tokens: 5> #> rank orig_rank type abs_freq nrm_freq #> ---- --------- ---- -------- -------- #>    1         2  and        1     2000 #>    2         3  man        1     2000  # For a 'types' object ----------------------- (tps <- as_types(letters[1:10])) #> Type collection of length 10 #>    type #>    ---- #>  1    a #>  2    b #>  3    c #>  4    d #>  5    e #>  6    f #>  7    g #>  8    h #>  9    i #> 10    j  tps[c(1, 3, 5, 7, 9)] #> Type collection of length 5 #>   type #>   ---- #> 1    a #> 2    c #> 3    e #> 4    g #> 5    i tps[c(TRUE, FALSE)] #> Type collection of length 5 #>   type #>   ---- #> 1    a #> 2    c #> 3    e #> 4    g #> 5    i tps[c(\"a\", \"c\", \"e\", \"g\", \"i\")] #> Type collection of length 5 #>   type #>   ---- #> 1    a #> 2    c #> 3    e #> 4    g #> 5    i  tps[c(1, 3, 5, 7, 9), invert = TRUE] #> Type collection of length 5 #>   type #>   ---- #> 1    b #> 2    d #> 3    f #> 4    h #> 5    j tps[c(TRUE, FALSE), invert = TRUE] #> Type collection of length 5 #>   type #>   ---- #> 1    b #> 2    d #> 3    f #> 4    h #> 5    j tps[c(\"a\", \"c\", \"e\", \"g\", \"i\"), invert = TRUE] #> Type collection of length 5 #>   type #>   ---- #> 1    b #> 2    d #> 3    f #> 4    h #> 5    j  # For a 'tokens' object ---------------------- (tks <- as_tokens(letters[1:10])) #> Token sequence of length 10 #> idx token #> --- ----- #>   1     a #>   2     b #>   3     c #>   4     d #>   5     e #>   6     f #>   7     g #>   8     h #>   9     i #>  10     j  tks[re(\"[acegi]\"), invert = TRUE] #> Token sequence of length 5 #> idx token #> --- ----- #>   1     b #>   2     d #>   3     f #>   4     h #>   5     j tks[c(1, 3, 5, 7, 9), invert = TRUE] #> Token sequence of length 5 #> idx token #> --- ----- #>   1     b #>   2     d #>   3     f #>   4     h #>   5     j tks[c(TRUE, FALSE), invert = TRUE] #> Token sequence of length 5 #> idx token #> --- ----- #>   1     b #>   2     d #>   3     f #>   4     h #>   5     j tks[c(\"a\", \"c\", \"e\", \"g\", \"i\"), invert = TRUE] #> Token sequence of length 5 #> idx token #> --- ----- #>   1     b #>   2     d #>   3     f #>   4     h #>   5     j"},{"path":"https://masterclm.github.io/mclm/reference/ca_help.html","id":null,"dir":"Reference","previous_headings":"","what":"Helpers for plotting ca objects — ca_help","title":"Helpers for plotting ca objects — ca_help","text":"functions row_pcoord() col_pcoord() retrieve coordinates rows columns ca object across dimensions. functions xlim4ca() ylim4ca() return range values first second dimensions.","code":""},{"path":"https://masterclm.github.io/mclm/reference/ca_help.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helpers for plotting ca objects — ca_help","text":"","code":"row_pcoord(x, ...)  col_pcoord(x, ...)  xlim4ca(x, ...)  ylim4ca(x, ...)"},{"path":"https://masterclm.github.io/mclm/reference/ca_help.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helpers for plotting ca objects — ca_help","text":"x object class ca. ... Additional arguments (implemented).","code":""},{"path":"https://masterclm.github.io/mclm/reference/ca_help.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helpers for plotting ca objects — ca_help","text":"matrix (row_pcoord() col_pcoord()) numeric vector (xlim4ca() ylim4ca()).","code":""},{"path":"https://masterclm.github.io/mclm/reference/ca_help.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Helpers for plotting ca objects — ca_help","text":"output row_pcoord(), row corresponds row dataframe ca::ca() applied , column corresponds principal component. output col_pcoord(), row corresponds column dataframe ca::ca() applied , column corresponds principal component.","code":""},{"path":"https://masterclm.github.io/mclm/reference/ca_help.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Helpers for plotting ca objects — ca_help","text":"row_pcoord(): Retrieve row principal coordinates dimensions col_pcoord(): Retrieve column principal coordinates dimensions xlim4ca(): Return range first dimension plotting ylim4ca(): Return range second dimension plotting","code":""},{"path":"https://masterclm.github.io/mclm/reference/ca_help.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Helpers for plotting ca objects — ca_help","text":"","code":"# traditional biplot from {ca}  library(ca) data(\"author\") author_ca <- ca(author) plot(author_ca)   # alternative plot with {mclm} tools r_pc <- row_pcoord(author_ca) c_pc <- col_pcoord(author_ca) xlim <- xlim4ca(author_ca) ylim <- ylim4ca(author_ca) author_names <- as.factor(gsub(                               \"^.*?\\\\((.*?)\\\\)$\", \"\\\\1\",                              rownames(author), perl = TRUE)) plot(r_pc[,1], r_pc[,2], pch = 18,     xlim = xlim, ylim = ylim, xlab = \"\", ylab = \"\",     main = \"authors and their alphabet\",     col = as.numeric(author_names)) abline(h = 0, col = \"gray\", lty = 3) abline(v = 0, col = \"gray\", lty = 3) text(c_pc[,1], c_pc[,2], colnames(author), col = \"gray\") legend(\"topright\",        legend = levels(author_names),        pch = rep(18, length(levels(author_names))),        col = 1:length(levels(author_names)),        title = \"authors\")"},{"path":"https://masterclm.github.io/mclm/reference/cat_re.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a regular expression to the console — cat_re","title":"Print a regular expression to the console — cat_re","text":"function cat_re() prints regular expression console. default, regular expression printed R string, `plain regular expression'. specifically, regular expression printed without surrounding quotation marks, characters special characters R strings (quotation marks backslashes) escaped backslash. Also, default, multi-line regular expressions printed single-line regular expressions regular expression comments removed.","code":""},{"path":"https://masterclm.github.io/mclm/reference/cat_re.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a regular expression to the console — cat_re","text":"","code":"cat_re(x, format = c(\"plain\", \"R\"), as_single_line = TRUE)"},{"path":"https://masterclm.github.io/mclm/reference/cat_re.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a regular expression to the console — cat_re","text":"x object class re character vector containing regular expression. x character vector length higher 1, first element used. format Character vector describing requested format (\"plain\" regular expression \"R\" string). length higher 1, first element used. as_single_line Logical. Whether x converted single line regular expression, therefore also removing comments, prior printing. length vector larger 1, first item used.","code":""},{"path":"https://masterclm.github.io/mclm/reference/cat_re.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print a regular expression to the console — cat_re","text":"Invisibly, x.","code":""},{"path":"https://masterclm.github.io/mclm/reference/cat_re.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print a regular expression to the console — cat_re","text":"WARNING: current implementation, way character # handled guaranteed correct. specifically, code guaranteed correctly distinguish # symbol introduces regular expression comment # symbol . Firstly, testing whether point encountering # free-spacing mode. Second, thorough testing whether # symbol part character class. However, # processed correctly long 'literal #' immediately preceded either backslash opening square bracket, `comment-introducing #' immediately preceded backslash opening square bracket.","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/cat_re.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print a regular expression to the console — cat_re","text":"","code":"# single-line regular expression x <- \"(?xi)  \\\\b \\\\w* willing \\\\w* \\\\b\" cat_re(x) #> (?xi) \\b \\w* willing \\w* \\b #>  y <- \"(?xi)          \\\\b        # word boundary         \\\\w*       # optional prefix        willing   # stem        \\\\w*       # optional suffix        \\\\b        # word boundary\" cat_re(y) #> (?xi) \\b \\w* willing \\w* \\b #>  cat_re(y, as_single_line = FALSE) #> (?xi)   #>        \\b        # word boundary  #>        \\w*       # optional prefix #>        willing   # stem #>        \\w*       # optional suffix #>        \\b        # word boundary #>  cat_re(y, format = \"R\") #> \"(?xi) \\\\b \\\\w* willing \\\\w* \\\\b\" #>  cat_re(y, format = \"R\", as_single_line = FALSE) #> \"(?xi)   #>        \\\\b        # word boundary  #>        \\\\w*       # optional prefix #>        willing   # stem #>        \\\\w*       # optional suffix #>        \\\\b        # word boundary\" #>   regex <- re(\"(?xi)                   \\\\b        # word boundary                  \\\\w*       # optional prefix                 willing   # stem                 \\\\w*       # optional suffix                 \\\\b        # word boundary\") cat_re(regex) #> (?xi) \\b \\w* willing \\w* \\b #>  cat_re(regex, as_single_line = FALSE) #> (?xi)   #>                 \\b        # word boundary  #>                 \\w*       # optional prefix #>                 willing   # stem #>                 \\w*       # optional suffix #>                 \\b        # word boundary #>"},{"path":"https://masterclm.github.io/mclm/reference/chisq1_to_p.html","id":null,"dir":"Reference","previous_headings":"","what":"Proportion of chi-squared distribution with one degree of freedom that sits to the right of x — chisq1_to_p","title":"Proportion of chi-squared distribution with one degree of freedom that sits to the right of x — chisq1_to_p","text":"Helper function takes argument numerical value x returns proportion p chi-squared distribution one degree freedom sits right value `x.","code":""},{"path":"https://masterclm.github.io/mclm/reference/chisq1_to_p.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Proportion of chi-squared distribution with one degree of freedom that sits to the right of x — chisq1_to_p","text":"","code":"chisq1_to_p(x)"},{"path":"https://masterclm.github.io/mclm/reference/chisq1_to_p.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Proportion of chi-squared distribution with one degree of freedom that sits to the right of x — chisq1_to_p","text":"x number.","code":""},{"path":"https://masterclm.github.io/mclm/reference/chisq1_to_p.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Proportion of chi-squared distribution with one degree of freedom that sits to the right of x — chisq1_to_p","text":"proportion p chi-squared distribution one degree freedom sits right value x.","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/cleanup_spaces.html","id":null,"dir":"Reference","previous_headings":"","what":"Clean up the use of whitespace in a character vector — cleanup_spaces","title":"Clean up the use of whitespace in a character vector — cleanup_spaces","text":"function cleanup_spaces() takes character vector input turns uninterrupted stretch whitespace characters one single space character. Moreover, can also remove leading whitespace trailing whitespace.","code":""},{"path":"https://masterclm.github.io/mclm/reference/cleanup_spaces.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clean up the use of whitespace in a character vector — cleanup_spaces","text":"","code":"cleanup_spaces(x, remove_leading = TRUE, remove_trailing = TRUE)"},{"path":"https://masterclm.github.io/mclm/reference/cleanup_spaces.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clean up the use of whitespace in a character vector — cleanup_spaces","text":"x Character vector. remove_leading Logical. TRUE, leading whitespace removed. remove_trailing Logical. TRUE, trailing whitespace removed.","code":""},{"path":"https://masterclm.github.io/mclm/reference/cleanup_spaces.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Clean up the use of whitespace in a character vector — cleanup_spaces","text":"character vector.","code":""},{"path":"https://masterclm.github.io/mclm/reference/cleanup_spaces.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Clean up the use of whitespace in a character vector — cleanup_spaces","text":"","code":"txt <- \"  A \\\\t  small      example \\\\n with redundant whitespace    \" cleanup_spaces(txt) #> [1] \"A \\\\t small example \\\\n with redundant whitespace\" cleanup_spaces(txt, remove_leading = FALSE, remove_trailing = FALSE) #> [1] \" A \\\\t small example \\\\n with redundant whitespace \""},{"path":"https://masterclm.github.io/mclm/reference/conc.html","id":null,"dir":"Reference","previous_headings":"","what":"Build a concordance for the matches of a regex — conc","title":"Build a concordance for the matches of a regex — conc","text":"function builds concordance matches regular expression. result dataset can written file function write_conc(). mimics behavior concordance tool program AntConc.","code":""},{"path":"https://masterclm.github.io/mclm/reference/conc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build a concordance for the matches of a regex — conc","text":"","code":"conc(   x,   pattern,   c_left = 200,   c_right = 200,   perl = TRUE,   re_drop_line = NULL,   line_glue = \"\\n\",   re_cut_area = NULL,   file_encoding = \"UTF-8\",   as_text = FALSE )"},{"path":"https://masterclm.github.io/mclm/reference/conc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build a concordance for the matches of a regex — conc","text":"x character vector determining text used corpus. as_text = TRUE, x treated actual text used corpus. as_text = FALSE (default), x treated vector filenames, interpreted names corpus files contain actual corpus data. pattern Character string containing regular expression serves search term concordancer. c_left Number. many characters left match must included result left co-text match. c_right Number. many characters right match must included result right co-text match. perl TRUE, pattern treated PCRE flavor regular expression. Otherwise, pattern treated regular expression R's default flavor regular expression. re_drop_line Character vector NULL. NULL, argument ignored. Otherwise, lines x containing match re_drop_line treated belonging corpus excluded results. line_glue Character vector NULL. NULL, argument ignored. Otherwise, lines corpus glued together one character vector length 1, string line_glue pasted consecutive lines. value line_glue can also equal empty string (\"\"). 'line_glue' operation conducted immediately 'drop line' operation. re_cut_area Character vector NULL. NULL, argument ignored. Otherwise, matches corpus 'cut ' text prior identification tokens text (therefore taken account identifying tokens). 'cut area' operation conducted immediately 'line glue' operation. file_encoding File encoding reading corpus file. Ignored as_text = TRUE. Otherwise, must character vector length one (case encoding used files) length x (case file can different encoding). as_text Logical. TRUE, content x treated actual text corpus (item within x treated separate 'document RAM'). FALSE, x treated vector filenames, interpreted names corpus files actual corpus data.","code":""},{"path":"https://masterclm.github.io/mclm/reference/conc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build a concordance for the matches of a regex — conc","text":"Object class conc, kind data frame rows matches following columns: glob_id: Number indicating position match overall list matches. id: Number indicating position match list matches one specific query. source: Either filename file match found (case setting as_text = FALSE), string '-' (case setting as_text = TRUE). left: left-hand side co-text match. match: actual match. right: right-hand side co-text match. also additional attributes methods : base as_data_frame() print() methods, well print_kwic() function, explore() method. object class conc can merged another means merge_conc(). can written file write_conc() read read_conc(). also possible import concordances created means write_conc() import_conc().","code":""},{"path":"https://masterclm.github.io/mclm/reference/conc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Build a concordance for the matches of a regex — conc","text":"order make sure columns left, match, right output conc contain TAB NEWLINE characters, whitespace items 'normalized'. particularly, stretch whitespace, .e.  uninterrupted sequences whitespace characters, replaced  single SPACE character. values items glob_id id output conc always identical dataset output function conc. item glob_id becomes useful later, instance, one wants merge two datasets.#'","code":""},{"path":"https://masterclm.github.io/mclm/reference/conc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build a concordance for the matches of a regex — conc","text":"","code":"(conc_data <- conc('A very small corpus.', '\\\\w+', as_text = TRUE)) #> Concordance-based data frame (number of observations: 4) #> idx                                           left|match |right              #>   1                                               |  A   |very small corpus. #>   2                                              A| very |small corpus.      #>   3                                         A very|small |corpus.            #>   4                                   A very small|corpus|.                  #>  #> This data frame has 6 columns: #>    column #> 1 glob_id #> 2      id #> 3  source #> 4    left #> 5   match #> 6   right print(conc_data) #> Concordance-based data frame (number of observations: 4) #> idx                                           left|match |right              #>   1                                               |  A   |very small corpus. #>   2                                              A| very |small corpus.      #>   3                                         A very|small |corpus.            #>   4                                   A very small|corpus|.                  #>  #> This data frame has 6 columns: #>    column #> 1 glob_id #> 2      id #> 3  source #> 4    left #> 5   match #> 6   right print_kwic(conc_data) #> idx                                           left|match |right              #>   1                                               |  A   |very small corpus. #>   2                                              A| very |small corpus.      #>   3                                         A very|small |corpus.            #>   4                                   A very small|corpus|."},{"path":"https://masterclm.github.io/mclm/reference/create_cooc.html","id":null,"dir":"Reference","previous_headings":"","what":"Build collocation frequencies. — create_cooc","title":"Build collocation frequencies. — create_cooc","text":"functions builds surface textual collocation frequency specific node.","code":""},{"path":"https://masterclm.github.io/mclm/reference/create_cooc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build collocation frequencies. — create_cooc","text":"","code":"surf_cooc(   x,   re_node,   w_left = 3,   w_right = 3,   re_boundary = NULL,   re_drop_line = NULL,   line_glue = NULL,   re_cut_area = NULL,   re_token_splitter = re(\"[^_\\\\p{L}\\\\p{N}\\\\p{M}'-]+\"),   re_token_extractor = re(\"[_\\\\p{L}\\\\p{N}\\\\p{M}'-]+\"),   re_drop_token = NULL,   re_token_transf_in = NULL,   token_transf_out = NULL,   token_to_lower = TRUE,   perl = TRUE,   blocksize = 300,   verbose = FALSE,   dot_blocksize = 10,   file_encoding = \"UTF-8\" )  text_cooc(   x,   re_node,   re_boundary = NULL,   re_drop_line = NULL,   line_glue = NULL,   re_cut_area = NULL,   re_token_splitter = re(\"[^_\\\\p{L}\\\\p{N}\\\\p{M}'-]+\"),   re_token_extractor = re(\"[_\\\\p{L}\\\\p{N}\\\\p{M}'-]+\"),   re_drop_token = NULL,   re_token_transf_in = NULL,   token_transf_out = NULL,   token_to_lower = TRUE,   perl = TRUE,   blocksize = 300,   verbose = FALSE,   dot_blocksize = 10,   file_encoding = \"UTF-8\" )"},{"path":"https://masterclm.github.io/mclm/reference/create_cooc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build collocation frequencies. — create_cooc","text":"x List filenames corpus files. re_node Regular expression used identifying instances 'node', .e. target item collocation information collected. w_left Number tokens left 'node' treated belonging co-text 'node'. (also see re_boundary.) w_right Number tokens right 'node' treated belonging co-text 'node'. (also see re_boundary.) re_boundary Regular expression. text_cooc(), identifies boundaries 'textual units'. surf_cooc(), identifies 'cut-' points co-text 'node'. NULL, maximum length left right co-texts still given w_left w_right, match re_boundary found within co-text, 'boundary token' tokens beyond excluded. re_drop_line Regular expression NULL. NULL, argument  ignored. Otherwise, lines corpus match treated belonging corpus excluded results. line_glue Character vector NULL. NULL, argument ignored. Otherwise, lines corpus glued together one character vector length 1, string line_glue pasted consecutive lines. value can also equal empty string \"\". 'line glue' operation conducted immediately 'drop line' operation. re_cut_area Regular expression NULL. NULL, argument  ignored. Otherwise, matches corpus 'cut ' text prior identification tokens therefore taken account identifying tokens. 'cut area' operation conducted immediately 'line glue' operation. re_token_splitter Regular expression NULL. NULL, argument ignored re_token_extractor used instead. Otherwise, identifies areas tokens within line corpus. 'token identification' operation conducted immediately 'cut area' operation. re_token_extractor Regular expression identifies locations actual tokens. used re_token_splitter NULL. Currently implementation argument lot less time-efficient re_token_splitter. 'token identification' operation conducted immediately 'cut area' operation. re_drop_token Regular expression NULL. NULL, argument ignored. Otherwise, identifies tokens excluded results. 'drop token' operation conducted immediately 'token identification' operation. re_token_transf_in regular expression identifies areas tokens transformed. argument works together token_transf_out. either NULL, ignored. Otherwise, matches tokens re_token_transf_in replaced replacement string token_transf_out. 'token transformation' operation conducted immediately 'drop token' transformation. token_transf_out 'replacement string'. argument works together re_token_transf_in ignored either argument NULL. token_to_lower Logical. Whether tokens converted lowercase returning results. 'token lower' operation conducted immediately 'token transformation' operation. perl Logical. Whether PCRE flavor regular expressions used arguments contain regular expressions. blocksize Number indicating many corpus files read memory 'individual step' steps procedure. Normally default value 300 changed, one works exceptionally small corpus files, may worthwhile use higher number, one works exceptionally large corpus files, may worthwhile use lower number. verbose Logical. TRUE, messages printed console indicate progress. dot_blocksize Logical. TRUE, dots printed console indicate progress. file_encoding Encoding input files. Either character vector length 1, case files assumed encoding, character vector length x, allows different encodings different files.","code":""},{"path":"https://masterclm.github.io/mclm/reference/create_cooc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build collocation frequencies. — create_cooc","text":"object class cooc_info, containing information co-occurrence frequencies.","code":""},{"path":"https://masterclm.github.io/mclm/reference/create_cooc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Build collocation frequencies. — create_cooc","text":"Two major steps can distinguished procedure conducted functions. first major step identification (sequence ) tokens , purpose analysis, considered content corpus. function arguments jointly determine details step re_drop_line, line_glue, re_cut_area, re_token_splitter, re_token_extractor, re_drop_token, re_token_transf_in, token_transf_out, token_to_lower. sequence tokens ultimate outcome step handed second major step procedure. second major step establishment co-occurrence frequencies. function arguments jointly determine details step re_node re_boundary functions, w_left w_right surf_cooc() . important know second step conducted tokens corpus identified, applied sequence tokens, original text. specifically regular expressions re_node re_boundary tested individual tokens, identified token identification procedure. Moreover, surf_cooc(), numbers w_left w_right also apply tokens identified token identification procedure.","code":""},{"path":"https://masterclm.github.io/mclm/reference/create_cooc.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Build collocation frequencies. — create_cooc","text":"surf_cooc(): Build surface collocation frequencies text_cooc(): Build textual collocation frequencies","code":""},{"path":"https://masterclm.github.io/mclm/reference/details.html","id":null,"dir":"Reference","previous_headings":"","what":"Details on a specific item — details","title":"Details on a specific item — details","text":"method zooms details object x based item y. x class slma (currently supported class), y must one lexical markers described .","code":""},{"path":"https://masterclm.github.io/mclm/reference/details.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Details on a specific item — details","text":"","code":"details(x, y, ...)  # S3 method for slma details(x, y, shorten_names = TRUE, ...)"},{"path":"https://masterclm.github.io/mclm/reference/details.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Details on a specific item — details","text":"x object containing global statistics collection linguistic units, object class slma. y character vector length one representing one linguistic item. ... Additional arguments. shorten_names Logical. TRUE, filenames rownames shortened short_names().","code":""},{"path":"https://masterclm.github.io/mclm/reference/details.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Details on a specific item — details","text":"object details. x class slma, class output details.slma, namely list following items: summary: row x$scores corresponding y. scores (printed default), dataframe one row per pair documents slma frequencies association scores chosen item columns. item: value y. sig_cutoff small_pos, defined slma.","code":""},{"path":"https://masterclm.github.io/mclm/reference/details.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Details on a specific item — details","text":"","code":"a_corp <- get_fnames(system.file(\"extdata\", \"cleveland\", package = \"mclm\")) b_corp <- get_fnames(system.file(\"extdata\", \"roosevelt\", package = \"mclm\")) slma_ex <- slma(a_corp, b_corp, keep_intermediate = TRUE) #> building global frequency list for x #> .... #> building separate frequency lists for each document #> .... #> ..... #> calculating assoc scores #> .................... #> calculating stability measures #> done  gov <- details(slma_ex, \"government\") gov$summary #>            S_abs S_nrm S_att S_rep    S_lor   lor_min  lor_max    lor_sd #> government    13  0.65    13     0 1.112098 0.7850339 3.172484 0.7982415  # A bit of tidy manipulation to shorten filenames if (require(\"dplyr\") && require(\"tidyr\")) {   as_tibble(gov, rownames = \"files\") %>%       tidyr::separate(files, into = c(\"file_A\", \"file_B\"), sep = \"--\") %>%       dplyr::mutate(dplyr::across(dplyr::starts_with(\"file\"), short_names)) }  #> Loading required package: dplyr #>  #> Attaching package: ‘dplyr’ #> The following object is masked from ‘package:mclm’: #>  #>     as_data_frame #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union #> Loading required package: tidyr #> # A tibble: 20 × 12 #>    file_A       file_B     a     b     c     d      G   sig   dir dir_sig log_OR #>    <chr>        <chr>  <dbl> <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl>   <dbl>  <dbl> #>  1 cleveland_s… roose…    16  1676    15  9761 23.2       1     1       1  1.83  #>  2 cleveland_s… roose…    16  1676     0   309  2.92      1     1      NA  1.81  #>  3 cleveland_s… roose…    16  1676     0  1212 14.3       1     1       1  3.17  #>  4 cleveland_s… roose…    16  1676    51 19558 15.9       1     1       1  1.30  #>  5 cleveland_s… roose…    16  1676     5  2607 11.9       1     1       1  1.60  #>  6 cleveland_s… roose…    10  1722    15  9761  9.14      1     1       1  1.33  #>  7 cleveland_s… roose…    10  1722     0   309  1.28      1     1      NA  1.33  #>  8 cleveland_s… roose…    10  1722     0  1212  7.98      1     1       1  2.69  #>  9 cleveland_s… roose…    10  1722    51 19558  4.45      1     1       1  0.801 #> 10 cleveland_s… roose…    10  1722     5  2607  4.40      1     1       1  1.11  #> 11 cleveland_s… roose…   113 19765    15  9761 31.3       1     1       1  1.31  #> 12 cleveland_s… roose…   113 19765     0   309  1.27      1     1      NA  1.27  #> 13 cleveland_s… roose…   113 19765     0  1212  9.91      1     1       1  2.63  #> 14 cleveland_s… roose…   113 19765    51 19558 23.3       1     1       1  0.785 #> 15 cleveland_s… roose…   113 19765     5  2607  8.07      1     1       1  1.09  #> 16 cleveland_s… roose…     4   823    15  9761  3.30      1     1      NA  1.15  #> 17 cleveland_s… roose…     4   823     0   309  0.915     1     1      NA  1.22  #> 18 cleveland_s… roose…     4   823     0  1212  5.40      1     1       1  2.58  #> 19 cleveland_s… roose…     4   823    51 19558  1.21      1     1      NA  0.623 #> 20 cleveland_s… roose…     4   823     5  2607  1.79      1     1      NA  0.930 #> # … with 1 more variable: log_OR_sig <dbl>"},{"path":"https://masterclm.github.io/mclm/reference/drop_empty_rc.html","id":null,"dir":"Reference","previous_headings":"","what":"Drop empty rows and columns from a matrix — drop_empty_rc","title":"Drop empty rows and columns from a matrix — drop_empty_rc","text":"x matrix containing frequency counts, drop_empty_rc makes copy x -zero rows -zero columns removed. checks performed function.","code":""},{"path":"https://masterclm.github.io/mclm/reference/drop_empty_rc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Drop empty rows and columns from a matrix — drop_empty_rc","text":"","code":"drop_empty_rc(x)"},{"path":"https://masterclm.github.io/mclm/reference/drop_empty_rc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Drop empty rows and columns from a matrix — drop_empty_rc","text":"x matrix, assumed contain frequency counts.","code":""},{"path":"https://masterclm.github.io/mclm/reference/drop_empty_rc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Drop empty rows and columns from a matrix — drop_empty_rc","text":"Matrix, -zero rows columns removed.","code":""},{"path":"https://masterclm.github.io/mclm/reference/drop_empty_rc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Drop empty rows and columns from a matrix — drop_empty_rc","text":"just convenience function. identical , implemented , x[rowSums(x) > 0, colSums(x) > 0, drop = FALSE].","code":""},{"path":"https://masterclm.github.io/mclm/reference/drop_empty_rc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Drop empty rows and columns from a matrix — drop_empty_rc","text":"","code":"# first example m <- matrix(nrow = 3, byrow = TRUE,             dimnames = list(c('r1','r2','r3'),                            c('c1','c2','c3')),            c(10, 0, 4,              0, 0, 0,              5, 0, 7))  m #>    c1 c2 c3 #> r1 10  0  4 #> r2  0  0  0 #> r3  5  0  7 m2 <- drop_empty_rc(m) m2 #>    c1 c3 #> r1 10  4 #> r3  5  7  ## second example m <- matrix(nrow = 3, byrow = TRUE,            dimnames = list(c('r1','r2','r3'),                           c('c1','c2','c3')),            c(0, 0, 4,              0, 0, 0,              0, 0, 7)) m #>    c1 c2 c3 #> r1  0  0  4 #> r2  0  0  0 #> r3  0  0  7 m2 <- drop_empty_rc(m) m2 #>    c3 #> r1  4 #> r3  7  ## third example m <- matrix(nrow = 3, byrow = TRUE,             dimnames = list(c('r1','r2','r3'),                             c('c1','c2','c3')),            c(0, 0, 0,              0, 0, 0,              0, 0, 0)) m #>    c1 c2 c3 #> r1  0  0  0 #> r2  0  0  0 #> r3  0  0  0 m2 <- drop_empty_rc(m) m2  #> <0 x 0 matrix>"},{"path":"https://masterclm.github.io/mclm/reference/drop_tags.html","id":null,"dir":"Reference","previous_headings":"","what":"Drop XML tags from character string — drop_tags","title":"Drop XML tags from character string — drop_tags","text":"function takes character vector returns copy XML-like tags removed. Moreover, half_tags_too = TRUE half tag beginning end x also removed.","code":""},{"path":"https://masterclm.github.io/mclm/reference/drop_tags.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Drop XML tags from character string — drop_tags","text":"","code":"drop_tags(x, half_tags_too = TRUE)"},{"path":"https://masterclm.github.io/mclm/reference/drop_tags.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Drop XML tags from character string — drop_tags","text":"x String XML tag half_tags_too Logical. Whether tags opening/closing bracket also removed.","code":""},{"path":"https://masterclm.github.io/mclm/reference/drop_tags.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Drop XML tags from character string — drop_tags","text":"Character string","code":""},{"path":"https://masterclm.github.io/mclm/reference/drop_tags.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Drop XML tags from character string — drop_tags","text":"function XML-aware. uses simple definition counts tag. specifically, character sequence starting < ending > considered 'tag'; inside tag, < >, drop_tags() accepts sequence zero characters.","code":""},{"path":"https://masterclm.github.io/mclm/reference/drop_tags.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Drop XML tags from character string — drop_tags","text":"","code":"xml_snippet <- \"id='3'/><w pos='Det'>An<\/w> <w pos='N'>example<\/w> <w\" drop_tags(xml_snippet) #> [1] \"An example \" drop_tags(xml_snippet, half_tags_too = FALSE) #> [1] \"id='3'/>An example <w\""},{"path":"https://masterclm.github.io/mclm/reference/explore.html","id":null,"dir":"Reference","previous_headings":"","what":"Interactively navigate through an object — explore","title":"Interactively navigate through an object — explore","text":"method works interactive R session open 'exploration mode', user can navigate object x means brief commands.","code":""},{"path":"https://masterclm.github.io/mclm/reference/explore.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interactively navigate through an object — explore","text":"","code":"explore(x, ...)  # S3 method for assoc_scores explore(   x,   n = 20,   from = 1,   from_col = 1,   perl = TRUE,   sort_order = c(\"none\", \"G_signed\", \"PMI\", \"alpha\"),   use_clear = TRUE,   ... )  # S3 method for conc explore(x, n = 20, from = 1, use_clear = TRUE, ...)  # S3 method for fnames explore(x, n = 20, from = 1, perl = TRUE, use_clear = TRUE, ...)  # S3 method for freqlist explore(x, n = 20, from = 1, perl = TRUE, use_clear = TRUE, ...)  # S3 method for tokens explore(x, n = 20, from = 1, perl = TRUE, use_clear = TRUE, ...)  # S3 method for types explore(x, n = 20, from = 1, perl = TRUE, use_clear = TRUE, ...)"},{"path":"https://masterclm.github.io/mclm/reference/explore.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Interactively navigate through an object — explore","text":"x object classes method implemented. ... Additional arguments. n Maximum number items object printed . Index first item printed. from_col Index first column displayed regular area (among selected columns, including frozen columns). from_col points perl Logical. Whether regular expressions used exploration session use PERL flavor regular expression. sort_order Order items printed. general, possible values \"alpha\" (meaning items sorted alphabetically), \"none\" (meaning items sorted). x object class assoc_scores, column name vector column names may provided instead. use_clear Logical. TRUE, feature supported R environment, console cleared interactive steps exploration session.","code":""},{"path":"https://masterclm.github.io/mclm/reference/explore.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Interactively navigate through an object — explore","text":"Invisibly, x.","code":""},{"path":"https://masterclm.github.io/mclm/reference/explore.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Interactively navigate through an object — explore","text":"explore() different R instructions automatically stop executing show new regular prompt (>) console. Instead shows special prompt (>>) can use explore()-specific commands. Note special prompt >> none regular R instructions work. instructions work prompt, explore(), listed . instruction user must press ENTER. b (begin): first items x shown. e (end): last items x shown. d (n items): 'next page' items shown. u (n items): 'previous page' items shown. n (next item): list/table shifts one item list. p (previous item): list/table shifts one item list. g {linenumber} (go ...): Jump line {linenumber}. E.g. g 1000 jump 1000th line. f {regex} (find...): Jump next item matching regular expression {regex}. E.g. f (?xi) astic $ jump next item ending \"astic\". software starts searching second item presently visible onward. f jump next item matching last regular expression used f {regex}. command available x conc object. l (left): assoc_scores objects, move one column left. r (right): assoc_scores objects, move one column right. ?: help page displayed, showing possible commands. q (quit): Terminate interactive session.","code":""},{"path":"https://masterclm.github.io/mclm/reference/find_xpath.html","id":null,"dir":"Reference","previous_headings":"","what":"Run XPath query — find_xpath","title":"Run XPath query — find_xpath","text":"function finds matches XPath query corpus.","code":""},{"path":"https://masterclm.github.io/mclm/reference/find_xpath.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run XPath query — find_xpath","text":"","code":"find_xpath(x, pattern, fun = NULL, final_fun = NULL, namespaces = NULL, ...)"},{"path":"https://masterclm.github.io/mclm/reference/find_xpath.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run XPath query — find_xpath","text":"x corpus: fnames object, character vector XML source, document parsed xml2::read_xml(). pattern XPath query. fun Function applied individual nodes prior returning result. final_fun Function applied complete list matches prior returning result. namespaces namespace generated xml2::xml_ns(). ... Additional arguments.","code":""},{"path":"https://masterclm.github.io/mclm/reference/find_xpath.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run XPath query — find_xpath","text":"nodeset output applying fun nodeset.","code":""},{"path":"https://masterclm.github.io/mclm/reference/find_xpath.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run XPath query — find_xpath","text":"","code":"test_xml <- ' <p>   <w pos=\"at\">The<\/w>   <w pos=\"nn\">example<\/w>   <punct>.<\/punct> <\/p>'  find_xpath(test_xml, \"//w\") #> {xml_nodeset (2)} #> [1] <w pos=\"at\">The<\/w> #> [2] <w pos=\"nn\">example<\/w> find_xpath(test_xml, \"//@pos\") #> {xml_nodeset (2)} #> [1]  pos=\"at\" #> [2]  pos=\"nn\" find_xpath(test_xml, \"//w[@pos='nn']\") #> {xml_nodeset (1)} #> [1] <w pos=\"nn\">example<\/w>  find_xpath(test_xml, \"//w\", fun = xml2::xml_text) #> [1] \"The\"     \"example\" find_xpath(test_xml, \"//w\", fun = xml2::xml_attr, attr = \"pos\") #> [1] \"at\" \"nn\""},{"path":"https://masterclm.github.io/mclm/reference/fnames.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve the names of files in a given path — fnames","title":"Retrieve the names of files in a given path — fnames","text":"Build object class fnames.","code":""},{"path":"https://masterclm.github.io/mclm/reference/fnames.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve the names of files in a given path — fnames","text":"","code":"get_fnames(   path = \".\",   re_pattern = NULL,   recursive = TRUE,   perl = TRUE,   invert = FALSE )"},{"path":"https://masterclm.github.io/mclm/reference/fnames.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve the names of files in a given path — fnames","text":"path location files listed. re_pattern Optional regular expression. present, filenames match retrieved (unless invert = TRUE, case filenames excluded). match done absolute path files. recursive Boolean value. subdirectories path also searched? perl Boolean value. Whether re_pattern interpreted PERL flavor regular expression. invert Boolean value. TRUE, filenames matching re_pattern ones retrieved. FALSE, filenames matching re_pattern excluded.","code":""},{"path":"https://masterclm.github.io/mclm/reference/fnames.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve the names of files in a given path — fnames","text":"object class fnames, special kind character vector storing absolute paths corpus files. additional attributes methods : base print(), as_data_frame(), sort() summary() (returns number items unique items), tibble::as_tibble(), interactive explore() method, function get number items n_fnames(), subsetting methods keep_types(), keep_pos(), etc. including [] subsetting (see brackets), well specific functions keep_fnames() drop_fnames(). Additional manipulation functions includes fnames_merge() combine filenames collections short_names() family functions shorten names. Objects class fnames can saved file write_fnames(); files can read read_fnames(). possible coerce character vector fnames object as_fnames().","code":""},{"path":"https://masterclm.github.io/mclm/reference/fnames.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve the names of files in a given path — fnames","text":"","code":"if (FALSE) { cwd_fnames <- get_fnames(recursive = FALSE) } cwd_fnames <- as_fnames(c(\"file1\", \"file2\", \"file3\")) cwd_fnames #> Filename collection of length 3 #>   filename #>   -------- #> 1    file1 #> 2    file2 #> 3    file3 print(cwd_fnames) #> Filename collection of length 3 #>   filename #>   -------- #> 1    file1 #> 2    file2 #> 3    file3 as_data_frame(cwd_fnames) #> Warning: `as_data_frame()` was deprecated in tibble 2.0.0. #> Please use `as_tibble()` instead. #> The signature and semantics have changed, see `?as_tibble`. #> # A tibble: 3 × 1 #>   filename #>   <fnames> #> 1 file1    #> 2 file2    #> 3 file3    as_tibble(cwd_fnames) #> # A tibble: 3 × 1 #>   filename #>   <fnames> #> 1 file1    #> 2 file2    #> 3 file3     sort(cwd_fnames) #> Filename collection of length 3 #>   filename #>   -------- #> 1    file1 #> 2    file2 #> 3    file3  summary(cwd_fnames) #> Filename collection of length 3"},{"path":"https://masterclm.github.io/mclm/reference/freqlist.html","id":null,"dir":"Reference","previous_headings":"","what":"Build the frequency list of a corpus — freqlist","title":"Build the frequency list of a corpus — freqlist","text":"function builds word frequency list corpus.","code":""},{"path":"https://masterclm.github.io/mclm/reference/freqlist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build the frequency list of a corpus — freqlist","text":"","code":"freqlist(   x,   re_drop_line = NULL,   line_glue = NULL,   re_cut_area = NULL,   re_token_splitter = re(\"[^_\\\\p{L}\\\\p{N}\\\\p{M}'-]+\"),   re_token_extractor = re(\"[_\\\\p{L}\\\\p{N}\\\\p{M}'-]+\"),   re_drop_token = NULL,   re_token_transf_in = NULL,   token_transf_out = NULL,   token_to_lower = TRUE,   perl = TRUE,   blocksize = 300,   verbose = FALSE,   show_dots = FALSE,   dot_blocksize = 10,   file_encoding = \"UTF-8\",   ngram_size = NULL,   max_skip = 0,   ngram_sep = \"_\",   ngram_n_open = 0,   ngram_open = \"[]\",   as_text = FALSE )"},{"path":"https://masterclm.github.io/mclm/reference/freqlist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build the frequency list of a corpus — freqlist","text":"x Either list filenames corpus files (as_text TRUE) actual text corpus (as_text FALSE). as_text TRUE length vector x higher one, item x treated separate line (separate series lines) corpus text. Within item x, character \"\\\\n\" also treated line separator. re_drop_line NULL character vector. NULL, ignored. Otherwise, character vector (assumed length 1) containing regular expression. Lines x contain match re_drop_line treated belonging corpus excluded results. line_glue NULL character vector. NULL, ignored. Otherwise, lines corpus file (x, as_text TRUE), glued together one character vector length 1, string line_glue pasted consecutive lines. value line_glue can also equal empty string \"\". 'line glue' operation conducted immediately 'drop line' operation. re_cut_area NULL character vector. NULL, ignored. Otherwise, matches corpus file (x, as_text TRUE), 'cut ' text prior identification tokens text (therefore taken account identifying tokens). 'cut area' operation conducted immediately 'line glue' operation. re_token_splitter Regular expression NULL. Regular expression identifies locations lines corpus files split tokens. (See Details.) 'token identification' operation conducted immediately 'cut area' operation. re_token_extractor Regular expression identifies locations actual tokens. argument used re_token_splitter NULL. (See Details.) 'token identification' operation conducted immediately 'cut area' operation. re_drop_token Regular expression NULL. NULL, ignored. Otherwise, identifies tokens excluded results. token contains match re_drop_token removed results. 'drop token' operation conducted immediately 'token identification' operation. re_token_transf_in Regular expression identifies areas tokens transformed. argument works together argument token_transf_out. re_token_transf_in token_transf_out differ NA, matches, tokens, regular expression  re_token_transf_in replaced replacement string token_transf_out. 'token transformation' operation conducted immediately 'drop token' operation. token_transf_out Replacement string. argument works together re_token_transf_in ignored re_token_transf_in NULL NA. token_to_lower Logical. Whether tokens must converted lowercase returning result. 'token lower' operation conducted immediately 'token transformation' operation. perl Logical. Whether PCRE regular expression flavor used arguments contain regular expressions. blocksize Number indicates many corpus files read memory individual step' steps procedure; normally default value 300` changed, one works exceptionally small corpus files, may worthwhile use higher number, one works exceptionally large corpus files, may worthwhile use lower number. verbose IfTRUE, messages printed console indicate progress. show_dots, dot_blocksize TRUE, dots printed console indicate progress. file_encoding File encoding assumed corpus files. ngram_size Argument support ngrams/skipgrams (see also max_skip). one wants identify individual tokens, value ngram_size NULL 1. one wants retrieve token ngrams/skipgrams, ngram_size integer indicating size ngrams/skipgrams. E.g. 2 bigrams, 3 trigrams, etc. max_skip Argument support skipgrams. argument ignored ngram_size NULL 1. ngram_size 2 higher, max_skip 0, regular ngrams retrieved (albeit may contain open slots; see ngram_n_open). ngram_size 2 higher, max_skip 1 higher, skipgrams retrieved (current implementation contain open slots; see ngram_n_open). instance, ngram_size 3 max_skip 2, 2-skip trigrams retrieved. ngram_size 5 max_skip 3, 3-skip 5-grams retrieved. ngram_sep Character vector length 1 containing string used separate/link tokens representation ngrams/skipgrams output function. ngram_n_open ngram_size 2 higher, moreover ngram_n_open number higher 0, ngrams 'open slots' retrieved. ngrams 'open slots' generalizations fully lexically specific ngrams (generalization one items ngram replaced notation stands 'arbitrary token'). instance, ngram_size 4 ngram_n_open 1, moreover input contains 4-gram \"it_is_widely_accepted\", output contain modifications \"it_is_widely_accepted\" one (since ngram_n_open 1) items n-gram replaced open slot. first last item inside ngram never turned open slot; items candidates turned open slots. Therefore, example, output contain \"it_[]_widely_accepted\" \"it_is_[]_accepted\". second example, ngram_size 5 ngram_n_open 2, moreover input contains 5-gram \"it_is_widely_accepted_that\", output contain \"it_[]_[]_accepted_that\", \"it_[]_widely_[]_that\", \"it_is_[]_[]_that\". ngram_open Character string used represent open slots ngrams output function. as_text Logical. Whether x interpreted character vector containing actual contents corpus (as_text TRUE) character vector containing names corpus files (as_text FALSE). as_text TRUE, arguments blocksize, verbose, show_dots, dot_blocksize, file_encoding ignored.","code":""},{"path":"https://masterclm.github.io/mclm/reference/freqlist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build the frequency list of a corpus — freqlist","text":"object class freqlist, based class table. additional attributes methods : base print(), as_data_frame(), summary() sort, tibble::as_tibble(), interactive explore() method, various getters, including tot_n_tokens(), n_types(), n_tokens(), values also returned summary(), , subsetting methods keep_types(), keep_pos(), etc. including [] subsetting (see brackets). Additional manipulation functions include type_freqs() extract frequencies different items, freqlist_merge() combine frequency lists, freqlist_diff() subtract frequency list another. Objects class freqlist can saved file write_freqlist(); files can read read_freqlist().","code":""},{"path":"https://masterclm.github.io/mclm/reference/freqlist.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Build the frequency list of a corpus — freqlist","text":"actual token identification either based re_token_splitter argument, regular expression identifies areas tokens, re_token_extractor, regular expression identifies area tokens. first mechanism default mechanism: argument re_token_extractor used re_token_splitter NULL. Currently implementation re_token_extractor lot less time-efficient re_token_splitter.","code":""},{"path":"https://masterclm.github.io/mclm/reference/freqlist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build the frequency list of a corpus — freqlist","text":"","code":"toy_corpus <- \"Once upon a time there was a tiny toy corpus. It consisted of three sentences. And it lived happily ever after.\"  (flist <- freqlist(toy_corpus, as_text = TRUE)) #> Frequency list (types in list: 19, tokens in list: 21) #> rank      type abs_freq nrm_freq #> ---- --------- -------- -------- #>    1         a        2  952.381 #>    2        it        2  952.381 #>    3     after        1  476.190 #>    4       and        1  476.190 #>    5 consisted        1  476.190 #>    6    corpus        1  476.190 #>    7      ever        1  476.190 #>    8   happily        1  476.190 #>    9     lived        1  476.190 #>   10        of        1  476.190 #>   11      once        1  476.190 #>   12 sentences        1  476.190 #>   13     there        1  476.190 #>   14     three        1  476.190 #>   15      time        1  476.190 #>   16      tiny        1  476.190 #>   17       toy        1  476.190 #>   18      upon        1  476.190 #>   19       was        1  476.190 print(flist, n = 20) #> Frequency list (types in list: 19, tokens in list: 21) #> rank      type abs_freq nrm_freq #> ---- --------- -------- -------- #>    1         a        2  952.381 #>    2        it        2  952.381 #>    3     after        1  476.190 #>    4       and        1  476.190 #>    5 consisted        1  476.190 #>    6    corpus        1  476.190 #>    7      ever        1  476.190 #>    8   happily        1  476.190 #>    9     lived        1  476.190 #>   10        of        1  476.190 #>   11      once        1  476.190 #>   12 sentences        1  476.190 #>   13     there        1  476.190 #>   14     three        1  476.190 #>   15      time        1  476.190 #>   16      tiny        1  476.190 #>   17       toy        1  476.190 #>   18      upon        1  476.190 #>   19       was        1  476.190 as.data.frame(flist) #>    rank      type abs_freq nrm_freq #> 1     1         a        2 952.3810 #> 2     2        it        2 952.3810 #> 3     3     after        1 476.1905 #> 4     4       and        1 476.1905 #> 5     5 consisted        1 476.1905 #> 6     6    corpus        1 476.1905 #> 7     7      ever        1 476.1905 #> 8     8   happily        1 476.1905 #> 9     9     lived        1 476.1905 #> 10   10        of        1 476.1905 #> 11   11      once        1 476.1905 #> 12   12 sentences        1 476.1905 #> 13   13     there        1 476.1905 #> 14   14     three        1 476.1905 #> 15   15      time        1 476.1905 #> 16   16      tiny        1 476.1905 #> 17   17       toy        1 476.1905 #> 18   18      upon        1 476.1905 #> 19   19       was        1 476.1905 as_tibble(flist) #> # A tibble: 19 × 4 #>     rank type      abs_freq nrm_freq #>    <dbl> <chr>        <dbl>    <dbl> #>  1     1 a                2     952. #>  2     2 it               2     952. #>  3     3 after            1     476. #>  4     4 and              1     476. #>  5     5 consisted        1     476. #>  6     6 corpus           1     476. #>  7     7 ever             1     476. #>  8     8 happily          1     476. #>  9     9 lived            1     476. #> 10    10 of               1     476. #> 11    11 once             1     476. #> 12    12 sentences        1     476. #> 13    13 there            1     476. #> 14    14 three            1     476. #> 15    15 time             1     476. #> 16    16 tiny             1     476. #> 17    17 toy              1     476. #> 18    18 upon             1     476. #> 19    19 was              1     476. summary(flist)  #> Frequency list (types in list: 19, tokens in list: 21) print(summary(flist)) #> Frequency list (types in list: 19, tokens in list: 21)  t_splitter <- \"(?xi) [:\\\\s.;,?!\\\"]+\" freqlist(toy_corpus,          re_token_splitter = t_splitter,          as_text = TRUE) #> Frequency list (types in list: 19, tokens in list: 21) #> rank      type abs_freq nrm_freq #> ---- --------- -------- -------- #>    1         a        2  952.381 #>    2        it        2  952.381 #>    3     after        1  476.190 #>    4       and        1  476.190 #>    5 consisted        1  476.190 #>    6    corpus        1  476.190 #>    7      ever        1  476.190 #>    8   happily        1  476.190 #>    9     lived        1  476.190 #>   10        of        1  476.190 #>   11      once        1  476.190 #>   12 sentences        1  476.190 #>   13     there        1  476.190 #>   14     three        1  476.190 #>   15      time        1  476.190 #>   16      tiny        1  476.190 #>   17       toy        1  476.190 #>   18      upon        1  476.190 #>   19       was        1  476.190           freqlist(toy_corpus,          re_token_splitter = t_splitter,          token_to_lower = FALSE,          as_text = TRUE) #> Frequency list (types in list: 20, tokens in list: 21) #> rank      type abs_freq nrm_freq #> ---- --------- -------- -------- #>    1         a        2  952.381 #>    2       And        1  476.190 #>    3        It        1  476.190 #>    4      Once        1  476.190 #>    5     after        1  476.190 #>    6 consisted        1  476.190 #>    7    corpus        1  476.190 #>    8      ever        1  476.190 #>    9   happily        1  476.190 #>   10        it        1  476.190 #>   11     lived        1  476.190 #>   12        of        1  476.190 #>   13 sentences        1  476.190 #>   14     there        1  476.190 #>   15     three        1  476.190 #>   16      time        1  476.190 #>   17      tiny        1  476.190 #>   18       toy        1  476.190 #>   19      upon        1  476.190 #>   20       was        1  476.190  t_extractor <- \"(?xi) ( [:;?!] | [.]+ | [\\\\w'-]+ )\" freqlist(toy_corpus,         re_token_splitter = NA,         re_token_extractor = t_extractor,         as_text = TRUE) #> Frequency list (types in list: 20, tokens in list: 24) #> rank      type abs_freq nrm_freq #> ---- --------- -------- -------- #>    1         .        3 1250.000 #>    2         a        2  833.333 #>    3        it        2  833.333 #>    4     after        1  416.667 #>    5       and        1  416.667 #>    6 consisted        1  416.667 #>    7    corpus        1  416.667 #>    8      ever        1  416.667 #>    9   happily        1  416.667 #>   10     lived        1  416.667 #>   11        of        1  416.667 #>   12      once        1  416.667 #>   13 sentences        1  416.667 #>   14     there        1  416.667 #>   15     three        1  416.667 #>   16      time        1  416.667 #>   17      tiny        1  416.667 #>   18       toy        1  416.667 #>   19      upon        1  416.667 #>   20       was        1  416.667  freqlist(letters, ngram_size = 3, as_text = TRUE) #> Frequency list (types in list: 24, tokens in list: 24) #> rank  type abs_freq nrm_freq #> ---- ----- -------- -------- #>    1 a_b_c        1  416.667 #>    2 b_c_d        1  416.667 #>    3 c_d_e        1  416.667 #>    4 d_e_f        1  416.667 #>    5 e_f_g        1  416.667 #>    6 f_g_h        1  416.667 #>    7 g_h_i        1  416.667 #>    8 h_i_j        1  416.667 #>    9 i_j_k        1  416.667 #>   10 j_k_l        1  416.667 #>   11 k_l_m        1  416.667 #>   12 l_m_n        1  416.667 #>   13 m_n_o        1  416.667 #>   14 n_o_p        1  416.667 #>   15 o_p_q        1  416.667 #>   16 p_q_r        1  416.667 #>   17 q_r_s        1  416.667 #>   18 r_s_t        1  416.667 #>   19 s_t_u        1  416.667 #>   20 t_u_v        1  416.667 #> ... #>   freqlist(letters, ngram_size = 2, ngram_sep = \" \", as_text = TRUE) #> Frequency list (types in list: 25, tokens in list: 25) #> rank type abs_freq nrm_freq #> ---- ---- -------- -------- #>    1  a b        1      400 #>    2  b c        1      400 #>    3  c d        1      400 #>    4  d e        1      400 #>    5  e f        1      400 #>    6  f g        1      400 #>    7  g h        1      400 #>    8  h i        1      400 #>    9  i j        1      400 #>   10  j k        1      400 #>   11  k l        1      400 #>   12  l m        1      400 #>   13  m n        1      400 #>   14  n o        1      400 #>   15  o p        1      400 #>   16  p q        1      400 #>   17  q r        1      400 #>   18  r s        1      400 #>   19  s t        1      400 #>   20  t u        1      400 #> ... #>"},{"path":"https://masterclm.github.io/mclm/reference/freqlist_diff.html","id":null,"dir":"Reference","previous_headings":"","what":"Subtract frequency lists — freqlist_diff","title":"Subtract frequency lists — freqlist_diff","text":"function merges information two frequency lists, subtracting frequencies found second frequency lists frequencies found first list.","code":""},{"path":"https://masterclm.github.io/mclm/reference/freqlist_diff.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subtract frequency lists — freqlist_diff","text":"","code":"freqlist_diff(x, y)"},{"path":"https://masterclm.github.io/mclm/reference/freqlist_diff.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Subtract frequency lists — freqlist_diff","text":"x, y Objects class freqlist.","code":""},{"path":"https://masterclm.github.io/mclm/reference/freqlist_diff.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Subtract frequency lists — freqlist_diff","text":"object class freqlist.","code":""},{"path":"https://masterclm.github.io/mclm/reference/freqlist_diff.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Subtract frequency lists — freqlist_diff","text":"","code":"(flist1 <- freqlist(\"A first toy corpus.\", as_text = TRUE)) #> Frequency list (types in list: 4, tokens in list: 4) #> rank   type abs_freq nrm_freq #> ---- ------ -------- -------- #>    1      a        1     2500 #>    2 corpus        1     2500 #>    3  first        1     2500 #>    4    toy        1     2500 (flist2 <- freqlist(\"A second toy corpus.\", as_text = TRUE)) #> Frequency list (types in list: 4, tokens in list: 4) #> rank   type abs_freq nrm_freq #> ---- ------ -------- -------- #>    1      a        1     2500 #>    2 corpus        1     2500 #>    3 second        1     2500 #>    4    toy        1     2500  freqlist_diff(flist1, flist2) #> Frequency list (types in list: 5, tokens in list: 1) #> <total number of tokens: 0> #> rank   type abs_freq #> ---- ------ -------- #>    1  first        1 #>    2      a        0 #>    3 corpus        0 #>    4 second        0 #>    5    toy        0"},{"path":"https://masterclm.github.io/mclm/reference/import_conc.html","id":null,"dir":"Reference","previous_headings":"","what":"Import a concordance — import_conc","title":"Import a concordance — import_conc","text":"function imports concordance files generated means write_conc().","code":""},{"path":"https://masterclm.github.io/mclm/reference/import_conc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import a concordance — import_conc","text":"","code":"import_conc(x, file_encoding = \"UTF-8\", source_type = c(\"corpuseye\"), ...)"},{"path":"https://masterclm.github.io/mclm/reference/import_conc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import a concordance — import_conc","text":"x vector input filenames. file_encoding Encoding file(s). source_type Character string. file read. Currently \"corpuseye\" supported. ... Additional arguments (implemented).","code":""},{"path":"https://masterclm.github.io/mclm/reference/import_conc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import a concordance — import_conc","text":"object class conc.","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/keep_bool.html","id":null,"dir":"Reference","previous_headings":"","what":"Subset an object based on logical criteria — keep_bool","title":"Subset an object based on logical criteria — keep_bool","text":"methods can used subset objects based logical vector.","code":""},{"path":"https://masterclm.github.io/mclm/reference/keep_bool.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subset an object based on logical criteria — keep_bool","text":"","code":"keep_bool(x, bool, invert = FALSE, ...)  drop_bool(x, bool, ...)  # S3 method for fnames drop_bool(x, bool, ...)  # S3 method for fnames keep_bool(x, bool, invert = FALSE, ...)  # S3 method for freqlist drop_bool(x, bool, ...)  # S3 method for freqlist keep_bool(x, bool, invert = FALSE, ...)  # S3 method for tokens drop_bool(x, bool, ...)  # S3 method for tokens keep_bool(x, bool, invert = FALSE, ...)  # S3 method for types drop_bool(x, bool, ...)  # S3 method for types keep_bool(x, bool, invert = FALSE, ...)"},{"path":"https://masterclm.github.io/mclm/reference/keep_bool.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Subset an object based on logical criteria — keep_bool","text":"x object classes method implemented. bool logical vector length x. bool correct length, recycled. Assuming invert FALSE, items selected bool TRUE. invert Logical. Whether matches selected rather non-matches. ... Additional arguments.","code":""},{"path":"https://masterclm.github.io/mclm/reference/keep_bool.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Subset an object based on logical criteria — keep_bool","text":"Object class x selected elements .","code":""},{"path":"https://masterclm.github.io/mclm/reference/keep_bool.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Subset an object based on logical criteria — keep_bool","text":"methods keep_pos() drop_pos() part family methods mclm package used subset different objects. methods starting keep_ extract items x based criterion specified second argument. contrast, methods starting drop_ exclude items match criterion argument. Calling drop_ method equivalent calling keep_ counterpart invert argument TRUE.","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/keep_bool.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Subset an object based on logical criteria — keep_bool","text":"","code":"# For a 'freqlist' object--------------------- (flist <- freqlist(\"The man and the mouse.\", as_text = TRUE)) #> Frequency list (types in list: 4, tokens in list: 5) #> rank  type abs_freq nrm_freq #> ---- ----- -------- -------- #>    1   the        2     4000 #>    2   and        1     2000 #>    3   man        1     2000 #>    4 mouse        1     2000  keep_bool(flist, type_freqs(flist) < 2) #> Frequency list (types in list: 3, tokens in list: 3) #> <total number of tokens: 5> #> rank orig_rank  type abs_freq nrm_freq #> ---- --------- ----- -------- -------- #>    1         2   and        1     2000 #>    2         3   man        1     2000 #>    3         4 mouse        1     2000 drop_bool(flist, type_freqs(flist) >= 2) #> Frequency list (types in list: 3, tokens in list: 3) #> <total number of tokens: 5> #> rank orig_rank  type abs_freq nrm_freq #> ---- --------- ----- -------- -------- #>    1         2   and        1     2000 #>    2         3   man        1     2000 #>    3         4 mouse        1     2000 keep_bool(flist, ranks(flist) <= 3) #> Frequency list (types in list: 3, tokens in list: 4) #> <total number of tokens: 5> #> rank orig_rank type abs_freq nrm_freq #> ---- --------- ---- -------- -------- #>    1         1  the        2     4000 #>    2         2  and        1     2000 #>    3         3  man        1     2000  keep_bool(flist, c(FALSE, TRUE, TRUE, FALSE))  #> Frequency list (types in list: 2, tokens in list: 2) #> <total number of tokens: 5> #> rank orig_rank type abs_freq nrm_freq #> ---- --------- ---- -------- -------- #>    1         2  and        1     2000 #>    2         3  man        1     2000  (flist2 <- keep_bool(flist, type_freqs(flist) < 2)) #> Frequency list (types in list: 3, tokens in list: 3) #> <total number of tokens: 5> #> rank orig_rank  type abs_freq nrm_freq #> ---- --------- ----- -------- -------- #>    1         2   and        1     2000 #>    2         3   man        1     2000 #>    3         4 mouse        1     2000 keep_bool(flist2, orig_ranks(flist2) > 2) #> Frequency list (types in list: 2, tokens in list: 2) #> <total number of tokens: 5> #> rank orig_rank  type abs_freq nrm_freq #> ---- --------- ----- -------- -------- #>    1         3   man        1     2000 #>    2         4 mouse        1     2000  # For a 'types' object ---------------------- (tps <- as_types(letters[1:10])) #> Type collection of length 10 #>    type #>    ---- #>  1    a #>  2    b #>  3    c #>  4    d #>  5    e #>  6    f #>  7    g #>  8    h #>  9    i #> 10    j  keep_bool(tps, c(TRUE, FALSE)) #> Type collection of length 5 #>   type #>   ---- #> 1    a #> 2    c #> 3    e #> 4    g #> 5    i drop_bool(tps, c(TRUE, FALSE)) #> Type collection of length 5 #>   type #>   ---- #> 1    b #> 2    d #> 3    f #> 4    h #> 5    j  # For a 'tokens' object ---------------------- (tks <- as_tokens(letters[1:10])) #> Token sequence of length 10 #> idx token #> --- ----- #>   1     a #>   2     b #>   3     c #>   4     d #>   5     e #>   6     f #>   7     g #>   8     h #>   9     i #>  10     j  keep_bool(tks, c(TRUE, FALSE)) #> Token sequence of length 5 #> idx token #> --- ----- #>   1     a #>   2     c #>   3     e #>   4     g #>   5     i drop_bool(tks, c(TRUE, FALSE)) #> Token sequence of length 5 #> idx token #> --- ----- #>   1     b #>   2     d #>   3     f #>   4     h #>   5     j"},{"path":"https://masterclm.github.io/mclm/reference/keep_fnames.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter collection of filenames by name — keep_fnames","title":"Filter collection of filenames by name — keep_fnames","text":"functions build subset object class fnames based vector characters, either including (keep_fnames(invert = FALSE)) excluding (keep_fnames(invert = FALSE) drop_fnames()).","code":""},{"path":"https://masterclm.github.io/mclm/reference/keep_fnames.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter collection of filenames by name — keep_fnames","text":"","code":"keep_fnames(x, y, invert = FALSE, ...)  drop_fnames(x, y, ...)"},{"path":"https://masterclm.github.io/mclm/reference/keep_fnames.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Filter collection of filenames by name — keep_fnames","text":"x object class fnames, filtered. y object class fnames class types character vector. filtering criterion. invert Boolean value. TRUE, elements y excluded rather kept (keep_fnames() behaves like drop_fnames()) ... Additional arguments.","code":""},{"path":"https://masterclm.github.io/mclm/reference/keep_fnames.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Filter collection of filenames by name — keep_fnames","text":"object class fnames.","code":""},{"path":"https://masterclm.github.io/mclm/reference/keep_fnames.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Filter collection of filenames by name — keep_fnames","text":"","code":"all_fnames <- as_fnames(c(\"file1\", \"file2\", \"file3\",                           \"file4\", \"file5\", \"file6\"))  unwanted_fnames <- as_fnames(c(\"file1\", \"file4\")) keep_fnames(all_fnames, unwanted_fnames, invert = TRUE) #> Filename collection of length 4 #>   filename #>   -------- #> 1    file2 #> 2    file3 #> 3    file5 #> 4    file6 drop_fnames(all_fnames, unwanted_fnames) #> Filename collection of length 4 #>   filename #>   -------- #> 1    file2 #> 2    file3 #> 3    file5 #> 4    file6  wanted_fnames <- as_fnames(c(\"file3\", \"file5\")) keep_fnames(all_fnames, wanted_fnames) #> Filename collection of length 2 #>   filename #>   -------- #> 1    file3 #> 2    file5"},{"path":"https://masterclm.github.io/mclm/reference/keep_pos.html","id":null,"dir":"Reference","previous_headings":"","what":"Subset an object by index — keep_pos","title":"Subset an object by index — keep_pos","text":"methods can used subset objects based numeric vector indices.","code":""},{"path":"https://masterclm.github.io/mclm/reference/keep_pos.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subset an object by index — keep_pos","text":"","code":"keep_pos(x, pos, invert = FALSE, ...)  # S3 method for fnames drop_pos(x, pos, ...)  # S3 method for fnames keep_pos(x, pos, invert = FALSE, ...)  # S3 method for freqlist drop_pos(x, pos, ...)  # S3 method for freqlist keep_pos(x, pos, invert = FALSE, ...)  drop_pos(x, pos, ...)  # S3 method for tokens drop_pos(x, pos, ...)  # S3 method for tokens keep_pos(x, pos, invert = FALSE, ...)  # S3 method for types drop_pos(x, pos, ...)  # S3 method for types keep_pos(x, pos, invert = FALSE, ...)"},{"path":"https://masterclm.github.io/mclm/reference/keep_pos.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Subset an object by index — keep_pos","text":"x object classes method implemented. pos numeric vector, numbers identify positions (= indices) items x. numbers positive, values point items selected. numbers negative, absolute values point items selected. Positive negative numbers must mixed. invert Logical. Whether matches selected rather non-matches. ... Additional arguments.","code":""},{"path":"https://masterclm.github.io/mclm/reference/keep_pos.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Subset an object by index — keep_pos","text":"Object class x selected elements .","code":""},{"path":"https://masterclm.github.io/mclm/reference/keep_pos.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Subset an object by index — keep_pos","text":"methods keep_pos() drop_pos() part family methods mclm package used subset different objects. methods starting keep_ extract items x based criterion specified second argument. contrast, methods starting drop_ exclude items match criterion argument. Calling drop_ method equivalent calling keep_ counterpart invert argument TRUE.","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/keep_pos.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Subset an object by index — keep_pos","text":"","code":"# For a 'freqlist' object -------------------- (flist <- freqlist(\"The man and the mouse.\", as_text = TRUE)) #> Frequency list (types in list: 4, tokens in list: 5) #> rank  type abs_freq nrm_freq #> ---- ----- -------- -------- #>    1   the        2     4000 #>    2   and        1     2000 #>    3   man        1     2000 #>    4 mouse        1     2000  keep_pos(flist, c(2, 3)) #> Frequency list (types in list: 2, tokens in list: 2) #> <total number of tokens: 5> #> rank orig_rank type abs_freq nrm_freq #> ---- --------- ---- -------- -------- #>    1         2  and        1     2000 #>    2         3  man        1     2000  # For a 'types' object ----------------------- (tps <- as_types(letters[1:10])) #> Type collection of length 10 #>    type #>    ---- #>  1    a #>  2    b #>  3    c #>  4    d #>  5    e #>  6    f #>  7    g #>  8    h #>  9    i #> 10    j  keep_pos(tps, c(1, 3, 5, 7, 9)) #> Type collection of length 5 #>   type #>   ---- #> 1    a #> 2    c #> 3    e #> 4    g #> 5    i drop_pos(tps, c(1, 3, 5, 7, 9)) #> Type collection of length 5 #>   type #>   ---- #> 1    b #> 2    d #> 3    f #> 4    h #> 5    j  # For a 'tokens' object ---------------------- (tks <- as_tokens(letters[1:10])) #> Token sequence of length 10 #> idx token #> --- ----- #>   1     a #>   2     b #>   3     c #>   4     d #>   5     e #>   6     f #>   7     g #>   8     h #>   9     i #>  10     j  keep_pos(tks, c(1, 3, 5, 7, 9)) #> Token sequence of length 5 #> idx token #> --- ----- #>   1     a #>   2     c #>   3     e #>   4     g #>   5     i drop_pos(tks, c(1, 3, 5, 7, 9)) #> Token sequence of length 5 #> idx token #> --- ----- #>   1     b #>   2     d #>   3     f #>   4     h #>   5     j"},{"path":"https://masterclm.github.io/mclm/reference/keep_re.html","id":null,"dir":"Reference","previous_headings":"","what":"Subset an object based on regular expressions — keep_re","title":"Subset an object based on regular expressions — keep_re","text":"methods can used subset objects based regular expression.","code":""},{"path":"https://masterclm.github.io/mclm/reference/keep_re.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subset an object based on regular expressions — keep_re","text":"","code":"keep_re(x, pattern, perl = TRUE, invert = FALSE, ...)  drop_re(x, pattern, perl = TRUE, ...)  # S3 method for fnames drop_re(x, pattern, perl = TRUE, ...)  # S3 method for fnames keep_re(x, pattern, perl = TRUE, invert = FALSE, ...)  # S3 method for freqlist drop_re(x, pattern, perl = TRUE, ...)  # S3 method for freqlist keep_re(x, pattern, perl = TRUE, invert = FALSE, ...)  # S3 method for tokens drop_re(x, pattern, perl = TRUE, ...)  # S3 method for tokens keep_re(x, pattern, perl = TRUE, invert = FALSE, ...)  # S3 method for types drop_re(x, pattern, perl = TRUE, ...)  # S3 method for types keep_re(x, pattern, perl = TRUE, invert = FALSE, ...)"},{"path":"https://masterclm.github.io/mclm/reference/keep_re.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Subset an object based on regular expressions — keep_re","text":"x object classes method implemented. pattern Either object class re character vector length one containing regular expression. perl Logical. Whether pattern treated PCRE flavor regular expression. perl argument used pattern regular character vector. pattern object class re, perl argument ignored, relevant information re object pattern, viz. value pattern$perl, used instead. invert Logical. Whether matches selected rather non-matches. ... Additional arguments.","code":""},{"path":"https://masterclm.github.io/mclm/reference/keep_re.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Subset an object based on regular expressions — keep_re","text":"Object class x selected elements .","code":""},{"path":"https://masterclm.github.io/mclm/reference/keep_re.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Subset an object based on regular expressions — keep_re","text":"methods keep_pos() drop_pos() part family methods mclm package used subset different objects. methods starting keep_ extract items x based criterion specified second argument. contrast, methods starting drop_ exclude items match criterion argument. Calling drop_ method equivalent calling keep_ counterpart invert argument TRUE.","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/keep_re.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Subset an object based on regular expressions — keep_re","text":"","code":"# For a 'freqlist' object -------------------- (flist <- freqlist(\"The man and the mouse.\", as_text = TRUE)) #> Frequency list (types in list: 4, tokens in list: 5) #> rank  type abs_freq nrm_freq #> ---- ----- -------- -------- #>    1   the        2     4000 #>    2   and        1     2000 #>    3   man        1     2000 #>    4 mouse        1     2000  keep_re(flist, \"[ao]\") #> Frequency list (types in list: 3, tokens in list: 3) #> <total number of tokens: 5> #> rank orig_rank  type abs_freq nrm_freq #> ---- --------- ----- -------- -------- #>    1         2   and        1     2000 #>    2         3   man        1     2000 #>    3         4 mouse        1     2000 drop_re(flist, \"[ao]\") #> Frequency list (types in list: 1, tokens in list: 2) #> <total number of tokens: 5> #> rank orig_rank type abs_freq nrm_freq #> ---- --------- ---- -------- -------- #>    1         1  the        2     4000 keep_re(flist, \"[ao]\", invert = TRUE) # same as drop_re() #> Frequency list (types in list: 1, tokens in list: 2) #> <total number of tokens: 5> #> rank orig_rank type abs_freq nrm_freq #> ---- --------- ---- -------- -------- #>    1         1  the        2     4000  # For a 'types' object ----------------------- (tps <- as_types(letters[1:10])) #> Type collection of length 10 #>    type #>    ---- #>  1    a #>  2    b #>  3    c #>  4    d #>  5    e #>  6    f #>  7    g #>  8    h #>  9    i #> 10    j  keep_re(tps, \"[acegi]\") #> Type collection of length 5 #>   type #>   ---- #> 1    a #> 2    c #> 3    e #> 4    g #> 5    i drop_re(tps, \"[acegi]\") #> Type collection of length 5 #>   type #>   ---- #> 1    b #> 2    d #> 3    f #> 4    h #> 5    j  # For a 'tokens' object ---------------------- (tks <- as_tokens(letters[1:10])) #> Token sequence of length 10 #> idx token #> --- ----- #>   1     a #>   2     b #>   3     c #>   4     d #>   5     e #>   6     f #>   7     g #>   8     h #>   9     i #>  10     j  keep_re(tks, \"[acegi]\") #> Token sequence of length 5 #> idx token #> --- ----- #>   1     a #>   2     c #>   3     e #>   4     g #>   5     i drop_re(tks, \"[acegi]\") #> Token sequence of length 5 #> idx token #> --- ----- #>   1     b #>   2     d #>   3     f #>   4     h #>   5     j"},{"path":"https://masterclm.github.io/mclm/reference/keep_types.html","id":null,"dir":"Reference","previous_headings":"","what":"Subset an object based on a selection of types — keep_types","title":"Subset an object based on a selection of types — keep_types","text":"methods can used subset objects based list types.","code":""},{"path":"https://masterclm.github.io/mclm/reference/keep_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subset an object based on a selection of types — keep_types","text":"","code":"keep_types(x, types, invert = FALSE, ...)  drop_types(x, types, ...)  # S3 method for fnames drop_types(x, types, ...)  # S3 method for fnames keep_types(x, types, invert = FALSE, ...)  # S3 method for freqlist drop_types(x, types, ...)  # S3 method for freqlist keep_types(x, types, invert = FALSE, ...)  # S3 method for tokens drop_types(x, types, ...)  # S3 method for tokens keep_types(x, types, invert = FALSE, ...)  # S3 method for types drop_types(x, types, ...)  # S3 method for types keep_types(x, types, invert = FALSE, ...)"},{"path":"https://masterclm.github.io/mclm/reference/keep_types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Subset an object based on a selection of types — keep_types","text":"x object classes method implemented. types Either object class types character vector. invert Logical. Whether matches selected rather non-matches. ... Additional arguments.","code":""},{"path":"https://masterclm.github.io/mclm/reference/keep_types.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Subset an object based on a selection of types — keep_types","text":"Object class x selected elements .","code":""},{"path":"https://masterclm.github.io/mclm/reference/keep_types.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Subset an object based on a selection of types — keep_types","text":"methods keep_pos() drop_pos() part family methods mclm package used subset different objects. methods starting keep_ extract items x based criterion specified second argument. contrast, methods starting drop_ exclude items match criterion argument. Calling drop_ method equivalent calling keep_ counterpart invert argument TRUE.","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/keep_types.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Subset an object based on a selection of types — keep_types","text":"","code":"# For a 'freqlist' object ------------------------ (flist <- freqlist(\"The man and the mouse.\", as_text = TRUE)) #> Frequency list (types in list: 4, tokens in list: 5) #> rank  type abs_freq nrm_freq #> ---- ----- -------- -------- #>    1   the        2     4000 #>    2   and        1     2000 #>    3   man        1     2000 #>    4 mouse        1     2000 keep_types(flist, c(\"man\", \"and\")) #> Frequency list (types in list: 2, tokens in list: 2) #> <total number of tokens: 5> #> rank orig_rank type abs_freq nrm_freq #> ---- --------- ---- -------- -------- #>    2         3  man        1     2000 #>    1         2  and        1     2000 drop_types(flist, c(\"man\", \"and\")) #> Frequency list (types in list: 2, tokens in list: 3) #> <total number of tokens: 5> #> rank orig_rank  type abs_freq nrm_freq #> ---- --------- ----- -------- -------- #>    1         1   the        2     4000 #>    2         4 mouse        1     2000 keep_types(flist, c(\"man\", \"and\"), invert = TRUE) # same as drop_types() #> Frequency list (types in list: 2, tokens in list: 3) #> <total number of tokens: 5> #> rank orig_rank  type abs_freq nrm_freq #> ---- --------- ----- -------- -------- #>    1         1   the        2     4000 #>    2         4 mouse        1     2000  # For a 'types' object --------------------------- (tps <- as_types(letters[1:10])) #> Type collection of length 10 #>    type #>    ---- #>  1    a #>  2    b #>  3    c #>  4    d #>  5    e #>  6    f #>  7    g #>  8    h #>  9    i #> 10    j  keep_types(tps, c(\"a\", \"c\", \"e\", \"g\", \"i\")) #> Type collection of length 5 #>   type #>   ---- #> 1    a #> 2    c #> 3    e #> 4    g #> 5    i drop_types(tps,  c(\"a\", \"c\", \"e\", \"g\", \"i\")) #> Type collection of length 5 #>   type #>   ---- #> 1    b #> 2    d #> 3    f #> 4    h #> 5    j  # For a 'tokens' object -------------------------- (tks <- as_tokens(letters[1:10])) #> Token sequence of length 10 #> idx token #> --- ----- #>   1     a #>   2     b #>   3     c #>   4     d #>   5     e #>   6     f #>   7     g #>   8     h #>   9     i #>  10     j  keep_types(tks, c(\"a\", \"c\", \"e\", \"g\", \"i\")) #> Token sequence of length 5 #> idx token #> --- ----- #>   1     a #>   2     c #>   3     e #>   4     g #>   5     i drop_types(tks,  c(\"a\", \"c\", \"e\", \"g\", \"i\")) #> Token sequence of length 5 #> idx token #> --- ----- #>   1     b #>   2     d #>   3     f #>   4     h #>   5     j"},{"path":"https://masterclm.github.io/mclm/reference/mclm-package.html","id":null,"dir":"Reference","previous_headings":"","what":"Mastering Corpus Linguistic Methods — mclm-package","title":"Mastering Corpus Linguistic Methods — mclm-package","text":"Various functions support quantitative corpus linguistics.","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/mclm-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Mastering Corpus Linguistic Methods — mclm-package","text":"Maintainer: Mariana Montes mariana.montes@kuleuven.Authors: Dirk Speelman dirk.speelman@kuleuven.","code":""},{"path":"https://masterclm.github.io/mclm/reference/mclm_print.html","id":null,"dir":"Reference","previous_headings":"","what":"Print an object — print.assoc_scores","title":"Print an object — print.assoc_scores","text":"base method prints objects; arguments specific mclm implementations described.","code":""},{"path":"https://masterclm.github.io/mclm/reference/mclm_print.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print an object — print.assoc_scores","text":"","code":"# S3 method for assoc_scores print(   x,   n = 20,   from = 1,   freeze_cols = NULL,   keep_cols = NULL,   drop_cols = NULL,   from_col = 1,   sort_order = c(\"none\", \"G_signed\", \"PMI\", \"alpha\"),   extra = NULL,   ... )  # S3 method for conc print(x, n = 30, ...)  # S3 method for fnames print(x, n = 20, from = 1, sort_order = c(\"none\", \"alpha\"), extra = NULL, ...)  # S3 method for freqlist print(x, n = 20, from = 1, extra = NULL, ...)  # S3 method for slma print(x, n = 20, from = 1, ...)  # S3 method for tokens print(x, n = 20, from = 1, extra = NULL, ...)  # S3 method for types print(x, n = 20, from = 1, sort_order = c(\"none\", \"alpha\"), extra = NULL, ...)"},{"path":"https://masterclm.github.io/mclm/reference/mclm_print.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print an object — print.assoc_scores","text":"x object classes method implemented. n Maximum number items object printed . Index first item printed. freeze_cols Names columns affected argument from_col. Frozen columns always printed left non-frozen columns, even original order different. names types always unavoidably printed leftmost column. argument NULL, default setting applies, meaning following columns, present, displayed \"frozen area\": , PMI G_signed. avoid columns frozen, freeze_cols NA character(0). keep_cols, drop_cols vector column names NULL. arguments NULL, columns printed (many fit screen). keep_cols NULL, indicates columns printed. NULL drop_cols , drop_cols indicates columns printed. Note effect frozen area. Columns blocked printing arguments still available sort_order. from_col Index first column displayed regular area (among selected columns, including frozen columns). from_col points sort_order Order items printed. general, possible values \"alpha\" (meaning items sorted alphabetically), \"none\" (meaning items sorted). x object class assoc_scores, column name vector column names may provided instead. extra Extra settings, environment. Arguments defined take precedence arguments. instance, extra$from_col NULL, overrule from_col argument. ... Additional printing arguments.","code":""},{"path":"https://masterclm.github.io/mclm/reference/mclm_print.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print an object — print.assoc_scores","text":"Invisibly, x. objects class assoc_scores, output consists two areas: 'frozen area' left 'regular area' right. areas visually separated vertical line (|). distinction intuitive explore(), frozen columns respond horizontal movements (r l commands). equivalent method from_col argument.","code":""},{"path":"https://masterclm.github.io/mclm/reference/mclm_xml_text.html","id":null,"dir":"Reference","previous_headings":"","what":"Get text from xml node — mclm_xml_text","title":"Get text from xml node — mclm_xml_text","text":"Get text xml node","code":""},{"path":"https://masterclm.github.io/mclm/reference/mclm_xml_text.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get text from xml node — mclm_xml_text","text":"","code":"mclm_xml_text(node, trim = FALSE)"},{"path":"https://masterclm.github.io/mclm/reference/mclm_xml_text.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get text from xml node — mclm_xml_text","text":"node XML node read xml2::read_xml(). trim TRUE trim leading trailing spaces.","code":""},{"path":"https://masterclm.github.io/mclm/reference/mclm_xml_text.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get text from xml node — mclm_xml_text","text":"Character vector: text value (elements ) node, concatenated spaces .","code":""},{"path":"https://masterclm.github.io/mclm/reference/mclm_xml_text.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get text from xml node — mclm_xml_text","text":"","code":"test_xml <- ' <p>   <w pos=\"at\">The<\/w>   <w pos=\"nn\">example<\/w>   <punct>.<\/punct> <\/p>'  test_xml_parsed <- xml2::read_xml(test_xml)  # xml2 output xml2::xml_text(test_xml_parsed) #> [1] \"Theexample.\"  # mclm version mclm_xml_text(test_xml_parsed) #> [1] \"The example .\""},{"path":"https://masterclm.github.io/mclm/reference/merge_conc.html","id":null,"dir":"Reference","previous_headings":"","what":"Merge concordances — merge_conc","title":"Merge concordances — merge_conc","text":"function merges multiple objects class conc one conc object.","code":""},{"path":"https://masterclm.github.io/mclm/reference/merge_conc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Merge concordances — merge_conc","text":"","code":"merge_conc(..., show_warnings = TRUE)"},{"path":"https://masterclm.github.io/mclm/reference/merge_conc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Merge concordances — merge_conc","text":"... Two objects class conc. show_warnings Logical. FALSE, warnings suppressed.","code":""},{"path":"https://masterclm.github.io/mclm/reference/merge_conc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Merge concordances — merge_conc","text":"object class conc.","code":""},{"path":"https://masterclm.github.io/mclm/reference/merge_conc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Merge concordances — merge_conc","text":"","code":"(cd_1 <- conc('A first very small corpus.', '\\\\w+', as_text = TRUE)) #> Concordance-based data frame (number of observations: 5) #> idx                                     left|match |right                    #>   1                                         |  A   |first very small corpus. #>   2                                        A|first |very small corpus.       #>   3                                  A first| very |small corpus.            #>   4                             A first very|small |corpus.                  #>   5                       A first very small|corpus|.                        #>  #> This data frame has 6 columns: #>    column #> 1 glob_id #> 2      id #> 3  source #> 4    left #> 5   match #> 6   right as.data.frame(cd_1) #>   glob_id id source                left  match                     right #> 1       1  1      -                          A  first very small corpus. #> 2       2  2      -                  A   first        very small corpus. #> 3       3  3      -            A first    very             small corpus. #> 4       4  4      -       A first very   small                   corpus. #> 5       5  5      - A first very small  corpus                         .  (cd_2 <- conc('A second very small corpus.', '\\\\w+', as_text = TRUE)) #> Concordance-based data frame (number of observations: 5) #> idx                                    left|match |right                     #>   1                                        |  A   |second very small corpus. #>   2                                       A|second|very small corpus.        #>   3                                A second| very |small corpus.             #>   4                           A second very|small |corpus.                   #>   5                     A second very small|corpus|.                         #>  #> This data frame has 6 columns: #>    column #> 1 glob_id #> 2      id #> 3  source #> 4    left #> 5   match #> 6   right (cd_3 <- conc('A third very small corpus.', '\\\\w+', as_text = TRUE)) #> Concordance-based data frame (number of observations: 5) #> idx                                     left|match |right                    #>   1                                         |  A   |third very small corpus. #>   2                                        A|third |very small corpus.       #>   3                                  A third| very |small corpus.            #>   4                             A third very|small |corpus.                  #>   5                       A third very small|corpus|.                        #>  #> This data frame has 6 columns: #>    column #> 1 glob_id #> 2      id #> 3  source #> 4    left #> 5   match #> 6   right (cd <- merge_conc(cd_1, cd_2, cd_3)) #> Concordance-based data frame (number of observations: 15) #> idx                                    left|match |right                     #>   1                                        |  A   |first very small corpus.  #>   2                                       A|first |very small corpus.        #>   3                                 A first| very |small corpus.             #>   4                            A first very|small |corpus.                   #>   5                      A first very small|corpus|.                         #>   6                                        |  A   |second very small corpus. #>   7                                       A|second|very small corpus.        #>   8                                A second| very |small corpus.             #>   9                           A second very|small |corpus.                   #>  10                     A second very small|corpus|.                         #>  11                                        |  A   |third very small corpus.  #>  12                                       A|third |very small corpus.        #>  13                                 A third| very |small corpus.             #>  14                            A third very|small |corpus.                   #>  15                      A third very small|corpus|.                         #>  #> This data frame has 6 columns: #>    column #> 1 glob_id #> 2      id #> 3  source #> 4    left #> 5   match #> 6   right as.data.frame(cd) #>    glob_id id source                 left  match                      right #> 1        1  1      -                           A   first very small corpus. #> 2        2  2      -                   A   first         very small corpus. #> 3        3  3      -             A first    very              small corpus. #> 4        4  4      -        A first very   small                    corpus. #> 5        5  5      -  A first very small  corpus                          . #> 6        6  1      -                           A  second very small corpus. #> 7        7  2      -                   A  second         very small corpus. #> 8        8  3      -            A second    very              small corpus. #> 9        9  4      -       A second very   small                    corpus. #> 10      10  5      - A second very small  corpus                          . #> 11      11  1      -                           A   third very small corpus. #> 12      12  2      -                   A   third         very small corpus. #> 13      13  3      -             A third    very              small corpus. #> 14      14  4      -        A third very   small                    corpus. #> 15      15  5      -  A third very small  corpus                          ."},{"path":"https://masterclm.github.io/mclm/reference/merge_fnames.html","id":null,"dir":"Reference","previous_headings":"","what":"Merge filenames collections — merge_fnames","title":"Merge filenames collections — merge_fnames","text":"functions merge two fnames objects one larger fnames object, removing duplicates (keeping first appearance) resorting items sort = TRUE.","code":""},{"path":"https://masterclm.github.io/mclm/reference/merge_fnames.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Merge filenames collections — merge_fnames","text":"","code":"fnames_merge(x, y, sort = FALSE)  fnames_merge_all(..., sort = FALSE)"},{"path":"https://masterclm.github.io/mclm/reference/merge_fnames.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Merge filenames collections — merge_fnames","text":"x, y object class fnames. sort Boolean value. items output sorted? ... Various objects class fnames list objects class fnames.","code":""},{"path":"https://masterclm.github.io/mclm/reference/merge_fnames.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Merge filenames collections — merge_fnames","text":"object class fnames.","code":""},{"path":"https://masterclm.github.io/mclm/reference/merge_fnames.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Merge filenames collections — merge_fnames","text":"","code":"cwd_fnames <- as_fnames(c(\"file1.txt\", \"file2.txt\")) cwd_fnames2 <- as_fnames(c(\"dir1/file3.txt\", \"dir1/file4.txt\")) cwd_fnames3 <- as_fnames(c(\"dir2/file5.txt\", \"dir2/file6.txt\")) fnames_merge(cwd_fnames, cwd_fnames2) #> Filename collection of length 4 #>         filename #>   -------------- #> 1      file1.txt #> 2      file2.txt #> 3 dir1/file3.txt #> 4 dir1/file4.txt fnames_merge_all(cwd_fnames, cwd_fnames2, cwd_fnames3) #> Filename collection of length 6 #>         filename #>   -------------- #> 1      file1.txt #> 2      file2.txt #> 3 dir1/file3.txt #> 4 dir1/file4.txt #> 5 dir2/file5.txt #> 6 dir2/file6.txt"},{"path":"https://masterclm.github.io/mclm/reference/merge_freqlist.html","id":null,"dir":"Reference","previous_headings":"","what":"Merge frequency lists — merge_freqlist","title":"Merge frequency lists — merge_freqlist","text":"functions merge two frequency lists, adding frequencies. current implementation, original ranks lost merging.","code":""},{"path":"https://masterclm.github.io/mclm/reference/merge_freqlist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Merge frequency lists — merge_freqlist","text":"","code":"freqlist_merge(x, y)  freqlist_merge_all(...)"},{"path":"https://masterclm.github.io/mclm/reference/merge_freqlist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Merge frequency lists — merge_freqlist","text":"x, y object class freqlist. ... Various objects class freqlist list objects class freqlist.","code":""},{"path":"https://masterclm.github.io/mclm/reference/merge_freqlist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Merge frequency lists — merge_freqlist","text":"object class freqlist.","code":""},{"path":"https://masterclm.github.io/mclm/reference/merge_freqlist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Merge frequency lists — merge_freqlist","text":"","code":"(flist1 <- freqlist(\"A first toy corpus.\", as_text = TRUE)) #> Frequency list (types in list: 4, tokens in list: 4) #> rank   type abs_freq nrm_freq #> ---- ------ -------- -------- #>    1      a        1     2500 #>    2 corpus        1     2500 #>    3  first        1     2500 #>    4    toy        1     2500 (flist2 <- freqlist(\"A second toy corpus.\", as_text = TRUE)) #> Frequency list (types in list: 4, tokens in list: 4) #> rank   type abs_freq nrm_freq #> ---- ------ -------- -------- #>    1      a        1     2500 #>    2 corpus        1     2500 #>    3 second        1     2500 #>    4    toy        1     2500 (flist3 <- freqlist(\"A third toy corpus.\", as_text = TRUE)) #> Frequency list (types in list: 4, tokens in list: 4) #> rank   type abs_freq nrm_freq #> ---- ------ -------- -------- #>    1      a        1     2500 #>    2 corpus        1     2500 #>    3  third        1     2500 #>    4    toy        1     2500  freqlist_merge(flist1, flist2) #> Frequency list (types in list: 5, tokens in list: 8) #> rank   type abs_freq nrm_freq #> ---- ------ -------- -------- #>    1      a        2     2500 #>    2 corpus        2     2500 #>    3    toy        2     2500 #>    4  first        1     1250 #>    5 second        1     1250  freqlist_merge_all(flist1, flist2, flist3) #> Frequency list (types in list: 6, tokens in list: 12) #> rank   type abs_freq nrm_freq #> ---- ------ -------- -------- #>    1      a        3 2500.000 #>    2 corpus        3 2500.000 #>    3    toy        3 2500.000 #>    4  first        1  833.333 #>    5 second        1  833.333 #>    6  third        1  833.333 freqlist_merge_all(list(flist1, flist2, flist3)) # same result #> Frequency list (types in list: 6, tokens in list: 12) #> rank   type abs_freq nrm_freq #> ---- ------ -------- -------- #>    1      a        3 2500.000 #>    2 corpus        3 2500.000 #>    3    toy        3 2500.000 #>    4  first        1  833.333 #>    5 second        1  833.333 #>    6  third        1  833.333"},{"path":"https://masterclm.github.io/mclm/reference/merge_tokens.html","id":null,"dir":"Reference","previous_headings":"","what":"Merge tokens objects — merge_tokens","title":"Merge tokens objects — merge_tokens","text":"tokens_merge() merges two tokens objects x y larger tokens object. tokens_merge_all() merge arguments one tokens object. result concatenation tokens, order items input preserved.","code":""},{"path":"https://masterclm.github.io/mclm/reference/merge_tokens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Merge tokens objects — merge_tokens","text":"","code":"tokens_merge(x, y)  tokens_merge_all(...)"},{"path":"https://masterclm.github.io/mclm/reference/merge_tokens.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Merge tokens objects — merge_tokens","text":"x, y object class tokens ... Objects class tokens list objects class tokens.","code":""},{"path":"https://masterclm.github.io/mclm/reference/merge_tokens.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Merge tokens objects — merge_tokens","text":"object class tokens.","code":""},{"path":"https://masterclm.github.io/mclm/reference/merge_tokens.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Merge tokens objects — merge_tokens","text":"","code":"(tks1 <- tokenize(c(\"This is a first sentence.\"))) #> Token sequence of length 5 #> idx    token #> --- -------- #>   1     this #>   2       is #>   3        a #>   4    first #>   5 sentence (tks2 <- tokenize(c(\"It is followed by a second one.\"))) #> Token sequence of length 7 #> idx    token #> --- -------- #>   1       it #>   2       is #>   3 followed #>   4       by #>   5        a #>   6   second #>   7      one (tks3 <- tokenize(c(\"Then a third one follows.\"))) #> Token sequence of length 5 #> idx   token #> --- ------- #>   1    then #>   2       a #>   3   third #>   4     one #>   5 follows  tokens_merge(tks1, tks2) #> Token sequence of length 12 #> idx    token #> --- -------- #>   1     this #>   2       is #>   3        a #>   4    first #>   5 sentence #>   6       it #>   7       is #>   8 followed #>   9       by #>  10        a #>  11   second #>  12      one tokens_merge_all(tks1, tks2, tks3) #> Token sequence of length 17 #> idx    token #> --- -------- #>   1     this #>   2       is #>   3        a #>   4    first #>   5 sentence #>   6       it #>   7       is #>   8 followed #>   9       by #>  10        a #>  11   second #>  12      one #>  13     then #>  14        a #>  15    third #>  16      one #>  17  follows tokens_merge_all(list(tks1, tks2, tks3)) #> Token sequence of length 17 #> idx    token #> --- -------- #>   1     this #>   2       is #>   3        a #>   4    first #>   5 sentence #>   6       it #>   7       is #>   8 followed #>   9       by #>  10        a #>  11   second #>  12      one #>  13     then #>  14        a #>  15    third #>  16      one #>  17  follows"},{"path":"https://masterclm.github.io/mclm/reference/merge_types.html","id":null,"dir":"Reference","previous_headings":"","what":"Merge 'types' objects — merge_types","title":"Merge 'types' objects — merge_types","text":"methods merge two objects class types.","code":""},{"path":"https://masterclm.github.io/mclm/reference/merge_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Merge 'types' objects — merge_types","text":"","code":"types_merge(x, y, sort = FALSE)  types_merge_all(..., sort = FALSE)"},{"path":"https://masterclm.github.io/mclm/reference/merge_types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Merge 'types' objects — merge_types","text":"x, y object class types. sort Logical. results sorted. ... Either objects class types lists containing objects.","code":""},{"path":"https://masterclm.github.io/mclm/reference/merge_types.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Merge 'types' objects — merge_types","text":"object class types.","code":""},{"path":"https://masterclm.github.io/mclm/reference/merge_types.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Merge 'types' objects — merge_types","text":"types_merge(): Merge two types types_merge_all(): Merge multiple types","code":""},{"path":"https://masterclm.github.io/mclm/reference/merge_types.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Merge 'types' objects — merge_types","text":"","code":"(tps1 <- as_types(c(\"a\", \"simple\", \"simple\", \"example\"))) #> Type collection of length 3 #>      type #>   ------- #> 1       a #> 2 example #> 3  simple (tps2 <- as_types(c(\"with\", \"a\", \"few\", \"words\"))) #> Type collection of length 4 #>    type #>   ----- #> 1     a #> 2   few #> 3  with #> 4 words (tps3 <- as_types(c(\"just\", \"for\", \"testing\"))) #> Type collection of length 3 #>      type #>   ------- #> 1     for #> 2    just #> 3 testing types_merge(tps1, tps2)       # always removes duplicates, but doesn't sort #> Type collection of length 6 #>      type #>   ------- #> 1       a #> 2 example #> 3  simple #> 4     few #> 5    with #> 6   words sort(types_merge(tps1, tps2)) # same, but with sorting #> Type collection of length 6 #>      type #>   ------- #> 1       a #> 2 example #> 3     few #> 4  simple #> 5    with #> 6   words types_merge_all(tps1, tps2, tps3) #> Type collection of length 9 #>      type #>   ------- #> 1       a #> 2 example #> 3  simple #> 4     few #> 5    with #> 6   words #> 7     for #> 8    just #> 9 testing types_merge_all(list(tps1, tps2, tps3)) #> Type collection of length 9 #>      type #>   ------- #> 1       a #> 2 example #> 3  simple #> 4     few #> 5    with #> 6   words #> 7     for #> 8    just #> 9 testing"},{"path":"https://masterclm.github.io/mclm/reference/n_fnames.html","id":null,"dir":"Reference","previous_headings":"","what":"Count number of items in an 'fnames' object — n_fnames","title":"Count number of items in an 'fnames' object — n_fnames","text":"function counts number items, duplicated , fnames object. duplicated items, return warning.","code":""},{"path":"https://masterclm.github.io/mclm/reference/n_fnames.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Count number of items in an 'fnames' object — n_fnames","text":"","code":"n_fnames(x, ...)"},{"path":"https://masterclm.github.io/mclm/reference/n_fnames.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Count number of items in an 'fnames' object — n_fnames","text":"x Object class fnames. ... Additional arguments.","code":""},{"path":"https://masterclm.github.io/mclm/reference/n_fnames.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Count number of items in an 'fnames' object — n_fnames","text":"number.","code":""},{"path":"https://masterclm.github.io/mclm/reference/n_fnames.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Count number of items in an 'fnames' object — n_fnames","text":"","code":"cwd_fnames <- as_fnames(c(\"folder/file1.txt\", \"folder/file2.txt\", \"folder/file3.txt\")) n_fnames(cwd_fnames) #> [1] 3"},{"path":"https://masterclm.github.io/mclm/reference/n_tokens.html","id":null,"dir":"Reference","previous_headings":"","what":"Count tokens — n_tokens","title":"Count tokens — n_tokens","text":"method returns number tokens object.","code":""},{"path":"https://masterclm.github.io/mclm/reference/n_tokens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Count tokens — n_tokens","text":"","code":"n_tokens(x, ...)  # S3 method for freqlist n_tokens(x, ...)  # S3 method for tokens n_tokens(x, ...)"},{"path":"https://masterclm.github.io/mclm/reference/n_tokens.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Count tokens — n_tokens","text":"x object classes method implemented. ... Additional arguments.","code":""},{"path":"https://masterclm.github.io/mclm/reference/n_tokens.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Count tokens — n_tokens","text":"number.","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/n_tokens.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Count tokens — n_tokens","text":"","code":"(tks <- tokenize(\"The old man and the sea.\")) #> Token sequence of length 6 #> idx token #> --- ----- #>   1   the #>   2   old #>   3   man #>   4   and #>   5   the #>   6   sea n_tokens(tks) #> [1] 6  (flist <- freqlist(tks)) #> Frequency list (types in list: 5, tokens in list: 6) #> rank type abs_freq nrm_freq #> ---- ---- -------- -------- #>    1  the        2 3333.333 #>    2  and        1 1666.667 #>    3  man        1 1666.667 #>    4  old        1 1666.667 #>    5  sea        1 1666.667 n_tokens(flist) #> [1] 6 n_types(flist) #> [1] 5"},{"path":"https://masterclm.github.io/mclm/reference/n_types.html","id":null,"dir":"Reference","previous_headings":"","what":"Count types — n_types","title":"Count types — n_types","text":"method returns number types object.","code":""},{"path":"https://masterclm.github.io/mclm/reference/n_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Count types — n_types","text":"","code":"n_types(x, ...)  # S3 method for assoc_scores n_types(x, ...)  # S3 method for freqlist n_types(x, ...)  # S3 method for tokens n_types(x, ...)  # S3 method for types n_types(x, ...)"},{"path":"https://masterclm.github.io/mclm/reference/n_types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Count types — n_types","text":"x object classes method implemented. ... Additional arguments.","code":""},{"path":"https://masterclm.github.io/mclm/reference/n_types.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Count types — n_types","text":"number.","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/n_types.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Count types — n_types","text":"","code":"(tks <- tokenize(\"The old man and the sea.\")) #> Token sequence of length 6 #> idx token #> --- ----- #>   1   the #>   2   old #>   3   man #>   4   and #>   5   the #>   6   sea  # for a types object ---------- (tps <- types(tks)) #> Type collection of length 5 #>   type #>   ---- #> 1  the #> 2  and #> 3  man #> 4  old #> 5  sea n_types(tps) #> [1] 5  # for a freqlist object ------- (flist <- freqlist(tks)) #> Frequency list (types in list: 5, tokens in list: 6) #> rank type abs_freq nrm_freq #> ---- ---- -------- -------- #>    1  the        2 3333.333 #>    2  and        1 1666.667 #>    3  man        1 1666.667 #>    4  old        1 1666.667 #>    5  sea        1 1666.667 n_tokens(flist) #> [1] 6 n_types(flist) #> [1] 5  # for an assoc_scores object -- a <- c(10,    30,    15,    1) b <- c(200, 1000,  5000,  300) c <- c(100,   14,    16,    4) d <- c(300, 5000, 10000, 6000) types <- c(\"four\", \"fictitious\", \"toy\", \"examples\")  (scores <- assoc_abcd(a, b, c, d, types = types)) #> Association scores (types in list: 4) #>         type  a    PMI G_signed|   b   c     d dir  exp_a DP_rows #> 1       four 10 -1.921  -45.432| 200 100   300  -1 37.869  -0.202 #> 2 fictitious 30  2.000   56.959|1000  14  5000   1  7.498   0.026 #> 3        toy 15  0.536    2.984|5000  16 10000   1 10.343   0.001 #> 4   examples  1  2.067    1.473| 300   4  6000   1  0.239   0.003 #> <number of extra columns to the right: 7> #>  n_types(scores) #> [1] 4"},{"path":"https://masterclm.github.io/mclm/reference/orig_ranks.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve or set original ranks — orig_ranks","title":"Retrieve or set original ranks — orig_ranks","text":"methods retrieve set, original ranks frequency counts object. original ranks defined x result selection procedure (.e. x contains frequency counts selection items , tokens corpus).","code":""},{"path":"https://masterclm.github.io/mclm/reference/orig_ranks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve or set original ranks — orig_ranks","text":"","code":"orig_ranks(x, ...)  orig_ranks(x) <- value  # S3 method for freqlist orig_ranks(x) <- value  # S3 method for freqlist orig_ranks(x, with_names = FALSE, ...)  # S3 method for default orig_ranks(x) <- value"},{"path":"https://masterclm.github.io/mclm/reference/orig_ranks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve or set original ranks — orig_ranks","text":"x object classes method implemented. ... Additional arguments. value Currently can NULL. with_names Logical. Whether items output given names. TRUE, names types frequency list used names.","code":""},{"path":"https://masterclm.github.io/mclm/reference/orig_ranks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve or set original ranks — orig_ranks","text":"Either NULL numeric vector, representing original ranks, names types ranks apply.","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/orig_ranks.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve or set original ranks — orig_ranks","text":"","code":"x <- freqlist(\"The man and the mouse.\",               as_text = TRUE) x #> Frequency list (types in list: 4, tokens in list: 5) #> rank  type abs_freq nrm_freq #> ---- ----- -------- -------- #>    1   the        2     4000 #>    2   and        1     2000 #>    3   man        1     2000 #>    4 mouse        1     2000 orig_ranks(x) #> NULL orig_ranks(x, with_names = TRUE) #> NULL  y <- keep_types(x, c(\"man\", \"and\")) orig_ranks(y) #> [1] 3 2 y #> Frequency list (types in list: 2, tokens in list: 2) #> <total number of tokens: 5> #> rank orig_rank type abs_freq nrm_freq #> ---- --------- ---- -------- -------- #>    2         3  man        1     2000 #>    1         2  and        1     2000  orig_ranks(y) <- NULL y #> Frequency list (types in list: 2, tokens in list: 2) #> <total number of tokens: 5> #> rank type abs_freq nrm_freq #> ---- ---- -------- -------- #>    2  man        1     2000 #>    1  and        1     2000 orig_ranks(y) #> NULL  tot_n_tokens(y) <- sum(y) y #> Frequency list (types in list: 2, tokens in list: 2) #> rank type abs_freq nrm_freq #> ---- ---- -------- -------- #>    2  man        1     5000 #>    1  and        1     5000"},{"path":"https://masterclm.github.io/mclm/reference/p_to_chisq1.html","id":null,"dir":"Reference","previous_headings":"","what":"P right quantile in chi-squared distribution with 1 degree of freedom — p_to_chisq1","title":"P right quantile in chi-squared distribution with 1 degree of freedom — p_to_chisq1","text":"P right quantile takes argument probability p returns p right quantile \\(\\chi^2\\) distribution one degree freedom. words, returns value q proportion p \\(\\chi^2\\) distribution one degree freedom lies q.","code":""},{"path":"https://masterclm.github.io/mclm/reference/p_to_chisq1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"P right quantile in chi-squared distribution with 1 degree of freedom — p_to_chisq1","text":"","code":"p_to_chisq1(p)"},{"path":"https://masterclm.github.io/mclm/reference/p_to_chisq1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"P right quantile in chi-squared distribution with 1 degree of freedom — p_to_chisq1","text":"p proportion.","code":""},{"path":"https://masterclm.github.io/mclm/reference/p_to_chisq1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"P right quantile in chi-squared distribution with 1 degree of freedom — p_to_chisq1","text":"p  right quantile \\(\\chi^2\\) distribution one degree freedom.","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/perl_flavor.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve or set the flavor of a regular expression — perl_flavor","title":"Retrieve or set the flavor of a regular expression — perl_flavor","text":"functions retrieve set perl property object class re.","code":""},{"path":"https://masterclm.github.io/mclm/reference/perl_flavor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve or set the flavor of a regular expression — perl_flavor","text":"","code":"perl_flavor(x)  perl_flavor(x) <- value"},{"path":"https://masterclm.github.io/mclm/reference/perl_flavor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve or set the flavor of a regular expression — perl_flavor","text":"x Object class re. value Logical.","code":""},{"path":"https://masterclm.github.io/mclm/reference/perl_flavor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve or set the flavor of a regular expression — perl_flavor","text":"logical vector length 1.","code":""},{"path":"https://masterclm.github.io/mclm/reference/perl_flavor.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Retrieve or set the flavor of a regular expression — perl_flavor","text":"assignment function merely sets perl property x attribute read expression using PCRE flavor regular expression (perl = TRUE) (perl = FALSE). regular expression modified: perl set inappropriate value, regular expression longer function properly functions support re objects.","code":""},{"path":"https://masterclm.github.io/mclm/reference/perl_flavor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve or set the flavor of a regular expression — perl_flavor","text":"","code":"(regex <- re(\"^.{3,}\")) #> Regular expression (perl = TRUE) #> ------------------ #> ^.{3,}  perl_flavor(regex) #> [1] TRUE  perl_flavor(regex) <- FALSE perl_flavor(regex) #> [1] FALSE regex #> Regular expression (perl = FALSE) #> ------------------ #> ^.{3,}   perl_flavor(regex) <- TRUE perl_flavor(regex) #> [1] TRUE regex #> Regular expression (perl = TRUE) #> ------------------ #> ^.{3,}"},{"path":"https://masterclm.github.io/mclm/reference/print_kwic.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a concordance in KWIC format — print_kwic","title":"Print a concordance in KWIC format — print_kwic","text":"function prints concordance KWIC format.","code":""},{"path":"https://masterclm.github.io/mclm/reference/print_kwic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a concordance in KWIC format — print_kwic","text":"","code":"print_kwic(   x,   min_c_left = NA,   max_c_left = NA,   min_c_match = NA,   max_c_match = NA,   min_c_right = NA,   max_c_right = NA,   from = 1,   n = 30,   drop_tags = TRUE )"},{"path":"https://masterclm.github.io/mclm/reference/print_kwic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a concordance in KWIC format — print_kwic","text":"x object class conc. min_c_left, max_c_left Minimum maximum size, expressed number characters, left co-text KWIC display. min_c_match, max_c_match Minimum maximum size, expressed number characters, match KWIC display. min_c_right, max_c_right Minimum maximum size, expressed number characters, right co-text KWIC display. Index first item x displayed. n Number consecutive items x displayed. drop_tags Logical. tags hidden?","code":""},{"path":"https://masterclm.github.io/mclm/reference/print_kwic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print a concordance in KWIC format — print_kwic","text":"Invisibly, x.","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/ranks.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve the current ranks for frequency counts. — ranks","title":"Retrieve the current ranks for frequency counts. — ranks","text":"ranks retrieves ranks items object. ranks integer values running one number items x. items receives unique rank. Items first ranked frequency descending order. Items identical frequency ranked alphabetic order.","code":""},{"path":"https://masterclm.github.io/mclm/reference/ranks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve the current ranks for frequency counts. — ranks","text":"","code":"ranks(x, ...)  # S3 method for freqlist ranks(x, with_names = FALSE, ...)"},{"path":"https://masterclm.github.io/mclm/reference/ranks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve the current ranks for frequency counts. — ranks","text":"x object classes method implemented. ... Additional arguments. with_names Logical. Whether items output given names. TRUE, names types frequency list used names.","code":""},{"path":"https://masterclm.github.io/mclm/reference/ranks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve the current ranks for frequency counts. — ranks","text":"Numeric vector representing current ranks, names types ranks apply.","code":""},{"path":"https://masterclm.github.io/mclm/reference/ranks.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Retrieve the current ranks for frequency counts. — ranks","text":"mclm method ranks() confused base::rank(). two important differences. First,base::rank() always ranks items low values high values ranks() ranks high frequency items low frequency items. Second, base::rank() allows user choose among number different ways handle ties. contrast, ranks() always handles ties way. specifically, items identical frequencies always ranked alphabetical order. words, base::rank() flexible tool supports number different ranking methods commonly used statistics. contrast, ranks() rigid tool supports one type ranking, type ranking atypical statistics point view, commonly used linguistic frequency lists. Also, designed unaffected order items frequency list.","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/ranks.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve the current ranks for frequency counts. — ranks","text":"","code":"(flist <- freqlist(\"The man and the mouse.\", as_text = TRUE)) #> Frequency list (types in list: 4, tokens in list: 5) #> rank  type abs_freq nrm_freq #> ---- ----- -------- -------- #>    1   the        2     4000 #>    2   and        1     2000 #>    3   man        1     2000 #>    4 mouse        1     2000  orig_ranks(flist) #> NULL ranks(flist) #> [1] 1 2 3 4 ranks(flist, with_names = TRUE) #>   the   and   man mouse  #>     1     2     3     4   (flist2 <- keep_types(flist, c(\"man\", \"and\"))) #> Frequency list (types in list: 2, tokens in list: 2) #> <total number of tokens: 5> #> rank orig_rank type abs_freq nrm_freq #> ---- --------- ---- -------- -------- #>    2         3  man        1     2000 #>    1         2  and        1     2000  orig_ranks(flist2) #> [1] 3 2 ranks(flist2) #> [1] 2 1"},{"path":"https://masterclm.github.io/mclm/reference/re.html","id":null,"dir":"Reference","previous_headings":"","what":"Build a regular expression — re","title":"Build a regular expression — re","text":"Create object class re coerce character vector object class re.","code":""},{"path":"https://masterclm.github.io/mclm/reference/re.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build a regular expression — re","text":"","code":"re(x, perl = TRUE, ...)  as_re(x, perl = TRUE, ...)  as.re(x, perl = TRUE, ...)"},{"path":"https://masterclm.github.io/mclm/reference/re.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build a regular expression — re","text":"x Character vector length one. value character vector assumed well-formed regular expression. current implementation assumed, checked. perl Logical. TRUE, x assumed use PCRE (.e. Perl Compatible Regular Expressions) notation. FALSE, x assumed use base R's default regular expression notation. Contrary base R's regular expression functions, re() assumes PCRE regular expression flavor used default. ... Additional arguments.","code":""},{"path":"https://masterclm.github.io/mclm/reference/re.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build a regular expression — re","text":"object class re, wrapper around character vector flagging containing regular expression. essence named list: x item contains x input perl item contains value perl argument (TRUE default). basic methods print(), summary() .character().","code":""},{"path":"https://masterclm.github.io/mclm/reference/re.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Build a regular expression — re","text":"class exists functions mclm package require arguments marked regular expressions. example, keep_re() need pattern argument re object, user wants subset items brackets using regular expression, must use re object.","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/re.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build a regular expression — re","text":"","code":"toy_corpus <- \"Once upon a time there was a tiny toy corpus.   It consisted of three sentences. And it lived happily ever after.\"  (tks <- tokenize(toy_corpus)) #> Token sequence of length 21 #> idx     token #> --- --------- #>   1      once #>   2      upon #>   3         a #>   4      time #>   5     there #>   6       was #>   7         a #>   8      tiny #>   9       toy #>  10    corpus #>  11        it #>  12 consisted #>  13        of #>  14     three #>  15 sentences #>  16       and #>  17        it #>  18     lived #>  19   happily #>  20      ever #> ... #>   # In `keep_re()`, the use of `re()` is optional keep_re(tks, re(\"^.{3,}\")) #> Token sequence of length 16 #> idx     token #> --- --------- #>   1      once #>   2      upon #>   3      time #>   4     there #>   5       was #>   6      tiny #>   7       toy #>   8    corpus #>   9 consisted #>  10     three #>  11 sentences #>  12       and #>  13     lived #>  14   happily #>  15      ever #>  16     after keep_re(tks, \"^.{3,}\") #> Token sequence of length 16 #> idx     token #> --- --------- #>   1      once #>   2      upon #>   3      time #>   4     there #>   5       was #>   6      tiny #>   7       toy #>   8    corpus #>   9 consisted #>  10     three #>  11 sentences #>  12       and #>  13     lived #>  14   happily #>  15      ever #>  16     after  # When using brackets notation, `re()` is necessary tks[re(\"^.{3,}\")] #> Token sequence of length 16 #> idx     token #> --- --------- #>   1      once #>   2      upon #>   3      time #>   4     there #>   5       was #>   6      tiny #>   7       toy #>   8    corpus #>   9 consisted #>  10     three #>  11 sentences #>  12       and #>  13     lived #>  14   happily #>  15      ever #>  16     after tks[\"^.{3,}\"] #> Token sequence of length 0 #>   # build and print a `re` object re(\"^.{3,}\") #> Regular expression (perl = TRUE) #> ------------------ #> ^.{3,}  as_re(\"^.{3,}\") #> Regular expression (perl = TRUE) #> ------------------ #> ^.{3,}  as.re(\"^.{3,}\") #> Regular expression (perl = TRUE) #> ------------------ #> ^.{3,}  print(re(\"^.{3,}\")) #> Regular expression (perl = TRUE) #> ------------------ #> ^.{3,}"},{"path":"https://masterclm.github.io/mclm/reference/re_convenience.html","id":null,"dir":"Reference","previous_headings":"","what":"Convenience functions in support of regular expressions — re_convenience","title":"Convenience functions in support of regular expressions — re_convenience","text":"functions essentially simple wrappers around base R functions regexpr(), gregexpr(), grepl(), grep(), sub() gsub(). important differences functions documented R base functions order arguments (x pattern) fact argument perl set TRUE default.","code":""},{"path":"https://masterclm.github.io/mclm/reference/re_convenience.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convenience functions in support of regular expressions — re_convenience","text":"","code":"re_retrieve_first(   x,   pattern,   ignore.case = FALSE,   perl = TRUE,   fixed = FALSE,   useBytes = FALSE,   requested_group = NULL,   drop_NA = FALSE,   ... )  re_retrieve_last(   x,   pattern,   ignore.case = FALSE,   perl = TRUE,   fixed = FALSE,   useBytes = FALSE,   requested_group = NULL,   drop_NA = FALSE,   ... )  re_retrieve_all(   x,   pattern,   ignore.case = FALSE,   perl = TRUE,   fixed = FALSE,   useBytes = FALSE,   requested_group = NULL,   unlist = TRUE,   ... )  re_has_matches(   x,   pattern,   ignore.case = FALSE,   perl = TRUE,   fixed = FALSE,   useBytes = FALSE,   ... )  re_which(   x,   pattern,   ignore.case = FALSE,   perl = TRUE,   fixed = FALSE,   useBytes = FALSE,   ... )  re_replace_first(   x,   pattern,   replacement,   ignore.case = FALSE,   perl = TRUE,   fixed = FALSE,   useBytes = FALSE,   ... )  re_replace_all(   x,   pattern,   replacement,   ignore.case = FALSE,   perl = TRUE,   fixed = FALSE,   useBytes = FALSE,   ... )"},{"path":"https://masterclm.github.io/mclm/reference/re_convenience.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convenience functions in support of regular expressions — re_convenience","text":"x Character vector searched modified. pattern Regular expression specifying searched. ignore.case Logical. search case insensitive? perl Logical. Whether regular expressions use PCRE flavor regular expression. Unlike base R functions, default TRUE. fixed Logical. TRUE, pattern string matched , .e. wildcards special characters interpreted. useBytes Logical. TRUE matching done byte--byte rather character--character. See 'Details' grep(). requested_group Numeric. NULL 0, output contain matches pattern whole. another number n provided, output contain matches pattern instead contain matches nth capturing group pattern (first requested_group = 1, second requested_group = 2...). drop_NA Logical. FALSE, output always length input x items contain match pattern yield NA. TRUE, NA values removed therefore result might contain fewer items x. ... Additional arguments. unlist Logical. FALSE, output always length input x. specifically, result list input items contain match pattern yield empty vector, whereas input items match yield vector least length one (depending number matches). TRUE, output single vector length may shorter longer x. replacement Character vector length one specifying replacement string. taken literally, except notation \\\\1, \\\\2, etc. can used refer groups pattern.","code":""},{"path":"https://masterclm.github.io/mclm/reference/re_convenience.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convenience functions in support of regular expressions — re_convenience","text":"re_retrieve_first(), re_retrieve_last() re_retrieve_all() return either single vector character data list containing vectors. re_replace_first() re_replace_all() return type character vector x. re_has_matches() returns logical vector indicating whether match found elements x; re_which() returns numeric vector indicating indices elements x match found.","code":""},{"path":"https://masterclm.github.io/mclm/reference/re_convenience.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convenience functions in support of regular expressions — re_convenience","text":"arguments (e.g. perl, fixed) reader directed base R's regex documentation.","code":""},{"path":"https://masterclm.github.io/mclm/reference/re_convenience.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Convenience functions in support of regular expressions — re_convenience","text":"re_retrieve_first(): Retrieve item x first match pattern. re_retrieve_last(): Retrieve item x last match pattern. re_retrieve_all(): Retrieve item x matches pattern. re_has_matches(): Simple wrapper around grepl(). re_which(): Simple wrapper around grep(). re_replace_first(): Simple wrapper around sub(). re_replace_all(): Simple wrapper around gsub().","code":""},{"path":"https://masterclm.github.io/mclm/reference/re_convenience.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convenience functions in support of regular expressions — re_convenience","text":"","code":"x <- tokenize(\"This is a sentence with a couple of words in it.\") pattern <- \"[oe](.)(.)\"  re_retrieve_first(x, pattern) #>  [1] NA    NA    NA    \"ent\" NA    NA    \"oup\" NA    \"ord\" NA    NA    re_retrieve_first(x, pattern, drop_NA = TRUE) #> [1] \"ent\" \"oup\" \"ord\" re_retrieve_first(x, pattern, requested_group = 1) #>  [1] NA  NA  NA  \"n\" NA  NA  \"u\" NA  \"r\" NA  NA  re_retrieve_first(x, pattern, drop_NA = TRUE, requested_group = 1) #> [1] \"n\" \"u\" \"r\" re_retrieve_first(x, pattern, requested_group = 2) #>  [1] NA  NA  NA  \"t\" NA  NA  \"p\" NA  \"d\" NA  NA   re_retrieve_last(x, pattern) #>  [1] NA    NA    NA    \"enc\" NA    NA    \"oup\" NA    \"ord\" NA    NA    re_retrieve_last(x, pattern, drop_NA = TRUE) #> [1] \"enc\" \"oup\" \"ord\" re_retrieve_last(x, pattern, requested_group = 1) #>  [1] NA  NA  NA  \"n\" NA  NA  \"u\" NA  \"r\" NA  NA  re_retrieve_last(x, pattern, drop_NA = TRUE, requested_group = 1) #> [1] \"n\" \"u\" \"r\" re_retrieve_last(x, pattern, requested_group = 2) #>  [1] NA  NA  NA  \"c\" NA  NA  \"p\" NA  \"d\" NA  NA   re_retrieve_all(x, pattern) #> [1] \"ent\" \"enc\" \"oup\" \"ord\" re_retrieve_all(x, pattern, unlist = FALSE) #> [[1]] #> character(0) #>  #> [[2]] #> character(0) #>  #> [[3]] #> character(0) #>  #> [[4]] #> [1] \"ent\" \"enc\" #>  #> [[5]] #> character(0) #>  #> [[6]] #> character(0) #>  #> [[7]] #> [1] \"oup\" #>  #> [[8]] #> character(0) #>  #> [[9]] #> [1] \"ord\" #>  #> [[10]] #> character(0) #>  #> [[11]] #> character(0) #>  re_retrieve_all(x, pattern, requested_group = 1) #> [1] \"n\" \"n\" \"u\" \"r\" re_retrieve_all(x, pattern, unlist = FALSE, requested_group = 1) #> [[1]] #> character(0) #>  #> [[2]] #> character(0) #>  #> [[3]] #> character(0) #>  #> [[4]] #> [1] \"n\" \"n\" #>  #> [[5]] #> character(0) #>  #> [[6]] #> character(0) #>  #> [[7]] #> [1] \"u\" #>  #> [[8]] #> character(0) #>  #> [[9]] #> [1] \"r\" #>  #> [[10]] #> character(0) #>  #> [[11]] #> character(0) #>  re_retrieve_all(x, pattern, requested_group = 2) #> [1] \"t\" \"c\" \"p\" \"d\"  re_replace_first(x, \"([oe].)\", \"{\\\\1}\") #> Token sequence of length 11 #> idx      token #> --- ---------- #>   1       this #>   2         is #>   3          a #>   4 s{en}tence #>   5       with #>   6          a #>   7   c{ou}ple #>   8       {of} #>   9    w{or}ds #>  10         in #>  11         it re_replace_all(x, \"([oe].)\", \"{\\\\1}\") #> Token sequence of length 11 #> idx        token #> --- ------------ #>   1         this #>   2           is #>   3            a #>   4 s{en}t{en}ce #>   5         with #>   6            a #>   7     c{ou}ple #>   8         {of} #>   9      w{or}ds #>  10           in #>  11           it"},{"path":"https://masterclm.github.io/mclm/reference/read_assoc.html","id":null,"dir":"Reference","previous_headings":"","what":"Read association scores from file — read_assoc","title":"Read association scores from file — read_assoc","text":"function reads file written write_assoc().","code":""},{"path":"https://masterclm.github.io/mclm/reference/read_assoc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read association scores from file — read_assoc","text":"","code":"read_assoc(file, sep = \"\\t\", file_encoding = \"UTF-8\", ...)"},{"path":"https://masterclm.github.io/mclm/reference/read_assoc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read association scores from file — read_assoc","text":"file Path input file. sep Field separator input file. file_encoding Encoding input file. ... Additional arguments.","code":""},{"path":"https://masterclm.github.io/mclm/reference/read_assoc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read association scores from file — read_assoc","text":"object class assoc_scores.","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/read_assoc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read association scores from file — read_assoc","text":"","code":"if (FALSE) { txt1 <- \"we're just two lost souls swimming in a fish bowl, year after year, running over the same old ground, what have we found? the same old fears. wish you were here.\" flist1 <- freqlist(txt1, as_text = TRUE) txt2 <- \"picture yourself in a boat on a river with tangerine dreams and marmelade skies somebody calls you, you answer quite slowly a girl with kaleidoscope eyes\" flist2 <- freqlist(txt2, as_text = TRUE) (scores <- assoc_scores(flist1, flist2, min_freq = 0)) write_assoc(scores, \"example_scores.tab\") (scores2 <- read_assoc(\"example_scores.tab\")) }"},{"path":"https://masterclm.github.io/mclm/reference/read_conc.html","id":null,"dir":"Reference","previous_headings":"","what":"Read a concordance from a file — read_conc","title":"Read a concordance from a file — read_conc","text":"function reads concordance-based data frames written file function write_conc().","code":""},{"path":"https://masterclm.github.io/mclm/reference/read_conc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read a concordance from a file — read_conc","text":"","code":"read_conc(   file,   sep = \"\\t\",   file_encoding = \"UTF-8\",   stringsAsFactors = FALSE,   ... )"},{"path":"https://masterclm.github.io/mclm/reference/read_conc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read a concordance from a file — read_conc","text":"file Name input file. sep Field separator used input file. file_encoding Encoding input file. stringsAsFactors Logical. Whether character data automatically converted factors. applies columns except \"source\", \"left\", \"match\" \"right\", never converted. ... Additional arguments, implemented.","code":""},{"path":"https://masterclm.github.io/mclm/reference/read_conc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read a concordance from a file — read_conc","text":"Object class conc.","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/read_conc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read a concordance from a file — read_conc","text":"","code":"if (FALSE) { (d <- conc('A very small corpus.', '\\\\w+', as_text = TRUE)) write_conc(d, \"example_data.tab\") (d2 <- read_conc(\"example_data.tab\")) }"},{"path":"https://masterclm.github.io/mclm/reference/read_fnames.html","id":null,"dir":"Reference","previous_headings":"","what":"Read a collection of filenames from a text file — read_fnames","title":"Read a collection of filenames from a text file — read_fnames","text":"function reads object class fnames text file, assumed contain one filename line.","code":""},{"path":"https://masterclm.github.io/mclm/reference/read_fnames.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read a collection of filenames from a text file — read_fnames","text":"","code":"read_fnames(file, sep = NA, file_encoding = \"UTF-8\", trim_fnames = FALSE, ...)"},{"path":"https://masterclm.github.io/mclm/reference/read_fnames.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read a collection of filenames from a text file — read_fnames","text":"file Path input file. sep Character vector length 1 NA. character, indicates separator input files, addition new line. file_encoding Encoding used input file. trim_fnames Boolean. leading trailing whitespace stripped filenames? ... Additional arguments (implemented).","code":""},{"path":"https://masterclm.github.io/mclm/reference/read_fnames.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read a collection of filenames from a text file — read_fnames","text":"object class fnames.","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/read_fnames.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read a collection of filenames from a text file — read_fnames","text":"","code":"if (FALSE) { cwd_fnames <- get_fnames(recursive = FALSE) write_fnames(cwd_fnames, \"file_with_filenames.txt\") cwd_fnames_2 <- read_fnames(\"file_with_filenames.txt\") }"},{"path":"https://masterclm.github.io/mclm/reference/read_freqlist.html","id":null,"dir":"Reference","previous_headings":"","what":"Read a frequency list from a csv file — read_freqlist","title":"Read a frequency list from a csv file — read_freqlist","text":"function reads object class freqlist csv file. csv file assumed contain two columns, first type second frequency type. file also assumed header line names columns.","code":""},{"path":"https://masterclm.github.io/mclm/reference/read_freqlist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read a frequency list from a csv file — read_freqlist","text":"","code":"read_freqlist(file, sep = \"\\t\", file_encoding = \"UTF-8\", ...)"},{"path":"https://masterclm.github.io/mclm/reference/read_freqlist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read a frequency list from a csv file — read_freqlist","text":"file Character vector length 1. Path input file. sep Character vector length 1. Column separator. file_encoding File encoding used input file. ... Additional arguments (implemented).","code":""},{"path":"https://masterclm.github.io/mclm/reference/read_freqlist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read a frequency list from a csv file — read_freqlist","text":"Object class freqlist.","code":""},{"path":"https://masterclm.github.io/mclm/reference/read_freqlist.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Read a frequency list from a csv file — read_freqlist","text":"read_freqlist reads file file, also checks whether configuration file exists name identical file, except filename extension \".yaml\". file exists, configuration file taken 'belong' file also read frequency list attributes \"tot_n_tokens\" \"tot_n_types\" retrieved . configuration file exists, values \"tot_n_tokens\" \"tot_n_types\" calculated basis frequencies frequency list.","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/read_freqlist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read a frequency list from a csv file — read_freqlist","text":"","code":"if (FALSE) { toy_corpus <- \"Once upon a time there was a tiny toy corpus. It consisted of three sentences. And it lived happily ever after.\" freqs <- freqlist(toy_corpus, as_text = TRUE)  print(freqs, n = 1000) write_freqlist(freqs, \"example_freqlist.csv\") freqs2 <- read_freqlist(\"example_freqlist.csv\") print(freqs2, n = 1000) }"},{"path":"https://masterclm.github.io/mclm/reference/read_tokens.html","id":null,"dir":"Reference","previous_headings":"","what":"Read a tokens object from a text file — read_tokens","title":"Read a tokens object from a text file — read_tokens","text":"function reads object class tokens text file, typically stored write_tokens(). text file assumed contain one token line header.","code":""},{"path":"https://masterclm.github.io/mclm/reference/read_tokens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read a tokens object from a text file — read_tokens","text":"","code":"read_tokens(file, file_encoding = \"UTF-8\", ...)"},{"path":"https://masterclm.github.io/mclm/reference/read_tokens.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read a tokens object from a text file — read_tokens","text":"file Name input file. file_encoding Encoding read input file. ... Additional arguments (implemented).","code":""},{"path":"https://masterclm.github.io/mclm/reference/read_tokens.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read a tokens object from a text file — read_tokens","text":"object class tokens.","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/read_tokens.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read a tokens object from a text file — read_tokens","text":"","code":"if (FALSE) { (tks <- tokenize(\"The old man and the sea.\")) write_tokens(tks, \"file_with_tokens.txt\") (tks2 <- read_tokens(\"file_with_tokens.txt\")) }"},{"path":"https://masterclm.github.io/mclm/reference/read_txt.html","id":null,"dir":"Reference","previous_headings":"","what":"Read a text file into a character vector — read_txt","title":"Read a text file into a character vector — read_txt","text":"function reads text file returns character vector containing lines text file.","code":""},{"path":"https://masterclm.github.io/mclm/reference/read_txt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read a text file into a character vector — read_txt","text":"","code":"read_txt(file, file_encoding = \"UTF-8\", line_glue = NA, ...)"},{"path":"https://masterclm.github.io/mclm/reference/read_txt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read a text file into a character vector — read_txt","text":"file Name input file. file_encoding Encoding input file. line_glue character vector NA. NA, output character vector input line separate item, readr::read_lines(). Otherwise, output character vector length 1 input lines concatenated, using value line_glue[1] line separator end--last-line marker. ... Additional arguments (implemented).","code":""},{"path":"https://masterclm.github.io/mclm/reference/read_txt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read a text file into a character vector — read_txt","text":"character vector.","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/read_txt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read a text file into a character vector — read_txt","text":"","code":"if (FALSE) { x <- \"This is a small text.\"  # write the text to a text file write_txt(x, \"example-text-file.txt\") # read a text from file y <- read_txt(\"example-text-file.txt\") y }"},{"path":"https://masterclm.github.io/mclm/reference/read_types.html","id":null,"dir":"Reference","previous_headings":"","what":"Read a vector of types from a text file — read_types","title":"Read a vector of types from a text file — read_types","text":"function read object class types text file. default, text file assumed contain one type line.","code":""},{"path":"https://masterclm.github.io/mclm/reference/read_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read a vector of types from a text file — read_types","text":"","code":"read_types(   file,   sep = NA,   file_encoding = \"UTF-8\",   trim_types = FALSE,   remove_duplicates = FALSE,   sort = FALSE,   ... )"},{"path":"https://masterclm.github.io/mclm/reference/read_types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read a vector of types from a text file — read_types","text":"file Name input file. sep .na(sep), sep must character vector length one. case, sep interpreted type separator input file. separator serves additional type separator, next end line. end line always indicated separator types (words, types cross lines). file_encoding file encoding used input file. trim_types Logical. leading trailing white space stripped types. remove_duplicates Logical. duplicates removed x prior coercing vector types. sort Logical. x alphabetically sorted prior coercing vector types; argument ignored remove_duplicates TRUE, result removing duplicates always sorted. ... Additional arguments (implemented).","code":""},{"path":"https://masterclm.github.io/mclm/reference/read_types.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read a vector of types from a text file — read_types","text":"Object class types.","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/read_types.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read a vector of types from a text file — read_types","text":"","code":"if (FALSE) {   types <- as_types(c(\"first\", \"second\", \"third\"))   write_types(types, \"file_with_types.txt\")   types_2 <- read_types(\"file_with_types.txt\")   }"},{"path":"https://masterclm.github.io/mclm/reference/scan_re.html","id":null,"dir":"Reference","previous_headings":"","what":"Scan a regular expression from console — scan_re","title":"Scan a regular expression from console — scan_re","text":"functions scan_re() scan_re2() can used scan regular expression console.","code":""},{"path":"https://masterclm.github.io/mclm/reference/scan_re.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Scan a regular expression from console — scan_re","text":"","code":"scan_re(perl = TRUE, ...)  scan_re2(perl = TRUE, ...)"},{"path":"https://masterclm.github.io/mclm/reference/scan_re.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Scan a regular expression from console — scan_re","text":"perl Logical. TRUE, regular expression scanned assumed use PCRE (Perl Compatible Regular Expressions) notation. FALSE, assumed use base R's default regular expression notation (see base::regex). Contrary base R's regular expression functions, default TRUE. ... Additional arguments.","code":""},{"path":"https://masterclm.github.io/mclm/reference/scan_re.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Scan a regular expression from console — scan_re","text":"object class re.","code":""},{"path":"https://masterclm.github.io/mclm/reference/scan_re.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Scan a regular expression from console — scan_re","text":"function call, R continue scanning input encounters empty input line, .e. encounters two consecutive newline symbols (encounters line nothing whitespace characters). words, press ENTER twice row want stop inputting characters. function return input character vector length one. functions designed allow input complex text, particular regular expressions, without dealing restrictions string literals, use \\\\ \\.","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/scan_txt.html","id":null,"dir":"Reference","previous_headings":"","what":"Scan a character string from console — scan_txt","title":"Scan a character string from console — scan_txt","text":"functions scan_txt() scan_txt2(), take arguments, can used scan text string console.","code":""},{"path":"https://masterclm.github.io/mclm/reference/scan_txt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Scan a character string from console — scan_txt","text":"","code":"scan_txt()  scan_txt2()"},{"path":"https://masterclm.github.io/mclm/reference/scan_txt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Scan a character string from console — scan_txt","text":"character vector length one contains string scanned console.","code":""},{"path":"https://masterclm.github.io/mclm/reference/scan_txt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Scan a character string from console — scan_txt","text":"function call, R continue scanning input encounters empty input line, .e. encounters two consecutive newline symbols (encounters line nothing whitespace characters). words, press ENTER twice row want stop inputting characters. function return input character vector length one. functions designed allow input complex text, particular regular expressions, without dealing restrictions string literals, use \\\\ \\.","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/short_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Shorten filenames — short_names","title":"Shorten filenames — short_names","text":"Helper functions make paths file shorter.","code":""},{"path":"https://masterclm.github.io/mclm/reference/short_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Shorten filenames — short_names","text":"","code":"drop_path(x, ...)  drop_extension(x, ...)  short_names(x, ...)"},{"path":"https://masterclm.github.io/mclm/reference/short_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Shorten filenames — short_names","text":"x object class fnames character vector. ... Additional arguments.","code":""},{"path":"https://masterclm.github.io/mclm/reference/short_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Shorten filenames — short_names","text":"object class x.","code":""},{"path":"https://masterclm.github.io/mclm/reference/short_names.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Shorten filenames — short_names","text":"drop_path(): Extract base name path, removing paths leading . drop_extension(): Remove extension filename. short_names(): Remove paths leading file extension.","code":""},{"path":"https://masterclm.github.io/mclm/reference/short_names.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Shorten filenames — short_names","text":"","code":"cwd_fnames <- as_fnames(c(\"folder/file1.txt\", \"folder/file2.txt\", \"folder/file3.txt\")) drop_path(cwd_fnames) #> Filename collection of length 3 #>    filename #>   --------- #> 1 file1.txt #> 2 file2.txt #> 3 file3.txt drop_extension(cwd_fnames) #> Filename collection of length 3 #>       filename #>   ------------ #> 1 folder/file1 #> 2 folder/file2 #> 3 folder/file3 short_names(cwd_fnames) # same as drop_path(drop_extension(cwd_fnames)) #> Filename collection of length 3 #>   filename #>   -------- #> 1    file1 #> 2    file2 #> 3    file3"},{"path":"https://masterclm.github.io/mclm/reference/slma.html","id":null,"dir":"Reference","previous_headings":"","what":"Stable lexical marker analysis — slma","title":"Stable lexical marker analysis — slma","text":"function conducts stable lexical marker analysis.","code":""},{"path":"https://masterclm.github.io/mclm/reference/slma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stable lexical marker analysis — slma","text":"","code":"slma(   x,   y,   file_encoding = \"UTF-8\",   sig_cutoff = qchisq(0.95, df = 1),   small_pos = 1e-05,   keep_intermediate = FALSE,   verbose = TRUE,   min_rank = 1,   max_rank = 5000,   keeplist = NULL,   stoplist = NULL,   ngram_size = NULL,   max_skip = 0,   ngram_sep = \"_\",   ngram_n_open = 0,   ngram_open = \"[]\",   ... )"},{"path":"https://masterclm.github.io/mclm/reference/slma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stable lexical marker analysis — slma","text":"x, y Character vector fnames object filenames two sets documents. file_encoding Encoding files read. sig_cutoff Numeric value indicating cutoff value 'significance stable lexical marker analysis. default value qchist(.95, df = 1), 3.84. small_pos Alternative (sometimes inferior) approach dealing zero frequencies, compared haldane. argument small_pos applies haldane set FALSE. (See Details section.) haldane FALSE, least one zero frequency contingency table, adding small positive values zero frequency cells done systematically measures calculated table, just measures need done. keep_intermediate Logical. TRUE, results intermediate calculations kept output \"intermediate\" element. necessary want inspect object details() method. verbose Logical. Whether progress printed console analysis. min_rank, max_rank Minimum maximum frequency rank first corpus (x) items take consideration candidate stable markers. tokens token n-grams frequency rank greater equal min_rank lower equal max_rank included. keeplist List types must certainly included list candidate markers regardless frequency rank stoplist. stoplist List types must included list candidate markers, although, type included keeplist, inclusion stoplist disregarded. ngram_size Argument support ngrams/skipgrams (see also max_skip). one wants identify individual tokens, value ngram_size NULL 1. one wants retrieve token ngrams/skipgrams, ngram_size integer indicating size ngrams/skipgrams. E.g. 2 bigrams, 3 trigrams, etc. max_skip Argument support skipgrams. argument ignored ngram_size NULL 1. ngram_size 2 higher, max_skip 0, regular ngrams retrieved (albeit may contain open slots; see ngram_n_open). ngram_size 2 higher, max_skip 1 higher, skipgrams retrieved (current implementation contain open slots; see ngram_n_open). instance, ngram_size 3 max_skip 2, 2-skip trigrams retrieved. ngram_size 5 max_skip 3, 3-skip 5-grams retrieved. ngram_sep Character vector length 1 containing string used separate/link tokens representation ngrams/skipgrams output function. ngram_n_open ngram_size 2 higher, moreover ngram_n_open number higher 0, ngrams 'open slots' retrieved. ngrams 'open slots' generalizations fully lexically specific ngrams (generalization one items ngram replaced notation stands 'arbitrary token'). instance, ngram_size 4 ngram_n_open 1, moreover input contains 4-gram \"it_is_widely_accepted\", output contain modifications \"it_is_widely_accepted\" one (since ngram_n_open 1) items n-gram replaced open slot. first last item inside ngram never turned open slot; items candidates turned open slots. Therefore, example, output contain \"it_[]_widely_accepted\" \"it_is_[]_accepted\". second example, ngram_size 5 ngram_n_open 2, moreover input contains 5-gram \"it_is_widely_accepted_that\", output contain \"it_[]_[]_accepted_that\", \"it_[]_widely_[]_that\", \"it_is_[]_[]_that\". ngram_open Character string used represent open slots ngrams output function. ... Additional arguments.","code":""},{"path":"https://masterclm.github.io/mclm/reference/slma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stable lexical marker analysis — slma","text":"object class slma, named list least following elements: scores dataframe information stability chosen lexical items. (See .) intermediate list register intermediate values keep_intermediate TRUE. Named items registering values arguments name, namely sig_cutoff, small_pos, x, y. slma object as_data_frame() print methods well ad-hoc details() method. Note print method simply prints main dataframe.","code":""},{"path":"https://masterclm.github.io/mclm/reference/slma.html","id":"contents-of-the-scores-element","dir":"Reference","previous_headings":"","what":"Contents of the scores element","title":"Stable lexical marker analysis — slma","text":"scores element dataframe rows linguistic items stable lexical marker analysis conducted columns different 'stability measures' related statistics. default, linguistic items sorted decreasing 'stability' according S_lor measure. S_lor computed fraction numerator sum log_OR values across \\((,b)\\) couples p_G lower sig_cutoff denominator \\(n*m\\). log_OR, see Value section assoc_scores(). final three columns output meant tool support interpretation log_OR column. Considering \\((,b)\\) couples p_G smaller sig_cutoff, lor_min, lor_max lor_sd minimum, maximum standard deviation element.","code":""},{"path":"https://masterclm.github.io/mclm/reference/slma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Stable lexical marker analysis — slma","text":"stable lexical marker analysis -documents x versus B-documents y starts separate keyword analysis possible document couples \\((,b)\\), -document b B-document. n -documents m B-documents, \\(n*m\\) keyword analyses conducted. 'stability' linguistic item x, marker collection -documents (compared B-documents) corresponds frequency consistency x found keyword -documents across aforementioned keyword analyses. specific keyword analysis, x considered keyword -document G_signed positive moreover p_G less sig_cutoff (see assoc_scores() information measures). Item x considered keyword B-document G_signed negative moreover p_G less sig_cutoff.","code":""},{"path":"https://masterclm.github.io/mclm/reference/slma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Stable lexical marker analysis — slma","text":"","code":"a_corp <- get_fnames(system.file(\"extdata\", \"cleveland\", package = \"mclm\")) b_corp <- get_fnames(system.file(\"extdata\", \"roosevelt\", package = \"mclm\")) slma_ex <- slma(a_corp, b_corp) #> building global frequency list for x #> .... #> building separate frequency lists for each document #> .... #> ..... #> calculating assoc scores #> .................... #> calculating stability measures #> done"},{"path":"https://masterclm.github.io/mclm/reference/sort.assoc_scores.html","id":null,"dir":"Reference","previous_headings":"","what":"Sort an 'assoc_scores' object — sort.assoc_scores","title":"Sort an 'assoc_scores' object — sort.assoc_scores","text":"Sort full object class assoc_scores based criterion. print bit flexibility.","code":""},{"path":"https://masterclm.github.io/mclm/reference/sort.assoc_scores.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sort an 'assoc_scores' object — sort.assoc_scores","text":"","code":"# S3 method for assoc_scores sort(x, decreasing = TRUE, sort_order = \"none\", ...)"},{"path":"https://masterclm.github.io/mclm/reference/sort.assoc_scores.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sort an 'assoc_scores' object — sort.assoc_scores","text":"x Object class assoc_scores. decreasing Boolean value. sort_order = \"alpha\" decreasing = FALSE, rows follow alphabetic order types. decreasing = TRUE instead, follow inverted alphabetic order (Z ). follows behavior applying sort() character vector: note default value probably want. sort_order column lower value indicates higher association, .e. form p-value, decreasing = TRUE place lower values top higher values bottom. column, decreasing = TRUE place higher values top lower values bottom. sort_order Criterion order rows. Possible values \"alpha\" (meaning items sorted alphabetically), \"none\" (meaning items sorted) present column name. ... Additional arguments.","code":""},{"path":"https://masterclm.github.io/mclm/reference/sort.assoc_scores.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sort an 'assoc_scores' object — sort.assoc_scores","text":"object class assoc_scores.","code":""},{"path":"https://masterclm.github.io/mclm/reference/sort.assoc_scores.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sort an 'assoc_scores' object — sort.assoc_scores","text":"","code":"a <- c(10,    30,    15,    1) b <- c(200, 1000,  5000,  300) c <- c(100,   14,    16,    4) d <- c(300, 5000, 10000, 6000) types <- c(\"four\", \"fictitious\", \"toy\", \"examples\") (scores <- assoc_abcd(a, b, c, d, types = types)) #> Association scores (types in list: 4) #>         type  a    PMI G_signed|   b   c     d dir  exp_a DP_rows #> 1       four 10 -1.921  -45.432| 200 100   300  -1 37.869  -0.202 #> 2 fictitious 30  2.000   56.959|1000  14  5000   1  7.498   0.026 #> 3        toy 15  0.536    2.984|5000  16 10000   1 10.343   0.001 #> 4   examples  1  2.067    1.473| 300   4  6000   1  0.239   0.003 #> <number of extra columns to the right: 7> #>   print(scores, sort_order = \"PMI\") #> Association scores (types in list: 4, sort order criterion: PMI) #>         type  a    PMI G_signed|   b   c     d dir  exp_a DP_rows #> 1   examples  1  2.067    1.473| 300   4  6000   1  0.239   0.003 #> 2 fictitious 30  2.000   56.959|1000  14  5000   1  7.498   0.026 #> 3        toy 15  0.536    2.984|5000  16 10000   1 10.343   0.001 #> 4       four 10 -1.921  -45.432| 200 100   300  -1 37.869  -0.202 #> <number of extra columns to the right: 7> #>  sorted_scores <- sort(scores, sort_order = \"PMI\") sorted_scores #> Association scores (types in list: 4) #>         type  a    PMI G_signed|   b   c     d dir  exp_a DP_rows #> 1   examples  1  2.067    1.473| 300   4  6000   1  0.239   0.003 #> 2 fictitious 30  2.000   56.959|1000  14  5000   1  7.498   0.026 #> 3        toy 15  0.536    2.984|5000  16 10000   1 10.343   0.001 #> 4       four 10 -1.921  -45.432| 200 100   300  -1 37.869  -0.202 #> <number of extra columns to the right: 7> #>   sort(scores, decreasing = FALSE, sort_order = \"PMI\") #> Association scores (types in list: 4) #>         type  a    PMI G_signed|   b   c     d dir  exp_a DP_rows #> 1       four 10 -1.921  -45.432| 200 100   300  -1 37.869  -0.202 #> 2        toy 15  0.536    2.984|5000  16 10000   1 10.343   0.001 #> 3 fictitious 30  2.000   56.959|1000  14  5000   1  7.498   0.026 #> 4   examples  1  2.067    1.473| 300   4  6000   1  0.239   0.003 #> <number of extra columns to the right: 7> #>"},{"path":"https://masterclm.github.io/mclm/reference/sort.freqlist.html","id":null,"dir":"Reference","previous_headings":"","what":"Sort a frequency list — sort.freqlist","title":"Sort a frequency list — sort.freqlist","text":"method sorts object class freqlist.","code":""},{"path":"https://masterclm.github.io/mclm/reference/sort.freqlist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sort a frequency list — sort.freqlist","text":"","code":"# S3 method for freqlist sort(   x,   decreasing = FALSE,   sort_crit = c(\"ranks\", \"names\", \"orig_ranks\", \"freqs\"),   na_last = TRUE,   ... )"},{"path":"https://masterclm.github.io/mclm/reference/sort.freqlist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sort a frequency list — sort.freqlist","text":"x Object class freqlist. decreasing Logical. TRUE items sorted large small; FALSE, small large. Note, however, ranking frequency lists lower ranks correspond higher frequencies. Therefore, sorting rank (either \"ranks\" \"orig_ranks\") decreasing set default value FALSE results highest frequencies ending beginning sorted list. sort_crit Character string determining sorting criterion. sort_crit \"ranks\", items frequency list sorted current frequency rank. sort_crit \"names\", items frequency list sorted alphabetically name. sort_crit \"orig_ranks\", items frequency list sorted original ranks (present), current frequency ranks (original ranks present). Finally, sorting sort_crit set \"freqs\" identical sorting frequency ranks, meaning argument decreasing reversed. words, sorting frequencies (\"freqs\") decreasing set default value FALSE results lowest frequencies ending beginning sorted list. na_last Logical defining behavior NA elements. argument relevant sort_crit \"orig_ranks\" currently names frequencies allowed NA frequency lists. na_last TRUE, items sorting criterion NA end end sorted frequency list. na_last FALSE, items sorting criterion NA end start sorted frequency list. na_last NA, items sorting criterion NA removed sorted frequency list. ... Additional arguments.","code":""},{"path":"https://masterclm.github.io/mclm/reference/sort.freqlist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sort a frequency list — sort.freqlist","text":"Object class freqlist.","code":""},{"path":"https://masterclm.github.io/mclm/reference/sort.freqlist.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sort a frequency list — sort.freqlist","text":"way ranks calculated ties (lower ranks assigned ties earlier list), sorting list may affect ranks ties. specifically, ranks among ties may differ depending criterion used sort frequency list.","code":""},{"path":"https://masterclm.github.io/mclm/reference/sort.freqlist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sort a frequency list — sort.freqlist","text":"","code":"(flist <- freqlist(tokenize(\"the old story of the old man and the sea.\"))) #> Frequency list (types in list: 7, tokens in list: 10) #> rank  type abs_freq nrm_freq #> ---- ----- -------- -------- #>    1   the        3     3000 #>    2   old        2     2000 #>    3   and        1     1000 #>    4   man        1     1000 #>    5    of        1     1000 #>    6   sea        1     1000 #>    7 story        1     1000 sort(flist) #> Frequency list (types in list: 7, tokens in list: 10) #> rank orig_rank  type abs_freq nrm_freq #> ---- --------- ----- -------- -------- #>    1         1   the        3     3000 #>    2         2   old        2     2000 #>    3         3   and        1     1000 #>    4         4   man        1     1000 #>    5         5    of        1     1000 #>    6         6   sea        1     1000 #>    7         7 story        1     1000 sort(flist, decreasing = TRUE) #> Frequency list (types in list: 7, tokens in list: 10) #> rank orig_rank  type abs_freq nrm_freq #> ---- --------- ----- -------- -------- #>    7         7 story        1     1000 #>    6         6   sea        1     1000 #>    5         5    of        1     1000 #>    4         4   man        1     1000 #>    3         3   and        1     1000 #>    2         2   old        2     2000 #>    1         1   the        3     3000"},{"path":"https://masterclm.github.io/mclm/reference/sort.tokens.html","id":null,"dir":"Reference","previous_headings":"","what":"Sort a Sequence of Tokens — sort.tokens","title":"Sort a Sequence of Tokens — sort.tokens","text":"Sort object class 'tokens'.","code":""},{"path":"https://masterclm.github.io/mclm/reference/sort.tokens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sort a Sequence of Tokens — sort.tokens","text":"","code":"# S3 method for tokens sort(x,      decreasing = FALSE,      ...)"},{"path":"https://masterclm.github.io/mclm/reference/sort.tokens.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sort a Sequence of Tokens — sort.tokens","text":"x object class 'tokens'. decreasing logical value indicates whether items    sorted small large (decreasing    FALSE) large small    (decreasing TRUE). default    value FALSE. ... additional arguments.","code":""},{"path":"https://masterclm.github.io/mclm/reference/sort.tokens.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sort a Sequence of Tokens — sort.tokens","text":"function described page returns object class  'tokens'.","code":""},{"path":"https://masterclm.github.io/mclm/reference/sort.tokens.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sort a Sequence of Tokens — sort.tokens","text":"moment, tokens sequences allowed contain   NA values. Therefore, function argument available   specifies NA values sorted.","code":""},{"path":"https://masterclm.github.io/mclm/reference/sort.tokens.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sort a Sequence of Tokens — sort.tokens","text":"","code":"(tks <- tokenize(\"the old man and the sea.\")) #> Token sequence of length 6 #> idx token #> --- ----- #>   1   the #>   2   old #>   3   man #>   4   and #>   5   the #>   6   sea sort(tks) #> Token sequence of length 6 #> idx token #> --- ----- #>   1   and #>   2   man #>   3   old #>   4   sea #>   5   the #>   6   the sort(tks, decreasing = TRUE) #> Token sequence of length 6 #> idx token #> --- ----- #>   1   the #>   2   the #>   3   sea #>   4   old #>   5   man #>   6   and  #sort(flist)"},{"path":"https://masterclm.github.io/mclm/reference/tokens.html","id":null,"dir":"Reference","previous_headings":"","what":"Create or coerce an object into class tokens — tokens","title":"Create or coerce an object into class tokens — tokens","text":"tokenize() splits text sequence tokens, using regular expressions identify , returns object class tokens.","code":""},{"path":"https://masterclm.github.io/mclm/reference/tokens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create or coerce an object into class tokens — tokens","text":"","code":"tokenize(   x,   re_drop_line = NULL,   line_glue = NULL,   re_cut_area = NULL,   re_token_splitter = re(\"[^_\\\\p{L}\\\\p{N}\\\\p{M}'-]+\"),   re_token_extractor = re(\"[_\\\\p{L}\\\\p{N}\\\\p{M}'-]+\"),   re_drop_token = NULL,   re_token_transf_in = NULL,   token_transf_out = NULL,   token_to_lower = TRUE,   perl = TRUE,   ngram_size = NULL,   max_skip = 0,   ngram_sep = \"_\",   ngram_n_open = 0,   ngram_open = \"[]\" )"},{"path":"https://masterclm.github.io/mclm/reference/tokens.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create or coerce an object into class tokens — tokens","text":"x Either character vector object class NLP::TextDocument contains text tokenized. re_drop_line NULL character vector. NULL, ignored. Otherwise, character vector (assumed length 1) containing regular expression. Lines x contain match re_drop_line treated belonging corpus excluded results. line_glue NULL character vector. NULL, ignored. Otherwise, lines corpus file (x, as_text TRUE), glued together one character vector length 1, string line_glue pasted consecutive lines. value line_glue can also equal empty string \"\". 'line glue' operation conducted immediately 'drop line' operation. re_cut_area NULL character vector. NULL, ignored. Otherwise, matches corpus file (x, as_text TRUE), 'cut ' text prior identification tokens text (therefore taken account identifying tokens). 'cut area' operation conducted immediately 'line glue' operation. re_token_splitter Regular expression NULL. Regular expression identifies locations lines corpus files split tokens. (See Details.) 'token identification' operation conducted immediately 'cut area' operation. re_token_extractor Regular expression identifies locations actual tokens. argument used re_token_splitter NULL. (See Details.) 'token identification' operation conducted immediately 'cut area' operation. re_drop_token Regular expression NULL. NULL, ignored. Otherwise, identifies tokens excluded results. token contains match re_drop_token removed results. 'drop token' operation conducted immediately 'token identification' operation. re_token_transf_in Regular expression identifies areas tokens transformed. argument works together argument token_transf_out. re_token_transf_in token_transf_out differ NA, matches, tokens, regular expression  re_token_transf_in replaced replacement string token_transf_out. 'token transformation' operation conducted immediately 'drop token' operation. token_transf_out Replacement string. argument works together re_token_transf_in ignored re_token_transf_in NULL NA. token_to_lower Logical. Whether tokens must converted lowercase returning result. 'token lower' operation conducted immediately 'token transformation' operation. perl Logical. Whether PCRE regular expression flavor used arguments contain regular expressions. ngram_size Argument support ngrams/skipgrams (see also max_skip). one wants identify individual tokens, value ngram_size NULL 1. one wants retrieve token ngrams/skipgrams, ngram_size integer indicating size ngrams/skipgrams. E.g. 2 bigrams, 3 trigrams, etc. max_skip Argument support skipgrams. argument ignored ngram_size NULL 1. ngram_size 2 higher, max_skip 0, regular ngrams retrieved (albeit may contain open slots; see ngram_n_open). ngram_size 2 higher, max_skip 1 higher, skipgrams retrieved (current implementation contain open slots; see ngram_n_open). instance, ngram_size 3 max_skip 2, 2-skip trigrams retrieved. ngram_size 5 max_skip 3, 3-skip 5-grams retrieved. ngram_sep Character vector length 1 containing string used separate/link tokens representation ngrams/skipgrams output function. ngram_n_open ngram_size 2 higher, moreover ngram_n_open number higher 0, ngrams 'open slots' retrieved. ngrams 'open slots' generalizations fully lexically specific ngrams (generalization one items ngram replaced notation stands 'arbitrary token'). instance, ngram_size 4 ngram_n_open 1, moreover input contains 4-gram \"it_is_widely_accepted\", output contain modifications \"it_is_widely_accepted\" one (since ngram_n_open 1) items n-gram replaced open slot. first last item inside ngram never turned open slot; items candidates turned open slots. Therefore, example, output contain \"it_[]_widely_accepted\" \"it_is_[]_accepted\". second example, ngram_size 5 ngram_n_open 2, moreover input contains 5-gram \"it_is_widely_accepted_that\", output contain \"it_[]_[]_accepted_that\", \"it_[]_widely_[]_that\", \"it_is_[]_[]_that\". ngram_open Character string used represent open slots ngrams output function.","code":""},{"path":"https://masterclm.github.io/mclm/reference/tokens.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create or coerce an object into class tokens — tokens","text":"object class tokens, .e. sequence tokens. number attributes method : base print, as_data_frame(), summary() (returns number items), sort() rev(), tibble::as_tibble(), interactive explore() method, getters, namely n_tokens() n_types(), subsetting methods keep_types(), keep_pos(), etc. including [] subsetting (see brackets). Additional manipulation functions include trunc_at() method ??, tokens_merge() tokens_merge_all() combine token lists as_character() method convert character vector. Objects class tokens can saved file write_tokens(); files can read read_freqlist().","code":""},{"path":"https://masterclm.github.io/mclm/reference/tokens.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create or coerce an object into class tokens — tokens","text":"output contains ngrams open slots, order items output longer meaningful. instance, imagine case ngram_size 5 ngram_n_open 2. input contains 5-gram \"it_is_widely_accepted_that\", output contain \"it_[]_[]_accepted_that\", \"it_[]_widely_[]_that\" \"it_is_[]_[]_that\". relative order three items output must considered arbitrary.","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/tokens.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create or coerce an object into class tokens — tokens","text":"","code":"toy_corpus <- \"Once upon a time there was a tiny toy corpus. It consisted of three sentences. And it lived happily ever after.\"  tks <- tokenize(toy_corpus) print(tks, n = 1000) #> Token sequence of length 21 #> idx     token #> --- --------- #>   1      once #>   2      upon #>   3         a #>   4      time #>   5     there #>   6       was #>   7         a #>   8      tiny #>   9       toy #>  10    corpus #>  11        it #>  12 consisted #>  13        of #>  14     three #>  15 sentences #>  16       and #>  17        it #>  18     lived #>  19   happily #>  20      ever #>  21     after  tks <- tokenize(toy_corpus, re_token_splitter = \"\\\\W+\") print(tks, n = 1000) #> Token sequence of length 21 #> idx     token #> --- --------- #>   1      once #>   2      upon #>   3         a #>   4      time #>   5     there #>   6       was #>   7         a #>   8      tiny #>   9       toy #>  10    corpus #>  11        it #>  12 consisted #>  13        of #>  14     three #>  15 sentences #>  16       and #>  17        it #>  18     lived #>  19   happily #>  20      ever #>  21     after sort(tks) #> Token sequence of length 21 #> idx     token #> --- --------- #>   1         a #>   2         a #>   3     after #>   4       and #>   5 consisted #>   6    corpus #>   7      ever #>   8   happily #>   9        it #>  10        it #>  11     lived #>  12        of #>  13      once #>  14 sentences #>  15     there #>  16     three #>  17      time #>  18      tiny #>  19       toy #>  20      upon #> ... #>  summary(tks) #> Token sequence of length 21  tokenize(toy_corpus, ngram_size = 3) #> Token sequence of length 19 #> idx               token #> --- ------------------- #>   1         once_upon_a #>   2         upon_a_time #>   3        a_time_there #>   4      time_there_was #>   5         there_was_a #>   6          was_a_tiny #>   7          a_tiny_toy #>   8     tiny_toy_corpus #>   9       toy_corpus_it #>  10 corpus_it_consisted #>  11     it_consisted_of #>  12  consisted_of_three #>  13  of_three_sentences #>  14 three_sentences_and #>  15    sentences_and_it #>  16        and_it_lived #>  17    it_lived_happily #>  18  lived_happily_ever #>  19  happily_ever_after  tokenize(toy_corpus, ngram_size = 3, max_skip = 2) #> Token sequence of length 106 #> idx           token #> --- --------------- #>   1     once_upon_a #>   2  once_upon_time #>   3 once_upon_there #>   4     once_a_time #>   5    once_a_there #>   6 once_time_there #>   7     upon_a_time #>   8    upon_a_there #>   9      upon_a_was #>  10 upon_time_there #>  11   upon_time_was #>  12  upon_there_was #>  13    a_time_there #>  14      a_time_was #>  15        a_time_a #>  16     a_there_was #>  17       a_there_a #>  18         a_was_a #>  19  time_there_was #>  20    time_there_a #> ... #>   tokenize(toy_corpus, ngram_size = 3, ngram_n_open = 1) #> Token sequence of length 19 #> idx               token #> --- ------------------- #>   1           once_[]_a #>   2        upon_[]_time #>   3          a_[]_there #>   4         time_[]_was #>   5          there_[]_a #>   6         was_[]_tiny #>   7            a_[]_toy #>   8      tiny_[]_corpus #>   9           toy_[]_it #>  10 corpus_[]_consisted #>  11            it_[]_of #>  12  consisted_[]_three #>  13     of_[]_sentences #>  14        three_[]_and #>  15     sentences_[]_it #>  16        and_[]_lived #>  17       it_[]_happily #>  18       lived_[]_ever #>  19    happily_[]_after"},{"path":"https://masterclm.github.io/mclm/reference/tot_n_tokens.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve or set the total number of tokens — tot_n_tokens","title":"Retrieve or set the total number of tokens — tot_n_tokens","text":"methods retrieve set total number tokens corpus frequency counts based. total number tokens may higher sum frequency counts x, instance, x contains frequency counts selection items , tokens corpus.","code":""},{"path":"https://masterclm.github.io/mclm/reference/tot_n_tokens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve or set the total number of tokens — tot_n_tokens","text":"","code":"tot_n_tokens(x)  tot_n_tokens(x) <- value  # S3 method for freqlist tot_n_tokens(x) <- value  # S3 method for freqlist tot_n_tokens(x)"},{"path":"https://masterclm.github.io/mclm/reference/tot_n_tokens.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve or set the total number of tokens — tot_n_tokens","text":"x object classes method implemented. value Numerical value.","code":""},{"path":"https://masterclm.github.io/mclm/reference/tot_n_tokens.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve or set the total number of tokens — tot_n_tokens","text":"number.","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/tot_n_tokens.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve or set the total number of tokens — tot_n_tokens","text":"","code":"x <- freqlist(\"The man and the mouse.\",               re_token_splitter = \"(?xi) [:\\\\s.;,?!\\\"]+\",               as_text = TRUE) x #> Frequency list (types in list: 4, tokens in list: 5) #> rank  type abs_freq nrm_freq #> ---- ----- -------- -------- #>    1   the        2     4000 #>    2   and        1     2000 #>    3   man        1     2000 #>    4 mouse        1     2000 tot_n_tokens(x) #> [1] 5  y <- keep_types(x, c(\"man\", \"and\")) tot_n_tokens(y) #> [1] 5 y #> Frequency list (types in list: 2, tokens in list: 2) #> <total number of tokens: 5> #> rank orig_rank type abs_freq nrm_freq #> ---- --------- ---- -------- -------- #>    2         3  man        1     2000 #>    1         2  and        1     2000  tot_n_tokens(y) <- sum(y) y #> Frequency list (types in list: 2, tokens in list: 2) #> rank orig_rank type abs_freq nrm_freq #> ---- --------- ---- -------- -------- #>    2         3  man        1     5000 #>    1         2  and        1     5000 tot_n_tokens(y) #> [1] 2"},{"path":"https://masterclm.github.io/mclm/reference/trunc_at.html","id":null,"dir":"Reference","previous_headings":"","what":"Truncate a sequence of character data — trunc_at","title":"Truncate a sequence of character data — trunc_at","text":"method takes argument x object represents sequence character data, object class tokens, truncates position match argument pattern found. Currently implemented tokens objects.","code":""},{"path":"https://masterclm.github.io/mclm/reference/trunc_at.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Truncate a sequence of character data — trunc_at","text":"","code":"trunc_at(x, pattern, ...)  # S3 method for tokens trunc_at(   x,   pattern,   keep_this = FALSE,   last_match = FALSE,   from_end = FALSE,   ... )"},{"path":"https://masterclm.github.io/mclm/reference/trunc_at.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Truncate a sequence of character data — trunc_at","text":"x object represents sequence character data. pattern regular expression. ... Additional arguments. keep_this Logical. Whether matching token kept. TRUE, truncating happens right matching token; FALSE, right . last_match Logical. case several matching tokens, last_match TRUE, last match used truncating point; otherwise, first match . from_end Logical. FALSE, match starts first token progressing forward; TRUE, starts last token progressing backward. from_end FALSE, part x kept truncation head x. TRUE instead, part kept truncation tail x.","code":""},{"path":"https://masterclm.github.io/mclm/reference/trunc_at.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Truncate a sequence of character data — trunc_at","text":"truncated version x.","code":""},{"path":"https://masterclm.github.io/mclm/reference/trunc_at.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Truncate a sequence of character data — trunc_at","text":"","code":"(toks <- tokenize('This is a first sentence . This is a second sentence .', re_token_splitter = '\\\\s+')) #> Token sequence of length 12 #> idx    token #> --- -------- #>   1     this #>   2       is #>   3        a #>   4    first #>   5 sentence #>   6        . #>   7     this #>   8       is #>   9        a #>  10   second #>  11 sentence #>  12        .  trunc_at(toks, re(\"[.]\"))  trunc_at(toks, re(\"[.]\"), last_match = TRUE)  trunc_at(toks, re(\"[.]\"), last_match = TRUE, from_end = TRUE)"},{"path":"https://masterclm.github.io/mclm/reference/type_freqs.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve frequencies from 'freqlist' object — type_freqs","title":"Retrieve frequencies from 'freqlist' object — type_freqs","text":"type_freq type_freqs retrieve frequency items freqlist object.","code":""},{"path":"https://masterclm.github.io/mclm/reference/type_freqs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve frequencies from 'freqlist' object — type_freqs","text":"","code":"type_freqs(x, types = NULL, with_names = FALSE, ...)  type_freq(x, types = NULL, with_names = FALSE, ...)"},{"path":"https://masterclm.github.io/mclm/reference/type_freqs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve frequencies from 'freqlist' object — type_freqs","text":"x Object class freqlist. types NULL character vector object class types. argument types NULL, frequencies items x returned, order items appear x. argument types character vector object class types, frequencies (x) items types given, order items appear types. items types occur x, frequency zero returned. with_names Logical. Whether items output given names. with_names TRUE, names types frequency list used names. ... Additional arguments.","code":""},{"path":"https://masterclm.github.io/mclm/reference/type_freqs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve frequencies from 'freqlist' object — type_freqs","text":"Numeric vector representing frequencies items.","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/type_freqs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve frequencies from 'freqlist' object — type_freqs","text":"","code":"(flist <- freqlist(\"The man and the mouse.\", as_text = TRUE)) #> Frequency list (types in list: 4, tokens in list: 5) #> rank  type abs_freq nrm_freq #> ---- ----- -------- -------- #>    1   the        2     4000 #>    2   and        1     2000 #>    3   man        1     2000 #>    4 mouse        1     2000  type_freqs(flist) # frequencies of all items #> [1] 2 1 1 1 type_names(flist) # names of all items #> [1] \"the\"   \"and\"   \"man\"   \"mouse\"  type_freqs(flist, with_names = TRUE) # frequencies of all types, with names #>   the   and   man mouse  #>     2     1     1     1  type_freqs(flist, c(\"man\", \"the\")) # frequencies of specific items ... #> [1] 1 2 type_freqs(flist, c(\"the\", \"man\")) # ... in the requested order #> [1] 2 1 type_freq(flist, \"the\")            # frequency of one item #> [1] 2  # frequencies of specific items can also be printed using subsetting flist[c(\"the\", \"man\")]  #> Frequency list (types in list: 2, tokens in list: 3) #> <total number of tokens: 5> #> rank orig_rank type abs_freq nrm_freq #> ---- --------- ---- -------- -------- #>    1         1  the        2     4000 #>    2         3  man        1     2000 flist[\"the\"] #> Frequency list (types in list: 1, tokens in list: 2) #> <total number of tokens: 5> #> rank orig_rank type abs_freq nrm_freq #> ---- --------- ---- -------- -------- #>    1         1  the        2     4000"},{"path":"https://masterclm.github.io/mclm/reference/type_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Return the names of the types in an object — type_names","title":"Return the names of the types in an object — type_names","text":"method returns names types represented object.","code":""},{"path":"https://masterclm.github.io/mclm/reference/type_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return the names of the types in an object — type_names","text":"","code":"type_names(x, ...)  # S3 method for assoc_scores type_names(x, ...)  # S3 method for freqlist type_names(x, ...)"},{"path":"https://masterclm.github.io/mclm/reference/type_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return the names of the types in an object — type_names","text":"x object classes method implemented. ... Additional arguments.","code":""},{"path":"https://masterclm.github.io/mclm/reference/type_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return the names of the types in an object — type_names","text":"Character vector.","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/type_names.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Return the names of the types in an object — type_names","text":"","code":"# for a freqlist object (flist <- freqlist(\"The man and the mouse.\", as_text = TRUE)) #> Frequency list (types in list: 4, tokens in list: 5) #> rank  type abs_freq nrm_freq #> ---- ----- -------- -------- #>    1   the        2     4000 #>    2   and        1     2000 #>    3   man        1     2000 #>    4 mouse        1     2000  type_names(flist) #> [1] \"the\"   \"and\"   \"man\"   \"mouse\"  # for an assoc_scores object a <- c(10,    30,    15,    1) b <- c(200, 1000,  5000,  300) c <- c(100,   14,    16,    4) d <- c(300, 5000, 10000, 6000) types <- c(\"four\", \"fictitious\", \"toy\", \"examples\")  (scores <- assoc_abcd(a, b, c, d, types = types)) #> Association scores (types in list: 4) #>         type  a    PMI G_signed|   b   c     d dir  exp_a DP_rows #> 1       four 10 -1.921  -45.432| 200 100   300  -1 37.869  -0.202 #> 2 fictitious 30  2.000   56.959|1000  14  5000   1  7.498   0.026 #> 3        toy 15  0.536    2.984|5000  16 10000   1 10.343   0.001 #> 4   examples  1  2.067    1.473| 300   4  6000   1  0.239   0.003 #> <number of extra columns to the right: 7> #>  type_names(scores) #> [1] \"four\"       \"fictitious\" \"toy\"        \"examples\""},{"path":"https://masterclm.github.io/mclm/reference/types.html","id":null,"dir":"Reference","previous_headings":"","what":"Build a 'types' object — types","title":"Build a 'types' object — types","text":"function builds object class types.","code":""},{"path":"https://masterclm.github.io/mclm/reference/types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build a 'types' object — types","text":"","code":"types(   x,   re_drop_line = NULL,   line_glue = NULL,   re_cut_area = NULL,   re_token_splitter = re(\"[^_\\\\p{L}\\\\p{N}\\\\p{M}'-]+\"),   re_token_extractor = re(\"[_\\\\p{L}\\\\p{N}\\\\p{M}'-]+\"),   re_drop_token = NULL,   re_token_transf_in = NULL,   token_transf_out = NULL,   token_to_lower = TRUE,   perl = TRUE,   blocksize = 300,   verbose = FALSE,   show_dots = FALSE,   dot_blocksize = 10,   file_encoding = \"UTF-8\",   ngram_size = NULL,   ngram_sep = \"_\",   ngram_n_open = 0,   ngram_open = \"[]\",   as_text = FALSE )"},{"path":"https://masterclm.github.io/mclm/reference/types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build a 'types' object — types","text":"x Either list filenames corpus files (as_text TRUE) actual text corpus (as_text FALSE). as_text TRUE length vector x higher one, item x treated separate line (separate series lines) corpus text. Within item x, character \"\\\\n\" also treated line separator. re_drop_line NULL character vector. NULL, ignored. Otherwise, character vector (assumed length 1) containing regular expression. Lines x contain match re_drop_line treated belonging corpus excluded results. line_glue NULL character vector. NULL, ignored. Otherwise, lines corpus file (x, as_text TRUE), glued together one character vector length 1, string line_glue pasted consecutive lines. value line_glue can also equal empty string \"\". 'line glue' operation conducted immediately 'drop line' operation. re_cut_area NULL character vector. NULL, ignored. Otherwise, matches corpus file (x, as_text TRUE), 'cut ' text prior identification tokens text (therefore taken account identifying tokens). 'cut area' operation conducted immediately 'line glue' operation. re_token_splitter Regular expression NULL. Regular expression identifies locations lines corpus files split tokens. (See Details.) 'token identification' operation conducted immediately 'cut area' operation. re_token_extractor Regular expression identifies locations actual tokens. argument used re_token_splitter NULL. (See Details.) 'token identification' operation conducted immediately 'cut area' operation. re_drop_token Regular expression NULL. NULL, ignored. Otherwise, identifies tokens excluded results. token contains match re_drop_token removed results. 'drop token' operation conducted immediately 'token identification' operation. re_token_transf_in Regular expression identifies areas tokens transformed. argument works together argument token_transf_out. re_token_transf_in token_transf_out differ NA, matches, tokens, regular expression  re_token_transf_in replaced replacement string token_transf_out. 'token transformation' operation conducted immediately 'drop token' operation. token_transf_out Replacement string. argument works together re_token_transf_in ignored re_token_transf_in NULL NA. token_to_lower Logical. Whether tokens must converted lowercase returning result. 'token lower' operation conducted immediately 'token transformation' operation. perl Logical. Whether PCRE regular expression flavor used arguments contain regular expressions. blocksize Number indicates many corpus files read memory individual step' steps procedure; normally default value 300` changed, one works exceptionally small corpus files, may worthwhile use higher number, one works exceptionally large corpus files, may worthwhile use lower number. verbose IfTRUE, messages printed console indicate progress. show_dots, dot_blocksize TRUE, dots printed console indicate progress. file_encoding File encoding assumed corpus files. ngram_size Argument support ngrams/skipgrams (see also max_skip). one wants identify individual tokens, value ngram_size NULL 1. one wants retrieve token ngrams/skipgrams, ngram_size integer indicating size ngrams/skipgrams. E.g. 2 bigrams, 3 trigrams, etc. ngram_sep Character vector length 1 containing string used separate/link tokens representation ngrams/skipgrams output function. ngram_n_open ngram_size 2 higher, moreover ngram_n_open number higher 0, ngrams 'open slots' retrieved. ngrams 'open slots' generalizations fully lexically specific ngrams (generalization one items ngram replaced notation stands 'arbitrary token'). instance, ngram_size 4 ngram_n_open 1, moreover input contains 4-gram \"it_is_widely_accepted\", output contain modifications \"it_is_widely_accepted\" one (since ngram_n_open 1) items n-gram replaced open slot. first last item inside ngram never turned open slot; items candidates turned open slots. Therefore, example, output contain \"it_[]_widely_accepted\" \"it_is_[]_accepted\". second example, ngram_size 5 ngram_n_open 2, moreover input contains 5-gram \"it_is_widely_accepted_that\", output contain \"it_[]_[]_accepted_that\", \"it_[]_widely_[]_that\", \"it_is_[]_[]_that\". ngram_open Character string used represent open slots ngrams output function. as_text Logical. Whether x interpreted character vector containing actual contents corpus (as_text TRUE) character vector containing names corpus files (as_text FALSE). as_text TRUE, arguments blocksize, verbose, show_dots, dot_blocksize, file_encoding ignored.","code":""},{"path":"https://masterclm.github.io/mclm/reference/types.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build a 'types' object — types","text":"object class types, based character vector. additional attributes methods : base print(), as_data_frame(), sort() base::summary() (returns number items unique items), tibble::as_tibble(), n_types() getter explore() method, subsetting methods keep_types(), keep_pos(), etc. including [] subsetting (see brackets). object class types can merged another means types_merge(), written file write_types() read file write_types().","code":""},{"path":"https://masterclm.github.io/mclm/reference/types.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Build a 'types' object — types","text":"actual token identification either based re_token_splitter argument, regular expression identifies areas tokens, re_token_extractor, regular expression identifies area tokens. first mechanism default mechanism: argument re_token_extractor used re_token_splitter NULL. Currently implementation re_token_extractor lot less time-efficient re_token_splitter.","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/types.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build a 'types' object — types","text":"","code":"toy_corpus <- \"Once upon a time there was a tiny toy corpus. It consisted of three sentences. And it lived happily ever after.\" (tps <- types(toy_corpus, as_text = TRUE)) #> Type collection of length 19 #>         type #>    --------- #>  1         a #>  2        it #>  3     after #>  4       and #>  5 consisted #>  6    corpus #>  7      ever #>  8   happily #>  9     lived #> 10        of #> 11      once #> 12 sentences #> 13     there #> 14     three #> 15      time #> 16      tiny #> 17       toy #> 18      upon #> 19       was print(tps) #> Type collection of length 19 #>         type #>    --------- #>  1         a #>  2        it #>  3     after #>  4       and #>  5 consisted #>  6    corpus #>  7      ever #>  8   happily #>  9     lived #> 10        of #> 11      once #> 12 sentences #> 13     there #> 14     three #> 15      time #> 16      tiny #> 17       toy #> 18      upon #> 19       was  as.data.frame(tps) #>         type #> 1          a #> 2         it #> 3      after #> 4        and #> 5  consisted #> 6     corpus #> 7       ever #> 8    happily #> 9      lived #> 10        of #> 11      once #> 12 sentences #> 13     there #> 14     three #> 15      time #> 16      tiny #> 17       toy #> 18      upon #> 19       was as_tibble(tps) #> # A tibble: 19 × 1 #>    type      #>    <types>   #>  1 a         #>  2 it        #>  3 after     #>  4 and       #>  5 consisted #>  6 corpus    #>  7 ever      #>  8 happily   #>  9 lived     #> 10 of        #> 11 once      #> 12 sentences #> 13 there     #> 14 three     #> 15 time      #> 16 tiny      #> 17 toy       #> 18 upon      #> 19 was        sort(tps) #> Type collection of length 19 #>         type #>    --------- #>  1         a #>  2     after #>  3       and #>  4 consisted #>  5    corpus #>  6      ever #>  7   happily #>  8        it #>  9     lived #> 10        of #> 11      once #> 12 sentences #> 13     there #> 14     three #> 15      time #> 16      tiny #> 17       toy #> 18      upon #> 19       was sort(tps, decreasing = TRUE) #> Type collection of length 19 #>         type #>    --------- #>  1       was #>  2      upon #>  3       toy #>  4      tiny #>  5      time #>  6     three #>  7     there #>  8 sentences #>  9      once #> 10        of #> 11     lived #> 12        it #> 13   happily #> 14      ever #> 15    corpus #> 16 consisted #> 17       and #> 18     after #> 19         a"},{"path":"https://masterclm.github.io/mclm/reference/write_assoc.html","id":null,"dir":"Reference","previous_headings":"","what":"Write association scores to file — write_assoc","title":"Write association scores to file — write_assoc","text":"function writes object class assoc_scores file.","code":""},{"path":"https://masterclm.github.io/mclm/reference/write_assoc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write association scores to file — write_assoc","text":"","code":"write_assoc(x, file = \"\", sep = \"\\t\")"},{"path":"https://masterclm.github.io/mclm/reference/write_assoc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write association scores to file — write_assoc","text":"x object class assoc_scores. file Name output file. sep Field separator output file.","code":""},{"path":"https://masterclm.github.io/mclm/reference/write_assoc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write association scores to file — write_assoc","text":"Invisibly, x.","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/write_assoc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write association scores to file — write_assoc","text":"","code":"if (FALSE) { txt1 <- \"we're just two lost souls swimming in a fish bowl, year after year, running over the same old ground, what have we found? the same old fears. wish you were here.\" flist1 <- freqlist(txt1, as_text = TRUE) txt2 <- \"picture yourself in a boat on a river with tangerine dreams and marmelade skies somebody calls you, you answer quite slowly a girl with kaleidoscope eyes\" flist2 <- freqlist(txt2, as_text = TRUE) (scores <- assoc_scores(flist1, flist2, min_freq = 0)) write_assoc(scores, \"example_scores.tab\") (scores2 <- read_assoc(\"example_scores.tab\")) }"},{"path":"https://masterclm.github.io/mclm/reference/write_conc.html","id":null,"dir":"Reference","previous_headings":"","what":"Write a concordance to file. — write_conc","title":"Write a concordance to file. — write_conc","text":"function writes object class conc file.","code":""},{"path":"https://masterclm.github.io/mclm/reference/write_conc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write a concordance to file. — write_conc","text":"","code":"write_conc(x, file = \"\", sep = \"\\t\")"},{"path":"https://masterclm.github.io/mclm/reference/write_conc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write a concordance to file. — write_conc","text":"x Object class conc. file Path output file. sep Field separator columns output file.","code":""},{"path":"https://masterclm.github.io/mclm/reference/write_conc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write a concordance to file. — write_conc","text":"Invisibly, x.","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/write_conc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write a concordance to file. — write_conc","text":"","code":"if (FALSE) { (d <- conc('A very small corpus.', '\\\\w+', as_text = TRUE)) write_conc(d, \"example_data.tab\") (d2 <- read_conc(\"example_data.tab\")) }"},{"path":"https://masterclm.github.io/mclm/reference/write_fnames.html","id":null,"dir":"Reference","previous_headings":"","what":"Write a collection of filenames to a text file — write_fnames","title":"Write a collection of filenames to a text file — write_fnames","text":"function writes object class fnames text file. filename written separate line. file encoding always \"UTF-8\". addition, can store metadata additional configuration file.","code":""},{"path":"https://masterclm.github.io/mclm/reference/write_fnames.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write a collection of filenames to a text file — write_fnames","text":"","code":"write_fnames(x, file, ...)"},{"path":"https://masterclm.github.io/mclm/reference/write_fnames.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write a collection of filenames to a text file — write_fnames","text":"x Object class fnames. file Path output file. ... Additional arguments (implemented).","code":""},{"path":"https://masterclm.github.io/mclm/reference/write_fnames.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write a collection of filenames to a text file — write_fnames","text":"Invisibly, x.","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/write_fnames.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write a collection of filenames to a text file — write_fnames","text":"","code":"if (FALSE) { cwd_fnames <- get_fnames(recursive = FALSE) write_fnames(cwd_fnames, \"file_with_filenames.txt\") cwd_fnames_2 <- read_fnames(\"file_with_filenames.txt\") }"},{"path":"https://masterclm.github.io/mclm/reference/write_freqlist.html","id":null,"dir":"Reference","previous_headings":"","what":"Write a frequency list to a csv file — write_freqlist","title":"Write a frequency list to a csv file — write_freqlist","text":"function writes object class freqlist csv file. resulting csv file contains two columns, first type second frequency type. file also contains header line names columns.","code":""},{"path":"https://masterclm.github.io/mclm/reference/write_freqlist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write a frequency list to a csv file — write_freqlist","text":"","code":"write_freqlist(x, file, sep = \"\\t\", make_config_file = TRUE, ...)"},{"path":"https://masterclm.github.io/mclm/reference/write_freqlist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write a frequency list to a csv file — write_freqlist","text":"x Object class freqlist. file Character vector length 1. Path output file. sep Character vector length 1. Column separator. make_config_file Logical. Whether configuration file needs created. circumstances, set TRUE. ... Additional arguments (implemented).","code":""},{"path":"https://masterclm.github.io/mclm/reference/write_freqlist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write a frequency list to a csv file — write_freqlist","text":"Invisibly, x.","code":""},{"path":"https://masterclm.github.io/mclm/reference/write_freqlist.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Write a frequency list to a csv file — write_freqlist","text":"write_freqlist writes file file, also creates configuration file name identical file, except filename extension \".yaml\". frequency list attributes \"tot_n_tokens\" \"tot_n_types\" stored configuration file.","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/write_freqlist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write a frequency list to a csv file — write_freqlist","text":"","code":"if (FALSE) { toy_corpus <- \"Once upon a time there was a tiny toy corpus. It consisted of three sentences. And it lived happily ever after.\" freqs <- freqlist(toy_corpus, as_text = TRUE)  print(freqs, n = 1000) write_freqlist(freqs, \"example_freqlist.csv\") freqs2 <- read_freqlist(\"example_freqlist.csv\") print(freqs2, n = 1000) }"},{"path":"https://masterclm.github.io/mclm/reference/write_tokens.html","id":null,"dir":"Reference","previous_headings":"","what":"Write a tokens object to a text file — write_tokens","title":"Write a tokens object to a text file — write_tokens","text":"function writes object class tokens text file. token written separate line. file encoding always \"UTF-8\". file can later read read_tokens().","code":""},{"path":"https://masterclm.github.io/mclm/reference/write_tokens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write a tokens object to a text file — write_tokens","text":"","code":"write_tokens(x, file, ...)"},{"path":"https://masterclm.github.io/mclm/reference/write_tokens.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write a tokens object to a text file — write_tokens","text":"x object class tokens. file Name output file. ... Additional arguments (implemented).","code":""},{"path":"https://masterclm.github.io/mclm/reference/write_tokens.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write a tokens object to a text file — write_tokens","text":"Invisibly, x.","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/write_tokens.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write a tokens object to a text file — write_tokens","text":"","code":"if (FALSE) { (tks <- tokenize(\"The old man and the sea.\")) write_tokens(tks, \"file_with_tokens.txt\") (tks2 <- read_tokens(\"file_with_tokens.txt\")) }"},{"path":"https://masterclm.github.io/mclm/reference/write_txt.html","id":null,"dir":"Reference","previous_headings":"","what":"Write a character vector to a text file — write_txt","title":"Write a character vector to a text file — write_txt","text":"function writes character vector text file. default, item character vector becomes line text file.","code":""},{"path":"https://masterclm.github.io/mclm/reference/write_txt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write a character vector to a text file — write_txt","text":"","code":"write_txt(x, file = \"\", line_glue = \"\\n\")"},{"path":"https://masterclm.github.io/mclm/reference/write_txt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write a character vector to a text file — write_txt","text":"x character vector. file Name output file. line_glue Character string used end--line marker disk NA end--line marker (x becomes single line).","code":""},{"path":"https://masterclm.github.io/mclm/reference/write_txt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write a character vector to a text file — write_txt","text":"Invisibly, x.","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/write_txt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write a character vector to a text file — write_txt","text":"","code":"if (FALSE) { x <- \"This is a small text.\"  # write the text to a text file write_txt(x, \"example-text-file.txt\") # read a text from file y <- read_txt(\"example-text-file.txt\") y }"},{"path":"https://masterclm.github.io/mclm/reference/write_types.html","id":null,"dir":"Reference","previous_headings":"","what":"Write a vector of types to a text file — write_types","title":"Write a vector of types to a text file — write_types","text":"function writes object class types text file. type written separate line. file encoding used \"UTF-8\".","code":""},{"path":"https://masterclm.github.io/mclm/reference/write_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write a vector of types to a text file — write_types","text":"","code":"write_types(x, file, ...)"},{"path":"https://masterclm.github.io/mclm/reference/write_types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write a vector of types to a text file — write_types","text":"x Object class types. file Name output file ... Additional arguments (implemented).","code":""},{"path":"https://masterclm.github.io/mclm/reference/write_types.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write a vector of types to a text file — write_types","text":"Invisibly, x.","code":""},{"path":[]},{"path":"https://masterclm.github.io/mclm/reference/write_types.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write a vector of types to a text file — write_types","text":"","code":"if (FALSE) {   types <- as_types(c(\"first\", \"second\", \"third\"))   write_types(types, \"file_with_types.txt\")   types_2 <- read_types(\"file_with_types.txt\")   }"},{"path":"https://masterclm.github.io/mclm/reference/zero_plus.html","id":null,"dir":"Reference","previous_headings":"","what":"Make all values strictly higher than zero — zero_plus","title":"Make all values strictly higher than zero — zero_plus","text":"auxiliary function makes values numeric vector x strictly positive replacing values equal lower zero values small.pos. small_pos stands 'small positive constant'.","code":""},{"path":"https://masterclm.github.io/mclm/reference/zero_plus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make all values strictly higher than zero — zero_plus","text":"","code":"zero_plus(x, small_pos = 1e-05)"},{"path":"https://masterclm.github.io/mclm/reference/zero_plus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make all values strictly higher than zero — zero_plus","text":"x numeric vector. small_pos (small) positive number replace negative values 0s.","code":""},{"path":"https://masterclm.github.io/mclm/reference/zero_plus.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make all values strictly higher than zero — zero_plus","text":"copy x values equal lower zero replaced small_pos.","code":""},{"path":"https://masterclm.github.io/mclm/reference/zero_plus.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make all values strictly higher than zero — zero_plus","text":"","code":"(x <- rnorm(30)) #>  [1]  0.73590420  1.80063821  0.70872217  1.68482245  1.60903903 -0.60443796 #>  [7]  2.30511056  0.67216580 -0.20695340 -0.38364395  0.35348617  0.63177901 #> [13]  1.54573295 -0.57590690 -0.58569503  0.72894925 -0.91698322 -0.37403847 #> [19]  1.09805672  1.00795088  0.52726743 -0.05689228  0.18284248  0.81015510 #> [25]  0.47036815 -1.50922665  0.02228813 -0.22299303 -2.84564781  0.43513545 zero_plus(x) #>  [1] 0.73590420 1.80063821 0.70872217 1.68482245 1.60903903 0.00001000 #>  [7] 2.30511056 0.67216580 0.00001000 0.00001000 0.35348617 0.63177901 #> [13] 1.54573295 0.00001000 0.00001000 0.72894925 0.00001000 0.00001000 #> [19] 1.09805672 1.00795088 0.52726743 0.00001000 0.18284248 0.81015510 #> [25] 0.47036815 0.00001000 0.02228813 0.00001000 0.00001000 0.43513545"},{"path":"https://masterclm.github.io/mclm/news/index.html","id":"mclm-026","dir":"Changelog","previous_headings":"","what":"mclm 0.2.6","title":"mclm 0.2.6","text":"First publish version package.","code":""}]
